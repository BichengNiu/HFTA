import streamlit as st
import pandas as pd
import io

# å°è¯•å¯¼å…¥åç«¯æ•°æ®å¤„ç†å‡½æ•°
try:
    from ..utils.data_comparison_data import (
        handle_uploaded_file_for_comparison,
        add_pending_file_to_staged_data,
        reset_all_pending_uploads_comparison,
        compare_variables_in_dataset,
        compare_datasets_for_common_variables,
        update_variable_in_staged_data,
        make_staged_data_copy # <--- Add new import
    )
    BACKEND_FUNCTIONS_AVAILABLE = True
except ImportError as e:
    BACKEND_FUNCTIONS_AVAILABLE = False
    print(f"Data Comparison UI: Error importing utils.data_comparison_data: {e}")

def render_data_comparison_ui():
    """
    æ¸²æŸ“æ•°æ®æ¯”è¾ƒæ ‡ç­¾é¡µçš„UIç•Œé¢ã€‚
    è¯¥æ ‡ç­¾é¡µåŒ…å«ä¸‰ä¸ªä¸»è¦çš„åŠŸèƒ½æ¨¡å—ã€‚
    """

    # åˆå§‹åŒ–session_stateé”® (æ¨¡å—1: ä¸Šä¼ è‡³æš‚å­˜åŒº)
    st.session_state.setdefault('dc_m1_uploader_key_suffix', 0)
    st.session_state.setdefault('dc_m1_pending_uploads', {}) # {filename: {'file_obj': UploadedFile, 'df_preview': pd.DataFrame, 'time_col_details': dict, 'error': str}}

    # --- åˆå§‹åŒ–session_stateé”® (æ¨¡å—2: å˜é‡æ¯”è¾ƒ) ---
    st.session_state.setdefault('dc_m2_selected_dataset_key', None)
    st.session_state.setdefault('dc_m2_selected_variables', [])
    st.session_state.setdefault('dc_m2_comparison_results', None) #  <--- æ–°å¢session_state

    # --- åˆå§‹åŒ–session_stateé”® (æ¨¡å—3: æ•°æ®é›†æ¯”è¾ƒ) ---
    st.session_state.setdefault('dc_m3_selected_datasets', [])      # For dataset comparison module
    st.session_state.setdefault('dc_m3_comparison_results', None)  # For dataset comparison module
    st.session_state.setdefault('dc_m3_update_execution_report', None)  # For update execution report

    # --- æ¨¡å—ä¸€: ä¸Šä¼ æ•°æ®è‡³æš‚å­˜åŒº ---
    with st.container():
        st.subheader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰")

        if not BACKEND_FUNCTIONS_AVAILABLE:
            st.error("é”™è¯¯ï¼šæ•°æ®æ¯”è¾ƒçš„æ ¸å¿ƒåç«¯å¤„ç†æ¨¡å—æœªèƒ½æˆåŠŸå¯¼å…¥ã€‚åŠŸèƒ½å—é™ã€‚")
            return

        # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
        uploader_key_dc_m1 = f"dc_m1_file_uploader_{st.session_state.get('dc_m1_uploader_key_suffix', 0)}"
        uploaded_files_dc_m1 = st.file_uploader(
            "é€‰æ‹©æˆ–æ‹–æ”¾ä¸€ä¸ªæˆ–å¤šä¸ªCSVæˆ–Excelæ–‡ä»¶ï¼š",
            type=['csv', 'xlsx', 'xls'],
            key=uploader_key_dc_m1,
            accept_multiple_files=True  # å…è®¸ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
        )

        # --- Synchronize pending_uploads with file_uploader state (handles 'X' clicks) ---
        pending_uploads_dict = st.session_state.get('dc_m1_pending_uploads', {})
        active_original_filenames_in_uploader = set()
        if uploaded_files_dc_m1: # This is the list of UploadedFile objects currently in the uploader
            active_original_filenames_in_uploader = {f.name for f in uploaded_files_dc_m1}
        
        keys_in_pending_to_remove = []
        if pending_uploads_dict: # Only proceed if there's something to sync
            for key, details_in_pending in pending_uploads_dict.items():
                if details_in_pending.get('original_filename') not in active_original_filenames_in_uploader:
                    keys_in_pending_to_remove.append(key)

            if keys_in_pending_to_remove:
                for key_to_del in keys_in_pending_to_remove:
                    if key_to_del in pending_uploads_dict:
                        del pending_uploads_dict[key_to_del]
                # Streamlit should rerun due to file_uploader change, updating the UI.

        # --- Process newly uploaded files (or remaining files after 'X' clicks) ---
        if uploaded_files_dc_m1:
            batch_success_messages = []
            batch_error_messages = []

            for uploaded_file_obj in uploaded_files_dc_m1: 
                # Let handle_uploaded_file_for_comparison decide if it needs to add to pending.
                # It should internally avoid adding duplicates to dc_m1_pending_uploads and check staged_data.
                success, messages_from_handler = handle_uploaded_file_for_comparison(st.session_state, uploaded_file_obj)
                
                if success:
                    if isinstance(messages_from_handler, list):
                        batch_success_messages.extend(messages_from_handler)
                    elif messages_from_handler: # Non-empty string
                        batch_success_messages.append(messages_from_handler)
                else:
                    if isinstance(messages_from_handler, list):
                        batch_error_messages.extend(messages_from_handler)
                    elif messages_from_handler: # Non-empty string
                        batch_error_messages.append(messages_from_handler)
            
            # Display aggregated messages from this batch of uploads processing
            # Ensure unique messages if there's overlap or repeated info
            if batch_success_messages:
                unique_success_messages = list(dict.fromkeys(batch_success_messages)) # Remove duplicates while preserving order
                st.success("\n".join(unique_success_messages))
            if batch_error_messages:
                unique_error_messages = list(dict.fromkeys(batch_error_messages)) # Remove duplicates
                st.error("\n".join(unique_error_messages))
            
            # DO NOT increment uploader key or st.rerun() here.
            # This allows the pending files list below to display what was just added.

        # æ˜¾ç¤ºå¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨
        if st.session_state.dc_m1_pending_uploads:
            st.markdown("##### **ä¸Šä¼ æ•°æ®é¢„è§ˆ**")
            
            pending_files_items = list(st.session_state.dc_m1_pending_uploads.items())
            num_files = len(pending_files_items)
            files_per_row = 2 # ä½ å¯ä»¥è°ƒæ•´æ¯è¡Œæ˜¾ç¤ºçš„é¢„è§ˆæ•°é‡

            for i in range(0, num_files, files_per_row):
                cols = st.columns(files_per_row)
                for j in range(files_per_row):
                    item_index = i + j
                    if item_index < num_files:
                        pending_file_key, details = pending_files_items[item_index]
                        pending_file_key_safe = pending_file_key.replace('.', '_').replace(' ', '_').replace('-', '_')
                        
                        with cols[j]: # åœ¨å½“å‰åˆ—ä¸­æ¸²æŸ“
                            st.markdown(f"**{pending_file_key}**") # æ˜¾ç¤ºæ–‡ä»¶å
                            if details.get('error'):
                                st.error(f"åŠ è½½é”™è¯¯: {details['error']}")
                            elif details.get('df_preview') is not None:
                                st.dataframe(details['df_preview']) # Show full DataFrame
                                st.caption(f"åŸå§‹æ–‡ä»¶å: {details.get('original_filename', 'N/A')}, å·¥ä½œè¡¨: {details.get('sheet_name', 'N/A') if details.get('sheet_name') else ' (å•CSVæ–‡ä»¶)'}")
                                
                                if st.button(f"æ·»åŠ åˆ°æš‚å­˜åŒº", key=f"add_to_staged_dc_{pending_file_key_safe}", help="å°†æ­¤æ–‡ä»¶å¤„ç†åæ·»åŠ åˆ°å…¨å±€æš‚å­˜æ•°æ®ä¸­"):
                                    success_add, message_add = add_pending_file_to_staged_data(st.session_state, pending_file_key, details)
                                    if success_add:
                                        st.success(message_add)
                                        st.rerun()
                                    else:
                                        st.error(message_add)
                            else:
                                st.warning("æ²¡æœ‰å¯ç”¨çš„æ•°æ®é¢„è§ˆã€‚")
               

    # --- æ¨¡å—äºŒ: æ¯”è¾ƒæš‚å­˜åŒºæ•°æ® ---
    with st.container():
        st.markdown("--- ")
        st.subheader("æ•°æ®é›†å†…å˜é‡æ¯”è¾ƒ")

        left_col, right_col = st.columns([1, 1]) # Or specify width ratios e.g. [2, 3]

        with left_col:
            st.markdown("##### **å‚æ•°é…ç½®**")
            staged_data = st.session_state.get('staged_data', {})

            if not staged_data:
                st.info("æš‚å­˜åŒºç›®å‰æ²¡æœ‰å¯ä¾›æ¯”è¾ƒçš„æ•°æ®ã€‚è¯·å…ˆåœ¨æ¨¡å—ä¸€ä¸Šä¼ å¹¶æ·»åŠ åˆ°æš‚å­˜åŒºã€‚")
            else:
                dataset_options = list(staged_data.keys())
                current_selected_dataset_key = st.session_state.get('dc_m2_selected_dataset_key')
                if current_selected_dataset_key not in dataset_options:
                    current_selected_dataset_key = None 
                
                selected_dataset_key = st.selectbox(
                    "1. é€‰æ‹©è¦åˆ†æçš„æ•°æ®é›†ï¼š",
                    options=[None] + dataset_options, 
                    format_func=lambda x: "è¯·é€‰æ‹©ä¸€ä¸ªæ•°æ®é›†" if x is None else x,
                    index=0 if current_selected_dataset_key is None else ([None] + dataset_options).index(current_selected_dataset_key),
                    key='dc_m2_selectbox_dataset'
                )

                if selected_dataset_key != st.session_state.get('dc_m2_selected_dataset_key'):
                    st.session_state['dc_m2_selected_dataset_key'] = selected_dataset_key
                    st.session_state['dc_m2_selected_variables'] = [] 
                    st.session_state['dc_m2_comparison_results'] = None 
                    # Consider st.rerun() if immediate feedback in right_col is needed upon dataset change
                    # For now, let button trigger comparison and result display

                if st.session_state['dc_m2_selected_dataset_key']:
                    selected_dataset_name = st.session_state['dc_m2_selected_dataset_key']
                    dataset_details = staged_data.get(selected_dataset_name)
                    
                    if dataset_details and 'df' in dataset_details:
                        df_selected = dataset_details['df']
                        available_variables = list(df_selected.columns)
                        
                        current_selected_vars = st.session_state.get('dc_m2_selected_variables', [])
                        valid_current_selected_vars = [var for var in current_selected_vars if var in available_variables]
                        
                        selected_variables = st.multiselect(
                            f"2. ä» '{selected_dataset_name}' é€‰æ‹©å˜é‡ï¼š",
                            options=available_variables,
                            default=valid_current_selected_vars,
                            key='dc_m2_multiselect_variables',
                            help="é€‰æ‹©è‡³å°‘ä¸¤ä¸ªå˜é‡ã€‚ç¬¬ä¸€ä¸ªä¸ºåŸºå‡†ï¼Œå…¶ä½™ä¸ºæ¯”è¾ƒå¯¹è±¡ã€‚"
                        )
                        st.session_state['dc_m2_selected_variables'] = selected_variables

                        if len(selected_variables) >= 2:
                            base_var = selected_variables[0]
                            compare_vars = selected_variables[1:]
                            
                            if st.button(f"æ¯”è¾ƒå˜é‡ (åŸºå‡†: {base_var})", key="dc_m2_start_comparison_button"):
                                if not BACKEND_FUNCTIONS_AVAILABLE or not hasattr(compare_variables_in_dataset, '__call__'):
                                    st.error("é”™è¯¯ï¼šå˜é‡æ¯”è¾ƒåŠŸèƒ½æ‰€éœ€çš„æ ¸å¿ƒå‡½æ•°æœªèƒ½åŠ è½½ã€‚")
                                    st.session_state['dc_m2_comparison_results'] = None
                                else:
                                    with st.spinner("æ­£åœ¨æ¯”è¾ƒå˜é‡ï¼Œè¯·ç¨å€™..."):
                                        comparison_output = compare_variables_in_dataset(df_selected, base_var, compare_vars)
                                    st.session_state['dc_m2_comparison_results'] = comparison_output
                                    # st.rerun() # Usually not needed as Streamlit reruns on widget interaction / state change that affects layout
                        
                        elif selected_variables:
                            st.info("è¯·è‡³å°‘é€‰æ‹©ä¸¤ä¸ªå˜é‡è¿›è¡Œæ¯”è¾ƒã€‚")
                        else:
                            st.info("è¯·é€‰æ‹©å˜é‡ä»¥è¿›è¡Œæ¯”è¾ƒã€‚")
                    else:
                        st.warning(f"æ— æ³•åŠ è½½æ•°æ®é›† '{selected_dataset_name}' çš„è¯¦ç»†ä¿¡æ¯æˆ–æ•°æ®ã€‚")
                        st.session_state['dc_m2_comparison_results'] = None 
                elif selected_dataset_key is None and dataset_options: 
                     st.info("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ•°æ®é›†ä»¥æ˜¾ç¤ºå…¶å¯ç”¨å˜é‡ã€‚")
                     st.session_state['dc_m2_comparison_results'] = None 

        with right_col:
            st.markdown("##### **æ¯”è¾ƒç»“æœ**")
            if st.session_state.get('dc_m2_selected_dataset_key') and st.session_state.get('dc_m2_selected_variables'):
                if st.session_state.get('dc_m2_comparison_results'):
                    results_data = st.session_state['dc_m2_comparison_results']
                    selected_variables_for_display = st.session_state.get('dc_m2_selected_variables', []) # Get current selected vars for display
                    base_variable_for_display = selected_variables_for_display[0] if selected_variables_for_display else "N/A"

                    if "_error_base_variable" in results_data:
                        st.error(results_data["_error_base_variable"]['message'])
                    else:
                        if not results_data: # Check if results_data itself is empty (e.g. no comparison_vars provided)
                            st.info("æ²¡æœ‰è¿›è¡Œä»»ä½•æ¯”è¾ƒï¼Œæˆ–è€…æ¯”è¾ƒå˜é‡åˆ—è¡¨ä¸ºç©ºã€‚")
                        else:
                            for comp_var, result_detail in results_data.items():
                                status = result_detail.get('status', 'æœªçŸ¥çŠ¶æ€')
                                message = result_detail.get('message', 'æ— è¯¦ç»†ä¿¡æ¯ã€‚')
                                differences_df = result_detail.get('differences_df')

                                expander_title = f"{comp_var} vs {base_variable_for_display}: {status}"
                                if status == "å®Œå…¨ç›¸åŒ":
                                    expander_title = f"âœ… {expander_title}"
                                elif status == "å­˜åœ¨å·®å¼‚":
                                    expander_title = f"âš ï¸ {expander_title}"
                                elif status == "é”™è¯¯":
                                    expander_title = f"âŒ {expander_title}"
                                else:
                                    expander_title = f"â„¹ï¸ {expander_title}"

                                with st.expander(expander_title, expanded=True if status == "å­˜åœ¨å·®å¼‚" else False):
                                    st.markdown(f"**{status}**: {message}")
                                    if status == "å­˜åœ¨å·®å¼‚":
                                        if differences_df is not None and not differences_df.empty:
                                            st.dataframe(differences_df, use_container_width=True)
                                        elif differences_df is not None and differences_df.empty:
                                            st.info("å·®å¼‚åˆ†æè¡¨ä¸ºç©ºï¼Œä½†å˜é‡ä¸å®Œå…¨ç›¸åŒï¼ˆå¯èƒ½ç”±äºç±»å‹æˆ–ç‰¹æ®Šå€¼å·®å¼‚ï¼‰ã€‚")
                elif st.session_state.get('dc_m2_selected_dataset_key') and len(st.session_state.get('dc_m2_selected_variables', [])) >=2 :
                    st.info("å‚æ•°å·²é€‰æ‹©ï¼Œè¯·ç‚¹å‡»å·¦ä¾§â€œæ¯”è¾ƒå˜é‡â€æŒ‰é’®å¼€å§‹åˆ†æã€‚")
                else:
                    st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©æ•°æ®é›†å’Œè‡³å°‘ä¸¤ä¸ªå˜é‡ä»¥è¿›è¡Œæ¯”è¾ƒã€‚")
            else:
                st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©æ•°æ®é›†å’Œå˜é‡ã€‚")


    # --- æ¨¡å—ä¸‰: æ¯”è¾ƒæ•°æ®é›†å…±åŒå˜é‡ ---
    with st.container():
        st.markdown("--- ")
        st.subheader("æ•°æ®é›†é—´å˜é‡æ¯”è¾ƒä¸æ›´æ–°")

        left_col_m3, right_col_m3 = st.columns([1, 1])

        with left_col_m3:
            st.markdown("##### **å‚æ•°é…ç½®**")
            staged_data = st.session_state.get('staged_data', {})

            if not staged_data or len(staged_data) < 2:
                st.info("æš‚å­˜åŒºä¸­éœ€è¦è‡³å°‘æœ‰ä¸¤ä¸ªæ•°æ®é›†æ‰èƒ½è¿›è¡Œæ¯”è¾ƒã€‚è¯·å…ˆåœ¨æ¨¡å—ä¸€ä¸Šä¼ å¹¶æ·»åŠ è‡³å°‘ä¸¤ä¸ªæ•°æ®é›†åˆ°æš‚å­˜åŒºã€‚")
            else:
                dataset_options_m3 = list(staged_data.keys())
                
                # Ensure current selections are valid
                current_selected_datasets_m3 = st.session_state.get('dc_m3_selected_datasets', [])
                valid_current_selected_datasets_m3 = [ds for ds in current_selected_datasets_m3 if ds in dataset_options_m3]
                if len(valid_current_selected_datasets_m3) != len(current_selected_datasets_m3):
                    st.session_state['dc_m3_selected_datasets'] = valid_current_selected_datasets_m3
                    st.session_state['dc_m3_comparison_results'] = None # Reset results if selection changed due to invalidation

                selected_datasets_m3 = st.multiselect(
                    "1. é€‰æ‹©è¦æ¯”è¾ƒçš„æ•°æ®é›†ï¼ˆè‡³å°‘ä¸¤ä¸ªï¼‰ï¼š",
                    options=dataset_options_m3,
                    default=valid_current_selected_datasets_m3,
                    key='dc_m3_multiselect_datasets'
                )
                st.session_state['dc_m3_selected_datasets'] = selected_datasets_m3

                if len(selected_datasets_m3) >= 2:
                    if st.button("æ¯”è¾ƒé€‰å®šæ•°æ®é›†çš„å…±åŒå˜é‡", key="dc_m3_start_comparison_button"):
                        # Clear any previous update report when starting a new comparison
                        st.session_state['dc_m3_update_execution_report'] = None 

                        if not BACKEND_FUNCTIONS_AVAILABLE or not hasattr(compare_datasets_for_common_variables, '__call__'):
                            st.error("é”™è¯¯ï¼šæ•°æ®é›†æ¯”è¾ƒåŠŸèƒ½æ‰€éœ€çš„æ ¸å¿ƒå‡½æ•°æœªèƒ½åŠ è½½ã€‚")
                            st.session_state['dc_m3_comparison_results'] = None
                        else:
                            datasets_to_compare_data = {name: staged_data[name]['df'] for name in selected_datasets_m3 if name in staged_data and 'df' in staged_data[name]}
                            if len(datasets_to_compare_data) == len(selected_datasets_m3):
                                with st.spinner("æ­£åœ¨æ¯”è¾ƒæ•°æ®é›†ï¼Œè¯·ç¨å€™..."):
                                    comparison_output_m3 = compare_datasets_for_common_variables(datasets_to_compare_data)
                                st.session_state['dc_m3_comparison_results'] = comparison_output_m3
                            else:
                                st.error("éƒ¨åˆ†é€‰å®šæ•°æ®é›†æ— æ³•åŠ è½½æ•°æ®ï¼Œè¯·æ£€æŸ¥æš‚å­˜åŒºã€‚")
                                st.session_state['dc_m3_comparison_results'] = None
                    
                    # --- BEGIN: Variable Value Update Tool (Moved to left column) ---
                    results_m3_for_update_tool = st.session_state.get('dc_m3_comparison_results') # Use a distinct name if needed or reuse if context is clear
                    common_vars_list_for_update = results_m3_for_update_tool.get('common_variables', []) if results_m3_for_update_tool else []

                    if len(selected_datasets_m3) == 2 and results_m3_for_update_tool and results_m3_for_update_tool.get('status') == 'success' and common_vars_list_for_update:
                       
                        st.markdown("##### **å˜é‡å€¼æ›´æ–°**")
                        staged_data_for_update = st.session_state.get('staged_data', {})
                        ds1_name_for_update, ds2_name_for_update = selected_datasets_m3[0], selected_datasets_m3[1]
                        
                        if ds1_name_for_update in staged_data_for_update and ds2_name_for_update in staged_data_for_update:
                            df1_for_update = staged_data_for_update[ds1_name_for_update].get('df')
                            df2_for_update = staged_data_for_update[ds2_name_for_update].get('df')

                            if isinstance(df1_for_update, pd.DataFrame) and isinstance(df2_for_update, pd.DataFrame):
                                st.info(f"å½“å‰æ¯”è¾ƒçš„æ•°æ®é›†: **{ds1_name_for_update}** å’Œ **{ds2_name_for_update}**")
                                update_var_key_suffix = f"left_col_{ds1_name_for_update}_{ds2_name_for_update}"
                                
                                selected_update_var = st.selectbox(
                                    "1. é€‰æ‹©è¦æ“ä½œçš„å…±åŒå˜é‡ï¼š", 
                                    options=[None] + common_vars_list_for_update,
                                    format_func=lambda x: "è¯·é€‰æ‹©å˜é‡" if x is None else x,
                                    key=f'dc_m3_update_var_select_{update_var_key_suffix}'
                                )

                                if selected_update_var:
                                    if selected_update_var not in df1_for_update.columns or selected_update_var not in df2_for_update.columns:
                                        st.error(f"å˜é‡ '{selected_update_var}' åœ¨å…¶ä¸­ä¸€ä¸ªæ•°æ®é›†ä¸­æœªæ‰¾åˆ°ã€‚è¯·é‡æ–°è¿è¡Œæ¯”è¾ƒã€‚")
                                    else:
                                        dataset_choices = [ds1_name_for_update, ds2_name_for_update]
                                        source_dataset_update = st.selectbox(
                                            "2. é€‰æ‹©æºæ•°æ®é›† (æä¾›æ–°å€¼)ï¼š",
                                            options=dataset_choices,
                                            key=f'dc_m3_source_ds_select_{update_var_key_suffix}'
                                        )
                                        target_dataset_update = st.selectbox(
                                            "3. é€‰æ‹©ç›®æ ‡æ•°æ®é›† (è¢«æ›´æ–°)ï¼š",
                                            options=dataset_choices,
                                            index=1 if source_dataset_update == dataset_choices[0] else 0, 
                                            key=f'dc_m3_target_ds_select_{update_var_key_suffix}'
                                        )

                                        if source_dataset_update == target_dataset_update:
                                            st.warning("æºæ•°æ®é›†å’Œç›®æ ‡æ•°æ®é›†ä¸èƒ½ç›¸åŒã€‚")
                                        else:
                                            update_mode = st.radio(
                                                "4. é€‰æ‹©æ›´æ–°æ¨¡å¼ï¼š",
                                                options=[
                                                    ('fill_missing', f"ç”¨'{source_dataset_update}'çš„'{selected_update_var}'å¡«è¡¥'{target_dataset_update}'çš„ç¼ºå¤±"),
                                                    ('replace_all', f"ç”¨'{source_dataset_update}'çš„'{selected_update_var}'æ›¿æ¢'{target_dataset_update}'çš„å…¨éƒ¨å€¼"),
                                                    ('replace_specific_dates', f"ç”¨'{source_dataset_update}'çš„'{selected_update_var}'æ›¿æ¢'{target_dataset_update}'çš„ç‰¹å®šæ—¥æœŸå€¼")
                                                ],
                                                format_func=lambda x: x[1],
                                                key=f'dc_m3_update_mode_radio_{update_var_key_suffix}'
                                            )[0]

                                            specific_dates_to_update = []
                                            if update_mode == 'replace_specific_dates':
                                                try:
                                                    common_indices = df1_for_update.index.intersection(df2_for_update.index)
                                                    date_options_for_multiselect = sorted([str(idx.date()) if isinstance(idx, pd.Timestamp) else str(idx) for idx in common_indices])
                                                    if not date_options_for_multiselect:
                                                        st.info("æºå’Œç›®æ ‡æ•°æ®é›†é—´æ— å…±åŒæ—¥æœŸå¯é€‰ã€‚")
                                                    else:
                                                        specific_dates_to_update_str = st.multiselect(
                                                            "5. é€‰æ‹©è¦æ›´æ–°çš„æ—¥æœŸï¼š",
                                                            options=date_options_for_multiselect,
                                                            key=f'dc_m3_specific_dates_multiselect_{update_var_key_suffix}'
                                                        )
                                                        if specific_dates_to_update_str:
                                                            specific_dates_to_update = pd.to_datetime(specific_dates_to_update_str).tolist()
                                                except Exception as e_idx:
                                                    st.error(f"è·å–æ—¥æœŸé€‰é¡¹æ—¶å‡ºé”™: {e_idx}")
                                            
                                            if st.button("æ‰§è¡Œæ›´æ–°", key=f'dc_m3_execute_update_button_{update_var_key_suffix}'):
                                                if update_mode == 'replace_specific_dates' and not specific_dates_to_update:
                                                    st.error("é€‰æ‹©äº†æŒ‰æ—¥æœŸæ›¿æ¢æ¨¡å¼ï¼Œä½†æœªé€‰æ‹©ä»»ä½•æ—¥æœŸã€‚")
                                                else:
                                                    with st.spinner("æ­£åœ¨æ›´æ–°æ•°æ®..."):
                                                        success_update, msg_update, changes_df = update_variable_in_staged_data(
                                                            session_state=st.session_state, 
                                                            target_dataset_name=target_dataset_update, 
                                                            source_dataset_name=source_dataset_update, 
                                                            variable_name=selected_update_var, 
                                                            update_mode=update_mode, 
                                                            specific_dates=specific_dates_to_update
                                                        )
                                                    # Store report in session state instead of immediate display
                                                    st.session_state['dc_m3_update_execution_report'] = (success_update, msg_update, changes_df)
                                                    
                                                    # DO NOT RERUN OR CLEAR COMPARISON RESULTS HERE
                        # No 'else' needed for the df isinstance check, as it's handled by lack of UI elements.
                    # --- END: Variable Value Update Tool ---

                elif selected_datasets_m3: # i.e., len is 1
                    st.info("è¯·è‡³å°‘é€‰æ‹©ä¸¤ä¸ªæ•°æ®é›†è¿›è¡Œæ¯”è¾ƒã€‚")
                else: # No datasets selected
                    st.info("è¯·é€‰æ‹©æ•°æ®é›†ä»¥è¿›è¡Œæ¯”è¾ƒã€‚")
                    if st.session_state.get('dc_m3_comparison_results') is not None:
                         st.session_state['dc_m3_comparison_results'] = None # Clear previous results if selection becomes insufficient
        with right_col_m3:
            st.markdown("##### **æ¯”è¾ƒç»“æœ**")
            results_m3 = st.session_state.get('dc_m3_comparison_results')

            if results_m3:
                status = results_m3.get('status', 'error')
                message = results_m3.get('message', 'è·å–æ¯”è¾ƒç»“æœæ—¶å‡ºé”™ã€‚')
                common_vars = results_m3.get('common_variables')
                vars_per_dataset = results_m3.get('variables_per_dataset')
                compared_datasets_names = results_m3.get('compared_datasets', [])
                value_comp_results = results_m3.get('value_comparison_results') # <-- Get new results

                expander_title_m3 = f"æ•°æ®é›†æ¯”è¾ƒæ‘˜è¦ ({len(compared_datasets_names)}ä¸ªæ•°æ®é›†): {message}"
                icon_m3 = "âœ…" if status == "success" and common_vars else ("â„¹ï¸" if status == "success" else "âš ï¸")
                if status == "error" or status == "no_datasets" or status == "insufficient_datasets":
                    icon_m3 = "âŒ"
                
                with st.expander(f"{icon_m3} {expander_title_m3}", expanded=True):
                    if status == "success":
                        if common_vars:
                            st.write("**å…±åŒå˜é‡åˆ—è¡¨ï¼š**")
                            st.code('\n'.join(common_vars), language='text')
                        else:
                            st.info("æœªåœ¨é€‰å®šæ•°æ®é›†ä¸­æ‰¾åˆ°ä»»ä½•å…±åŒå˜é‡ã€‚")
                    else:
                        st.error(f"æ¯”è¾ƒå¤±è´¥: {message}")
                
                # --- Expander for Value Comparison Results ---
                if status == "success" and common_vars and value_comp_results is not None:
                    # This expander is now OUTSIDE the one above, if you want it separate
                    # Or, if it should be inside the success case of the above, move it up.
                    # For now, keeping it separate as requested by "å¦èµ·ä¸€ä¸ªexpander"
                    with st.expander("å…±åŒå˜é‡å–å€¼ä¸€è‡´æ€§æ£€æŸ¥", expanded=True):
                        comparison_summaries = value_comp_results
                        if not comparison_summaries:
                            st.info("æ²¡æœ‰å…±åŒå˜é‡å¯ä¾›è¿›è¡Œå–å€¼æ¯”è¾ƒæˆ–æœªèƒ½ç”Ÿæˆæ¯”è¾ƒç»“æœã€‚")
                        else:
                            # Categorize variables
                            original_length_mismatches = []
                            post_dropna_length_mismatches = [] # Original lengths were same
                            value_mismatches = [] # Original and post-dropna lengths were same
                            type_mismatches = []
                            comparison_errors = []
                            identical_variables = []

                            for var_name, comp_detail in comparison_summaries.items():
                                comp_type = comp_detail.get('type')
                                comp_status = comp_detail.get('status')

                                if comp_type == 'original_length_mismatch':
                                    original_length_mismatches.append((var_name, comp_detail))
                                elif comp_type == 'type_mismatch':
                                    type_mismatches.append((var_name, comp_detail))
                                elif comp_type == 'exception_during_comparison' or comp_status == 'error': # Catch generic errors too
                                    comparison_errors.append((var_name, comp_detail))
                                elif comp_type == 'length_mismatch': # Post-dropna length mismatch
                                    post_dropna_length_mismatches.append((var_name, comp_detail))
                                elif comp_type == 'different_values':
                                    value_mismatches.append((var_name, comp_detail))
                                elif comp_type == 'identical' and comp_status == 'success':
                                    identical_variables.append((var_name, comp_detail))
                                else: # Fallback for any other unhandled cases
                                    # If comp_detail itself is None or not a dict, it would error earlier.
                                    # This handles cases where comp_type or comp_status is unexpected.
                                    unknown_detail = {'status': 'error', 'type': 'unknown_frontend_categorization', 'message': f"å‰ç«¯åˆ†ç±»æœªçŸ¥ï¼šç±»å‹='{comp_type}', çŠ¶æ€='{comp_status}'.åŸå§‹æ¶ˆæ¯: {comp_detail.get('message', 'N/A')}"}
                                    comparison_errors.append((var_name, unknown_detail))

                            # Display aggregated original index discrepancies
                            aggregated_original_discrepancies = results_m3.get('aggregated_original_index_discrepancies', [])
                            if aggregated_original_discrepancies:
                                st.write("**åŸå§‹ç´¢å¼•ï¼ˆæ—¥æœŸï¼‰ä¸ä¸€è‡´çš„æ•°æ®é›†å¯¹**")
                                for discrepancy in aggregated_original_discrepancies:
                                    ds1_name = discrepancy.get('dataset1_name', 'æ•°æ®é›†1')
                                    ds2_name = discrepancy.get('dataset2_name', 'æ•°æ®é›†2')
                                    ds1_unique_orig_str_list = discrepancy.get('dataset1_unique_indices_original', []) # Already strings YYYY-MM-DD
                                    ds2_unique_orig_str_list = discrepancy.get('dataset2_unique_indices_original', []) # Already strings YYYY-MM-DD
                                    
                                    ds1_part = f"{ds1_name}ç‹¬æœ‰æ—¶é—´ {', '.join(ds1_unique_orig_str_list) if ds1_unique_orig_str_list else 'æ— '}"
                                    ds2_part = f"{ds2_name}ç‹¬æœ‰æ—¶é—´ {', '.join(ds2_unique_orig_str_list) if ds2_unique_orig_str_list else 'æ— '}"
                                    
                                    st.info(f"{ds1_name} vs {ds2_name}ï¼š{ds1_part}ï¼›{ds2_part}")

                                st.markdown("---") # Separator after this section
                # --- End of Value Comparison Expander ---

                # --- Expander for Same Values, Different Names Analysis ---
                same_value_diff_names_results = results_m3.get('same_value_different_names_analysis')
                if status == "success" and same_value_diff_names_results is not None: # Ensure results exist
                    with st.expander("åç§°ä¸åŒä½†å–å€¼ç›¸åŒçš„å˜é‡ç»„", expanded=False): # Default to collapsed
                        if not same_value_diff_names_results: # Check if the list is empty
                            st.info("æœªæ‰¾åˆ°åç§°ä¸åŒä½†å–å€¼ç›¸åŒçš„å˜é‡ç»„ã€‚")
                        else:
                            for idx, group in enumerate(same_value_diff_names_results):
                                st.markdown(f"**ç»„ {idx + 1}**")
                                members = group.get('members', [])
                                preview = group.get('preview', {})
                                
                                if members:
                                    for member in members:
                                        st.markdown(f"  - æ•°æ®é›†: `{member['dataset_name']}`, å˜é‡å: `{member['variable_name']}`")
                                
                                if preview:
                                    length = preview.get('length', 'N/A')
                                    dtype = preview.get('dtype', 'N/A')
                                    st.markdown(f"  - é•¿åº¦: {length}, ç±»å‹: `{dtype}`")
                                st.markdown(" ") # Add a bit of space between groups
                # --- End of Same Values, Different Names Analysis Expander ---

                # --- BEGIN: Display Area for Update Execution Report (in right_col_m3) ---
                update_report = st.session_state.get('dc_m3_update_execution_report')
                if update_report:
                    st.markdown("##### **å˜é‡æ›´æ–°æ‰§è¡Œç»“æœ**")
                    success_update, msg_update, changes_df = update_report
                    if success_update:
                        st.success(msg_update)
                        if changes_df is not None and not changes_df.empty:
                            st.markdown("**å…·ä½“å˜æ›´è¯¦æƒ…ï¼š**")
                            st.dataframe(changes_df, use_container_width=True)
                        elif changes_df is not None and changes_df.empty:
                            # msg_update from backend should already cover this, but can add more info if needed
                            st.info("æ ¹æ®æ‰§è¡Œç»“æœï¼Œæ“ä½œå·²å®Œæˆä½†æœªå¯¹æ•°æ®å€¼è¿›è¡Œå®é™…æ›´æ”¹ã€‚") 
                    else:
                        st.error(msg_update)
                # --- END: Display Area for Update Execution Report ---

            elif st.session_state.get('dc_m3_selected_datasets') and len(st.session_state.get('dc_m3_selected_datasets',[])) >= 2:
                st.info("å‚æ•°å·²é€‰æ‹©ï¼Œè¯·ç‚¹å‡»å·¦ä¾§â€œæ¯”è¾ƒé€‰å®šæ•°æ®é›†çš„å…±åŒå˜é‡â€æŒ‰é’®å¼€å§‹åˆ†æã€‚")
            else:
                st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©è‡³å°‘ä¸¤ä¸ªæ•°æ®é›†ä»¥è¿›è¡Œæ¯”è¾ƒã€‚")

    # --- æ¨¡å—å››: æ•°æ®æš‚å­˜ä¸å¯¼å‡º --- (New Module)
    with st.container():
        st.markdown("--- ") # Visual separator
        st.subheader("ğŸ’¾ æ•°æ®æš‚å­˜ä¸å¯¼å‡º")

        staged_data_keys = list(st.session_state.get('staged_data', {}).keys())

        if not staged_data_keys:
            st.info("æš‚å­˜åŒºä¸ºç©ºã€‚è¯·å…ˆé€šè¿‡æ¨¡å—ä¸€ä¸Šä¼ æˆ–åœ¨ä¸Šæ–¹æ¨¡å—æ“ä½œæ•°æ®ã€‚")
        else:
            col1_m4, col2_m4 = st.columns(2)

            with col1_m4:
                st.markdown("##### **1. åœ¨æš‚å­˜åŒºåˆ›å»ºæ•°æ®é›†å‰¯æœ¬**")
                source_ds_for_copy = st.selectbox(
                    "é€‰æ‹©æºæ•°æ®é›†ï¼š", 
                    options=[None] + staged_data_keys,
                    format_func=lambda x: "è¯·é€‰æ‹©" if x is None else x, 
                    key="m4_source_ds_copy"
                )
                new_copy_name = st.text_input("è¾“å…¥å‰¯æœ¬çš„æ–°åç§°ï¼š", key="m4_new_copy_name")

                if st.button("åˆ›å»ºå‰¯æœ¬", key="m4_create_copy_button"):
                    if not source_ds_for_copy:
                        st.error("è¯·é€‰æ‹©ä¸€ä¸ªæºæ•°æ®é›†ã€‚")
                    elif not new_copy_name.strip():
                        st.error("å‰¯æœ¬åç§°ä¸èƒ½ä¸ºç©ºã€‚")
                    else:
                        if not BACKEND_FUNCTIONS_AVAILABLE or not hasattr(make_staged_data_copy, '__call__'):
                            st.error("é”™è¯¯ï¼šåˆ›å»ºå‰¯æœ¬åŠŸèƒ½æ‰€éœ€çš„æ ¸å¿ƒå‡½æ•°æœªèƒ½åŠ è½½ã€‚")
                        else:
                            success_copy, msg_copy = make_staged_data_copy(st.session_state, source_ds_for_copy, new_copy_name.strip())
                            if success_copy:
                                st.success(msg_copy)
                                # Update staged_data_keys for subsequent widgets if needed immediately
                                # This might require a rerun or careful state management if UI elements depend on it right after.
                                st.rerun() # Rerun to refresh selectbox options with new dataset
                            else:
                                st.error(msg_copy)
            
            with col2_m4:
                st.markdown("##### **2. å¯¼å‡ºæ•°æ®é›†**")
                datasets_to_export = st.multiselect(
                    "é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®é›†ï¼š", 
                    options=staged_data_keys, 
                    key="m4_datasets_to_export"
                )
                export_format = st.radio("é€‰æ‹©å¯¼å‡ºæ ¼å¼ï¼š", options=['CSV', 'Excel'], key="m4_export_format", horizontal=True)

                # Placeholder for advanced Excel options
                # excel_multi_sheet = False
                # if export_format == 'Excel' and datasets_to_export and len(datasets_to_export) > 1:
                #     excel_multi_sheet = st.checkbox("å°†å¤šä¸ªæ•°æ®é›†å¯¼å‡ºåˆ°åŒä¸€ä¸ªExcelæ–‡ä»¶çš„ä¸åŒå·¥ä½œè¡¨", value=True, key="m4_excel_multi_sheet")

                if datasets_to_export:
                    if export_format == 'CSV':
                        if len(datasets_to_export) == 1:
                            ds_name_csv = datasets_to_export[0]
                            df_to_export_csv = st.session_state['staged_data'][ds_name_csv].get('df')
                            if isinstance(df_to_export_csv, pd.DataFrame):
                                csv_data = df_to_export_csv.to_csv(index=True).encode('utf-8-sig') # utf-8-sig for Excel compatibility with BOM
                                st.download_button(
                                    label=f"ä¸‹è½½ {ds_name_csv}.csv",
                                    data=csv_data,
                                    file_name=f"{ds_name_csv}.csv",
                                    mime='text/csv',
                                    key=f"m4_download_csv_{ds_name_csv}"
                                )
                            else:
                                st.warning(f"æ•°æ®é›† '{ds_name_csv}' ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®è¡¨å¯å¯¼å‡ºã€‚")
                        else: # Multiple CSVs - need to zip them
                            st.info("å¯¼å‡ºå¤šä¸ªCSVæ–‡ä»¶å°†æ‰“åŒ…ä¸ºZIPã€‚æ­¤åŠŸèƒ½å¾…å®ç°ã€‚") 
                            # TODO: Implement ZIP export for multiple CSVs
                    
                    elif export_format == 'Excel':
                        if len(datasets_to_export) == 1:
                            ds_name_excel = datasets_to_export[0]
                            df_to_export_excel = st.session_state['staged_data'][ds_name_excel].get('df')
                            if isinstance(df_to_export_excel, pd.DataFrame):
                                from io import BytesIO
                                excel_buffer = BytesIO()
                                with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                    df_to_export_excel.to_excel(writer, sheet_name=ds_name_excel[:31], index=True) # Sheet name limit 31 chars
                                excel_data = excel_buffer.getvalue()
                                st.download_button(
                                    label=f"ä¸‹è½½ {ds_name_excel}.xlsx",
                                    data=excel_data,
                                    file_name=f"{ds_name_excel}.xlsx",
                                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                                    key=f"m4_download_excel_{ds_name_excel}"
                                )
                            else:
                                st.warning(f"æ•°æ®é›† '{ds_name_excel}' ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®è¡¨å¯å¯¼å‡ºã€‚")
                        else: # Multiple datasets for Excel
                            st.info("å¯¼å‡ºå¤šä¸ªæ•°æ®é›†åˆ°Excelï¼ˆå•æ–‡ä»¶å¤šå·¥ä½œè¡¨æˆ–å¤šæ–‡ä»¶ï¼‰åŠŸèƒ½å¾…å®ç°ã€‚")
                            # TODO: Implement multi-sheet or multi-file Excel export
                else:
                    st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ•°æ®é›†è¿›è¡Œå¯¼å‡ºã€‚")

if __name__ == '__main__':
    st.set_page_config(layout="wide", page_title="æ•°æ®æ¯”è¾ƒæ¨¡å—æµ‹è¯•")
    if 'staged_data' not in st.session_state:
        st.session_state['staged_data'] = {}
    render_data_comparison_ui()
