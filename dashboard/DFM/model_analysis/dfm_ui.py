import streamlit as st
import pandas as pd
import logging # Keep logging for UI-side info/errors if needed
import plotly.graph_objects as go # <--- æ–°å¢ Plotly
import numpy as np
import joblib
import pickle

# --- æ–°å¢ï¼šå¯¼å…¥çŠ¶æ€ç®¡ç†å™¨ ---
try:
    from ...core.state_manager import StateManager
    from ...core.compat import CompatibilityAdapter
    from ...core.state_keys import StateKeys
    DFM_STATE_MANAGER_AVAILABLE = True
except ImportError:
    DFM_STATE_MANAGER_AVAILABLE = False
    print("[DFM UI] Warning: State manager not available, using legacy state management")


def get_dfm_state_manager_instance():
    """è·å–çŠ¶æ€ç®¡ç†å™¨å®ä¾‹ï¼ˆDFMæ¨¡å—ä¸“ç”¨ï¼‰"""
    if DFM_STATE_MANAGER_AVAILABLE and hasattr(st.session_state, 'state_manager_initialized'):
        try:
            state_manager = StateManager(st.session_state)
            compat_adapter = CompatibilityAdapter(st.session_state)
            return state_manager, compat_adapter
        except Exception as e:
            print(f"[DFM UI] Error getting state manager: {e}")
            return None, None
    return None, None


def get_dfm_state(key, default=None, session_state=None):
    """è·å–DFMçŠ¶æ€å€¼ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰"""
    state_manager, compat_adapter = get_dfm_state_manager_instance()
    
    if compat_adapter is not None:
        return compat_adapter.get_value(key, default)
    else:
        # å›é€€åˆ°ä¼ ç»Ÿæ–¹å¼
        if session_state is not None:
            return getattr(session_state, key, default) if hasattr(session_state, key) else session_state.get(key, default)
        else:
            return st.session_state.get(key, default)


def set_dfm_state(key, value, session_state=None):
    """è®¾ç½®DFMçŠ¶æ€å€¼ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰"""
    state_manager, compat_adapter = get_dfm_state_manager_instance()
    
    if compat_adapter is not None:
        compat_adapter.set_value(key, value, use_new_key=True)
    else:
        # å›é€€åˆ°ä¼ ç»Ÿæ–¹å¼
        if session_state is not None:
            if hasattr(session_state, key):
                setattr(session_state, key, value)
            else:
                session_state[key] = value
        else:
            st.session_state[key] = value
# --- ç»“æŸæ–°å¢ ---

from typing import Optional, Dict, Any
from datetime import datetime # <<< æ–°å¢å¯¼å…¥ for date input defaults
# --- æ–°å¢å¯¼å…¥ ---
import os # <<< æ–°å¢å¯¼å…¥ os

# å¯¼å…¥é…ç½®
try:
    from config import (
        DataDefaults, TrainDefaults, UIDefaults, VisualizationDefaults,
        FileDefaults, FormatDefaults, AnalysisDefaults
    )
    CONFIG_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ æ— æ³•å¯¼å…¥é…ç½®æ¨¡å—: {e}")
    CONFIG_AVAILABLE = False

# Import backend functions
# Note: Use absolute import to avoid relative import issues in standalone execution
try:
    from .dfm_backend import load_dfm_results_from_uploads
except ImportError:
    # Fallback for standalone execution
    from dfm_backend import load_dfm_results_from_uploads

logger = logging.getLogger(__name__)


def load_dfm_data(_session_state: Dict) -> tuple[Optional[Any], Optional[Dict]]:
    """ä» session_state åŠ è½½æ¨¡å‹ç»“æœå’Œå…ƒæ•°æ®ã€‚"""
    model_file = get_dfm_state('dfm_model_file_indep', None, _session_state)
    metadata_file = get_dfm_state('dfm_metadata_file_indep', None, _session_state)

    model_results = None
    metadata = None

    # å®‰å…¨åœ°æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ºæœ‰æ•ˆçš„æ–‡ä»¶å¯¹è±¡
    if model_file is not None:
        # ğŸ”¥ ä¿®å¤ï¼šå¢åŠ æ–‡ä»¶å¯¹è±¡ç±»å‹æ£€æŸ¥ï¼Œé¿å…å¯¹éæ–‡ä»¶å¯¹è±¡è°ƒç”¨seekæ–¹æ³•
        if hasattr(model_file, 'seek') and hasattr(model_file, 'read'):
            try:
                model_file.seek(0) # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                model_results = joblib.load(model_file)
                print("[DFM UI] Model loaded successfully from session state.")
            except Exception as e:
                file_name = getattr(model_file, 'name', 'æœªçŸ¥æ–‡ä»¶')
                st.error(f"åŠ è½½æ¨¡å‹æ–‡ä»¶ ('{file_name}') æ—¶å‡ºé”™: {e}")
        else:
            print(f"[DFM UI] æ£€æµ‹åˆ°æ— æ•ˆçš„æ¨¡å‹æ–‡ä»¶å¯¹è±¡ç±»å‹: {type(model_file)}")

    # å®‰å…¨åœ°æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ºæœ‰æ•ˆçš„æ–‡ä»¶å¯¹è±¡
    if metadata_file is not None:
        # ğŸ”¥ ä¿®å¤ï¼šå¢åŠ æ–‡ä»¶å¯¹è±¡ç±»å‹æ£€æŸ¥ï¼Œé¿å…å¯¹éæ–‡ä»¶å¯¹è±¡è°ƒç”¨seekæ–¹æ³•
        if hasattr(metadata_file, 'seek') and hasattr(metadata_file, 'read'):
            try:
                metadata_file.seek(0) # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                metadata = pickle.load(metadata_file)
                print("[DFM UI] Metadata loaded successfully from session state.")
            except Exception as e:
                file_name = getattr(metadata_file, 'name', 'æœªçŸ¥æ–‡ä»¶')
                st.error(f"åŠ è½½å…ƒæ•°æ®æ–‡ä»¶ ('{file_name}') æ—¶å‡ºé”™: {e}")
        else:
            print(f"[DFM UI] æ£€æµ‹åˆ°æ— æ•ˆçš„å…ƒæ•°æ®æ–‡ä»¶å¯¹è±¡ç±»å‹: {type(metadata_file)}")

    return model_results, metadata

# --- Helper Function to Plot Factor Evolution ---
def plot_factor_evolution(factor_df: pd.DataFrame, title: str = "å› å­æ—¶é—´åºåˆ—æ¼”å˜å›¾"):
    """ç»˜åˆ¶å› å­éšæ—¶é—´å˜åŒ–çš„æ›²çº¿å›¾ã€‚"""
    if not isinstance(factor_df, pd.DataFrame) or factor_df.empty:
        st.warning("å› å­æ•°æ®æ— æ•ˆï¼Œæ— æ³•ç»˜åˆ¶æ¼”å˜å›¾ã€‚")
        return
    
    fig = go.Figure()
    
    for col in factor_df.columns:
        fig.add_trace(go.Scatter(
            x=factor_df.index,
            y=factor_df[col],
            mode='lines',
            name=col,
            hovertemplate=(
                f"æ—¥æœŸ: %{{x}}<br>" +
                f"{col}: %{{y:.4f}}<extra></extra>"
            )
        ))

    fig.update_layout(
        title=title,
        xaxis_title="æ—¥æœŸ",
        yaxis_title="å› å­å€¼",
        legend_title_text='å› å­',
        hovermode='x unified',
        height=400,
        margin=dict(t=50, b=50, l=50, r=50)
    )

    st.plotly_chart(fig, use_container_width=True)

# --- Helper Function to Plot Loadings Heatmap (ä¿®æ”¹å) ---
def plot_loadings_heatmap(loadings_df: pd.DataFrame, title: str = "å› å­è½½è·çŸ©é˜µ (Lambda)", cluster_vars: bool = True):
    """
    ç»˜åˆ¶å› å­è½½è·çŸ©é˜µçš„çƒ­åŠ›å›¾ (å› å­åœ¨Xè½´, å˜é‡åœ¨Yè½´, å¯é€‰èšç±»)ã€‚

    Args:
        loadings_df: åŒ…å«å› å­è½½è·çš„ DataFrame (åŸå§‹å½¢å¼ï¼šå˜é‡ä¸ºè¡Œï¼Œå› å­ä¸ºåˆ—)ã€‚
        title: å›¾è¡¨æ ‡é¢˜ã€‚
        cluster_vars: æ˜¯å¦å¯¹å˜é‡è¿›è¡Œèšç±»æ’åºã€‚
    """
    if not isinstance(loadings_df, pd.DataFrame) or loadings_df.empty:
        st.warning(f"æ— æ³•ç»˜åˆ¶çƒ­åŠ›å›¾ï¼šæä¾›çš„è½½è·æ•°æ®æ— æ•ˆ ({title})ã€‚")
        return

    data_for_clustering = loadings_df.copy() # å˜é‡æ˜¯è¡Œ
    variable_names = data_for_clustering.index.tolist()
    factor_names = data_for_clustering.columns.tolist()

    # 1. (å¦‚æœéœ€è¦) å¯¹å˜é‡è¿›è¡Œèšç±»
    if cluster_vars:
        try:
            if data_for_clustering.shape[0] <= 1: # å¦‚æœåªæœ‰ä¸€ä¸ªå˜é‡ï¼Œæ— æ³•èšç±»
                 print("[DFM UI] åªæœ‰ä¸€ä¸ªå˜é‡ï¼Œè·³è¿‡èšç±»ã€‚")
            else:
                from scipy.cluster import hierarchy as sch
                linked = sch.linkage(data_for_clustering.values, method='ward', metric='euclidean')
                dendro = sch.dendrogram(linked, no_plot=True)
                clustered_indices = dendro['leaves']
                data_for_clustering = data_for_clustering.iloc[clustered_indices, :]
                variable_names = data_for_clustering.index.tolist() # è·å–èšç±»åçš„å˜é‡é¡ºåº
                title += " (å˜é‡èšç±»æ’åº)"
        except Exception as e_cluster:
            st.warning(f"å˜é‡èšç±»å¤±è´¥: {e_cluster}. å°†æŒ‰åŸå§‹é¡ºåºæ˜¾ç¤ºã€‚")
            # å¦‚æœèšç±»å¤±è´¥ï¼Œvariable_names ä¿æŒåŸå§‹é¡ºåº

    # 2. è½¬ç½®æ•°æ®ä»¥ä¾¿ç»˜å›¾ (å› å­åœ¨ X è½´, å˜é‡åœ¨ Y è½´)
    plot_data_transposed = data_for_clustering.T # è½¬ç½®åï¼šå› å­æ˜¯è¡Œï¼Œï¼ˆèšç±»åï¼‰å˜é‡æ˜¯åˆ—
    
    # ç¡®ä¿è½´æ ‡ç­¾åˆ—è¡¨æ˜¯æœ€æ–°çš„
    y_axis_labels = variable_names # èšç±»åçš„å˜é‡å
    x_axis_labels = factor_names   # åŸå§‹å› å­å

    # 3. åˆ›å»ºçƒ­åŠ›å›¾
    fig = go.Figure(data=go.Heatmap(
        z=plot_data_transposed.values, # ä½¿ç”¨è½¬ç½®åçš„æ•°æ®
        x=x_axis_labels,          # X è½´æ˜¯å› å­
        y=y_axis_labels,          # Y è½´æ˜¯å˜é‡ (æŒ‰èšç±»é¡ºåº)
        colorscale='RdBu',
        zmid=0,
        hovertemplate=(
            "å˜é‡ (Variable): %{y}<br>" +
            "å› å­ (Factor): %{x}<br>" +
            "è½½è·å€¼ (Loading): %{z:.4f}<extra></extra>"
        )
    ))

    # 4. æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title=title,
        xaxis_title="å› å­ (Factors)",
        yaxis_title="å˜é‡ (Predictors)",
        xaxis_tickangle=-45, 
        # Yè½´ä½¿ç”¨ç±»åˆ«ç±»å‹ï¼Œå¹¶ç›´æ¥æŒ‡å®šé¡ºåº
        yaxis=dict(
            type='category', 
            categoryorder='array', # æ˜ç¡®æŒ‡å®šä½¿ç”¨ä¸‹é¢æä¾›çš„æ•°ç»„é¡ºåº
            categoryarray=y_axis_labels # ç¡®ä¿Yè½´æŒ‰èšç±»é¡ºåºæ˜¾ç¤º
        ), 
        height=max(600, len(y_axis_labels) * 20), # è°ƒæ•´é«˜åº¦è®¡ç®—
        margin=dict(l=150, r=30, t=80, b=100) # <<< å‡å°å·¦å³è¾¹è·
    )
    
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')
    fig.update_xaxes(showgrid=False) 

    st.plotly_chart(fig, use_container_width=True)

def render_file_upload_section(st_instance, session_state):
    """
    æ¸²æŸ“æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    """
    # ğŸ”¥ æ–°å¢ï¼šæ¸…ç†æ— æ•ˆçš„æ–‡ä»¶çŠ¶æ€
    def cleanup_invalid_file_states():
        """æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ— æ•ˆæ–‡ä»¶çŠ¶æ€"""
        model_file = get_dfm_state('dfm_model_file_indep', None, session_state)
        metadata_file = get_dfm_state('dfm_metadata_file_indep', None, session_state)
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶çŠ¶æ€
        if model_file is not None:
            if not (hasattr(model_file, 'seek') and 
                   hasattr(model_file, 'read') and 
                   hasattr(model_file, 'name') and
                   getattr(model_file, 'name', 'æœªçŸ¥æ–‡ä»¶') != 'æœªçŸ¥æ–‡ä»¶'):
                set_dfm_state('dfm_model_file_indep', None, session_state)
        
        # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶çŠ¶æ€
        if metadata_file is not None:
            if not (hasattr(metadata_file, 'seek') and 
                   hasattr(metadata_file, 'read') and 
                   hasattr(metadata_file, 'name') and
                   getattr(metadata_file, 'name', 'æœªçŸ¥æ–‡ä»¶') != 'æœªçŸ¥æ–‡ä»¶'):
                set_dfm_state('dfm_metadata_file_indep', None, session_state)
    
    # æ‰§è¡ŒçŠ¶æ€æ¸…ç†
    cleanup_invalid_file_states()
    
    st_instance.markdown("##### ğŸ“ ä¸Šä¼ æ¨¡å‹æ–‡ä»¶")
    st_instance.markdown("è¯·ä¸Šä¼ è®­ç»ƒå®Œæˆçš„DFMæ¨¡å‹æ–‡ä»¶å’Œå…ƒæ•°æ®æ–‡ä»¶ä»¥è¿›è¡Œç»“æœåˆ†æã€‚")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col_model, col_metadata = st_instance.columns(2)
    
    with col_model:
        st_instance.markdown("**DFM æ¨¡å‹æ–‡ä»¶ (.joblib)**")
        uploaded_model_file = st_instance.file_uploader(
            "é€‰æ‹©æ¨¡å‹æ–‡ä»¶",
            type=['joblib'],
            key="dfm_model_upload_independent",
            help="ä¸Šä¼ è®­ç»ƒå¥½çš„DFMæ¨¡å‹æ–‡ä»¶ï¼Œé€šå¸¸ä¸º.joblibæ ¼å¼"
        )
        
        if uploaded_model_file:
            set_dfm_state("dfm_model_file_indep", uploaded_model_file, session_state)
            st_instance.success(f"âœ… å·²ä¸Šä¼ : {uploaded_model_file.name}")
        else:
            existing_model_file = get_dfm_state('dfm_model_file_indep', None, session_state)
            if existing_model_file is not None:
                # ğŸ”¥ ä¿®å¤ï¼šåªåœ¨æœ‰æ•ˆæ–‡ä»¶æ—¶æ˜¾ç¤ºæ–‡ä»¶å
                file_name = getattr(existing_model_file, 'name', 'æœªçŸ¥æ–‡ä»¶')
                if (hasattr(existing_model_file, 'seek') and 
                    hasattr(existing_model_file, 'read') and 
                    file_name != 'æœªçŸ¥æ–‡ä»¶'):
                    st_instance.info(f"ğŸ“ å½“å‰æ–‡ä»¶: {file_name}")
    
    with col_metadata:
        st_instance.markdown("**å…ƒæ•°æ®æ–‡ä»¶ (.pkl)**")
        uploaded_metadata_file = st_instance.file_uploader(
            "é€‰æ‹©å…ƒæ•°æ®æ–‡ä»¶", 
            type=['pkl'],
            key="dfm_metadata_upload_independent",
            help="ä¸Šä¼ åŒ…å«è®­ç»ƒå…ƒæ•°æ®çš„.pklæ–‡ä»¶"
        )
        
        if uploaded_metadata_file:
            set_dfm_state("dfm_metadata_file_indep", uploaded_metadata_file, session_state)
            st_instance.success(f"âœ… å·²ä¸Šä¼ : {uploaded_metadata_file.name}")
        else:
            existing_metadata_file = get_dfm_state('dfm_metadata_file_indep', None, session_state)
            if existing_metadata_file is not None:
                # ğŸ”¥ ä¿®å¤ï¼šåªåœ¨æœ‰æ•ˆæ–‡ä»¶æ—¶æ˜¾ç¤ºæ–‡ä»¶å
                file_name = getattr(existing_metadata_file, 'name', 'æœªçŸ¥æ–‡ä»¶')
                if (hasattr(existing_metadata_file, 'seek') and 
                    hasattr(existing_metadata_file, 'read') and 
                    file_name != 'æœªçŸ¥æ–‡ä»¶'):
                    st_instance.info(f"ğŸ“ å½“å‰æ–‡ä»¶: {file_name}")
    
    # æ–‡ä»¶çŠ¶æ€æ€»ç»“
    model_file = get_dfm_state('dfm_model_file_indep', None, session_state)
    metadata_file = get_dfm_state('dfm_metadata_file_indep', None, session_state)

    # ğŸ”¥ ä¿®å¤ï¼šä¸¥æ ¼æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸæ­£æœ‰æ•ˆ
    def is_valid_file_object(file_obj):
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ–‡ä»¶å¯¹è±¡"""
        if file_obj is None:
            return False
        # æ£€æŸ¥æ˜¯å¦å…·æœ‰æ–‡ä»¶å¯¹è±¡çš„å¿…è¦æ–¹æ³•
        return (hasattr(file_obj, 'seek') and 
                hasattr(file_obj, 'read') and 
                hasattr(file_obj, 'name') and
                file_obj.name != 'æœªçŸ¥æ–‡ä»¶')

    model_file_exists = is_valid_file_object(model_file)
    metadata_file_exists = is_valid_file_object(metadata_file)

    if model_file_exists and metadata_file_exists:
        st_instance.success("ğŸ‰ æ‰€æœ‰å¿…éœ€æ–‡ä»¶å·²ä¸Šä¼ å®Œæˆï¼Œå¯ä»¥è¿›è¡Œæ¨¡å‹åˆ†æã€‚")
        return True
    else:
        missing_files = []
        if not model_file_exists:
            missing_files.append("æ¨¡å‹æ–‡ä»¶")
        if not metadata_file_exists:
            missing_files.append("å…ƒæ•°æ®æ–‡ä»¶")

        st_instance.warning(f"âš ï¸ ç¼ºå°‘æ–‡ä»¶: {', '.join(missing_files)}ã€‚è¯·ä¸Šä¼ æ‰€æœ‰æ–‡ä»¶åå†è¿›è¡Œåˆ†æã€‚")
        return False

def render_dfm_tab(st, session_state):
    """Renders the DFM Model Results tab using independently uploaded files."""
        
    # æ·»åŠ æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("---")
    files_ready = render_file_upload_section(st, session_state)
    
    if not files_ready:
        st.info("ğŸ’¡ è¯·å…ˆä¸Šä¼ æ¨¡å‹æ–‡ä»¶å’Œå…ƒæ•°æ®æ–‡ä»¶ä»¥ç»§ç»­åˆ†æã€‚")
        return

    # ğŸ”¥ ä¿®å¤ï¼šåªæœ‰åœ¨æ–‡ä»¶å‡†å¤‡å¥½åæ‰å°è¯•åŠ è½½æ•°æ®
    try:
        model_results, metadata = load_dfm_data(session_state)
    except Exception as e:
        st.error(f"âŒ åŠ è½½æ–‡ä»¶æ—¶å‡ºç°æ„å¤–é”™è¯¯: {e}")
        return

    if model_results is None or metadata is None:
        st.error("âŒ æ— æ³•åŠ è½½æ¨¡å‹æ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹ã€‚")
        return

    # è°ƒç”¨åç«¯å¤„ç†å‡½æ•°
    model, metadata, load_errors = load_dfm_results_from_uploads(model_results, metadata)
    
    all_errors = load_errors

    if all_errors:
        st.error("åŠ è½½ DFM ç›¸å…³æ–‡ä»¶æ—¶é‡åˆ°é”™è¯¯:")
        for error in all_errors:
            st.error(f"- {error}")
        if model is None or metadata is None: 
            return
            
    if model is None or metadata is None:
        st.warning("æœªèƒ½æˆåŠŸåŠ è½½ DFM æ¨¡å‹æˆ–å…ƒæ•°æ®ã€‚è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹æˆ–æ ¼å¼ã€‚")
        return
    
    st.success("æˆåŠŸåŠ è½½ DFM æ¨¡å‹å’Œå…ƒæ•°æ®ï¼")



    # --- å…³é”®ç»“æœæ‘˜è¦ (ç§»åˆ°æ­¤å¤„) ---
    st.write(f"- **ç›®æ ‡å˜é‡:** {metadata.get('target_variable', 'N/A')}")
    train_start = metadata.get('training_start_date', 'N/A')
    # ä¿®æ­£è®­ç»ƒç»“æŸæ—¥æœŸé”®å - è®­ç»ƒæ¨¡å—ä½¿ç”¨ 'training_end_date'
    train_end = metadata.get('training_end_date', metadata.get('train_end_date', 'N/A'))
    val_start = metadata.get('validation_start_date', 'N/A')
    val_end = metadata.get('validation_end_date', 'N/A')
    st.write(f"- **è®­ç»ƒæœŸ:** {train_start} è‡³ {train_end}")
    st.write(f"- **éªŒè¯æœŸ:** {val_start} è‡³ {val_end}")
    
    best_params_dict = metadata.get('best_params', {})
    var_select_method = best_params_dict.get('variable_selection_method', 'æœªæŒ‡å®š') 
    tuning_objective = best_params_dict.get('tuning_objective', 'æœªæŒ‡å®š')
    st.write(f"- **å˜é‡é€‰æ‹©æ–¹æ³•:** {var_select_method} (ä¼˜åŒ–ç›®æ ‡: {tuning_objective})") # Removed trailing space from original
    if var_select_method == 'æœªæŒ‡å®š' or tuning_objective == 'æœªæŒ‡å®š':
        st.caption(":grey[æ³¨ï¼šæœªèƒ½ä»å…ƒæ•°æ® 'best_params' å­—å…¸ä¸­æ‰¾åˆ° 'variable_selection_method' æˆ– 'tuning_objective'ã€‚]")
    st.markdown("---") # åˆ†éš”çº¿
    # --- ç»“æŸå…³é”®ç»“æœæ‘˜è¦ ---
    
    # ä»å…ƒæ•°æ®è·å–æŒ‡æ ‡
    # ğŸ”¥ ä¿®å¤å› å­æ•°é‡è·å–é€»è¾‘ - å¤šé‡å›é€€ç­–ç•¥
    k_factors = 'N/A'

    # ç­–ç•¥1: ä»best_paramsè·å– (æ”¯æŒå¤šç§é”®å)
    best_params = metadata.get('best_params', {})
    if isinstance(best_params, dict):
        # å°è¯•å¤šç§å¯èƒ½çš„é”®å
        possible_keys = ['k_factors', 'k_factors_final', 'best_k_factors']
        for key in possible_keys:
            if key in best_params:
                k_factors = best_params[key]
                logger.info(f"ä»best_params['{key}']è·å–k_factors: {k_factors}")
                break

    # ç­–ç•¥2: ä»å¤šç§å¯èƒ½çš„å› å­æ•°é”®è·å–
    if k_factors == 'N/A':
        factor_keys = ['n_factors', 'k_factors_final', 'best_k_factors']
        for key in factor_keys:
            value = metadata.get(key)
            if value is not None and value != 'N/A':
                k_factors = value
                logger.info(f"ä»{key}è·å–k_factors: {k_factors}")
                break

    # ç­–ç•¥3: ä»optimal_k_factorsè·å–
    if k_factors == 'N/A':
        optimal_k = metadata.get('optimal_k_factors')
        if optimal_k is not None and optimal_k != 'N/A':
            k_factors = optimal_k
            logger.info(f"ä»optimal_k_factorsè·å–k_factors: {k_factors}")

    # ç­–ç•¥4: ä»factor_loadingsæ¨æ–­
    if k_factors == 'N/A':
        factor_loadings = metadata.get('factor_loadings_df')
        if factor_loadings is not None and hasattr(factor_loadings, 'columns'):
            k_factors = len(factor_loadings.columns)
            logger.info(f"ä»factor_loadingsæ¨æ–­k_factors: {k_factors}")

    # ç­–ç•¥5: ä»factor_seriesæ¨æ–­
    if k_factors == 'N/A':
        factor_series = metadata.get('factor_series')
        if factor_series is not None and hasattr(factor_series, 'columns'):
            k_factors = len(factor_series.columns)
            logger.info(f"ä»factor_seriesæ¨æ–­k_factors: {k_factors}")

    # æœ€ç»ˆæ£€æŸ¥
    if k_factors == 'N/A':
        logger.warning("æ— æ³•è·å–å› å­æ•°é‡ï¼Œå°†æ˜¾ç¤ºN/A")
    else:
        logger.info(f"æœ€ç»ˆç¡®å®šçš„k_factors: {k_factors}")

    # ğŸ”¥ ä¿®å¤å˜é‡æ•°é‡è·å–é€»è¾‘
    best_variables = metadata.get('best_variables', [])
    if isinstance(best_variables, list) and len(best_variables) > 0:
        n_vars = len(best_variables)
        logger.info(f"ä»best_variablesè·å–å˜é‡æ•°é‡: {n_vars}")
    else:
        # ä»factor_loadingsæ¨æ–­å˜é‡æ•°é‡
        factor_loadings = metadata.get('factor_loadings_df')
        if factor_loadings is not None and hasattr(factor_loadings, 'index'):
            n_vars = len(factor_loadings.index)
            logger.info(f"ä»factor_loadingsæ¨æ–­å˜é‡æ•°é‡: {n_vars}")
        else:
            n_vars = 'N/A'
            logger.warning("æ— æ³•è·å–å˜é‡æ•°é‡ï¼Œå°†æ˜¾ç¤ºN/A")

    # --- ä½¿ç”¨åç«¯è®¡ç®—çš„ä¿®æ­£åæŒ‡æ ‡ ---
    revised_is_hr = metadata.get('revised_is_hr')
    revised_oos_hr = metadata.get('revised_oos_hr')
    revised_is_rmse = metadata.get('revised_is_rmse')
    revised_oos_rmse = metadata.get('revised_oos_rmse')
    revised_is_mae = metadata.get('revised_is_mae')
    revised_oos_mae = metadata.get('revised_oos_mae')
    # --- ç»“æŸä½¿ç”¨ä¿®æ­£åæŒ‡æ ‡ ---

    def format_value(val, is_percent=False, precision=2):
        if isinstance(val, (int, float)) and pd.notna(val):
            if is_percent:
                # MODIFIED: Assume val is already the percentage value if is_percent is True
                # e.g., if val is 72.3, it represents 72.3%
                return f"{val:.{precision}f}%" 
            return f"{val:.{precision}f}"
        return 'N/A' if val == 'N/A' or pd.isna(val) else str(val)

    # --- ç¬¬ä¸€è¡Œ ---
    row1_col1, row1_col2 = st.columns(2)
    with row1_col1:
        display_k = k_factors if isinstance(k_factors, int) else 'N/A'
        st.metric("æœ€ç»ˆå› å­æ•° (k)", display_k)
    with row1_col2:
        display_n = n_vars if isinstance(n_vars, int) else 'N/A'
        st.metric("æœ€ç»ˆå˜é‡æ•° (N)", display_n)

    # --- ç¬¬äºŒè¡Œ ---
    row2_col1, row2_col2 = st.columns(2)
    with row2_col1:
        st.metric("è®­ç»ƒæœŸèƒœç‡", format_value(revised_is_hr, is_percent=True))
    with row2_col2:
        st.metric("éªŒè¯æœŸèƒœç‡", format_value(revised_oos_hr, is_percent=True))

    # --- ç¬¬ä¸‰è¡Œ ---
    row3_col1, row3_col2, row3_col3, row3_col4 = st.columns(4)
    with row3_col1:
        st.metric("æ ·æœ¬å†… RMSE", format_value(revised_is_rmse))
    with row3_col2:
        st.metric("æ ·æœ¬å¤– RMSE", format_value(revised_oos_rmse))
    with row3_col3:
        st.metric("æ ·æœ¬å†… MAE", format_value(revised_is_mae))
    with row3_col4:
        st.metric("æ ·æœ¬å¤– MAE", format_value(revised_oos_mae))

    # --- "Nowcast ä¸å®é™…å€¼å¯¹æ¯”å›¾åŠè¯¦ç»†æ•°æ®" - ç›´æ¥æ˜¾ç¤ºå†…å®¹ ---
    # ğŸ”¥ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨pickleæ–‡ä»¶ä¸­çš„complete_aligned_tableæ•°æ®
    complete_aligned_table = metadata.get('complete_aligned_table')

    # è·å–ç›®æ ‡å˜é‡å
    target_variable_name_for_plot = metadata.get('target_variable', 'è§„æ¨¡ä»¥ä¸Šå·¥ä¸šå¢åŠ å€¼:å½“æœˆåŒæ¯”')

    # ğŸ”¥ æ–°å¢ï¼šè¯¦ç»†çš„æ•°æ®éªŒè¯å’Œè°ƒè¯•ä¿¡æ¯
    logger.info("ğŸ”¥ å¼€å§‹éªŒè¯complete_aligned_tableæ•°æ®...")
    logger.info(f"ğŸ”¥ metadataä¸­çš„é”®: {list(metadata.keys())}")
    logger.info(f"ğŸ”¥ complete_aligned_tableç±»å‹: {type(complete_aligned_table)}")

    if complete_aligned_table is not None:
        if isinstance(complete_aligned_table, pd.DataFrame):
            logger.info(f"ğŸ”¥ complete_aligned_tableå½¢çŠ¶: {complete_aligned_table.shape}")
            logger.info(f"ğŸ”¥ complete_aligned_tableåˆ—å: {list(complete_aligned_table.columns)}")
            logger.info(f"ğŸ”¥ complete_aligned_tableæ˜¯å¦ä¸ºç©º: {complete_aligned_table.empty}")
            if not complete_aligned_table.empty:
                logger.info(f"ğŸ”¥ complete_aligned_tableæ—¶é—´èŒƒå›´: {complete_aligned_table.index.min()} åˆ° {complete_aligned_table.index.max()}")
                logger.info(f"ğŸ”¥ complete_aligned_tableéç©ºå€¼ç»Ÿè®¡: {complete_aligned_table.notna().sum().to_dict()}")
        else:
            logger.warning(f"ğŸ”¥ complete_aligned_tableä¸æ˜¯DataFrameï¼Œè€Œæ˜¯: {type(complete_aligned_table)}")
    else:
        logger.error("ğŸ”¥ complete_aligned_tableä¸ºNone")

    if complete_aligned_table is not None and isinstance(complete_aligned_table, pd.DataFrame) and not complete_aligned_table.empty:
        # ç›´æ¥ä½¿ç”¨pickleæ–‡ä»¶ä¸­çš„æ•°æ®
        logger.info("âœ… ä½¿ç”¨pickleæ–‡ä»¶ä¸­çš„complete_aligned_tableæ•°æ®")
        comparison_df = complete_aligned_table.copy()

        # ç¡®ä¿åˆ—åæ­£ç¡®
        # åˆ—åï¼š'Nowcast (Original Scale)' å’Œç›®æ ‡å˜é‡å
        nowcast_display_name = "Nowcastå€¼"
        target_display_name = target_variable_name_for_plot

        # æ£€æŸ¥å¹¶é‡å‘½ååˆ—
        if len(comparison_df.columns) >= 2:
            # ç¬¬ä¸€åˆ—æ˜¯Nowcastï¼Œç¬¬äºŒåˆ—æ˜¯Target
            comparison_df.columns = [nowcast_display_name, target_display_name]

        logger.info(f"æ•°æ®åŒ…å« {len(comparison_df)} è¡Œæ•°æ®")
        logger.info(f"æ—¶é—´èŒƒå›´: {comparison_df.index.min()} åˆ° {comparison_df.index.max()}")

    else:
        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        logger.error("âŒ æœªæ‰¾åˆ°complete_aligned_tableæ•°æ®")
        comparison_df = None

    # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–äº†å¯¹æ¯”æ•°æ®
    if comparison_df is not None and not comparison_df.empty:
        # ç¡®ä¿ç´¢å¼•æ˜¯DatetimeIndex
        if not isinstance(comparison_df.index, pd.DatetimeIndex):
            try:
                comparison_df.index = pd.to_datetime(comparison_df.index)
                comparison_df = comparison_df.sort_index()
            except Exception as e:
                st.error(f"æ— æ³•å°†å¯¹æ¯”æ•°æ®çš„ç´¢å¼•è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´æ ¼å¼: {e}")
                st.dataframe(comparison_df, use_container_width=True)
                return

        # ç»˜åˆ¶Nowcast vs å®é™…å€¼å›¾è¡¨
        logger.info("å¼€å§‹ç»˜åˆ¶ Nowcast vs å®é™…å€¼å›¾è¡¨...")
        fig = go.Figure()

        # æ·»åŠ Nowcastæ•°æ®çº¿
        if nowcast_display_name in comparison_df.columns and comparison_df[nowcast_display_name].notna().any():
            fig.add_trace(go.Scatter(
                x=comparison_df.index,
                y=comparison_df[nowcast_display_name],
                mode='lines+markers',
                name=nowcast_display_name,
                line=dict(color='blue'),
                marker=dict(size=5),
                hovertemplate=
                f'<b>æ—¥æœŸ</b>: %{{x|%Y/%m/%d}}<br>' +
                f'<b>{nowcast_display_name}</b>: %{{y:.2f}}<extra></extra>'
            ))

        # æ·»åŠ å®é™…å€¼æ•°æ®ç‚¹
        if target_display_name in comparison_df.columns and comparison_df[target_display_name].notna().any():
            actual_plot_data = comparison_df[target_display_name].dropna()
            if not actual_plot_data.empty:
                fig.add_trace(go.Scatter(
                    x=actual_plot_data.index,
                    y=actual_plot_data.values,
                    mode='markers',
                    name=target_display_name,
                    marker=dict(color='red', size=7),
                    hovertemplate=
                    f'<b>æ—¥æœŸ</b>: %{{x|%Y/%m/%d}}<br>' +
                    f'<b>{target_display_name}</b>: %{{y:.2f}}<extra></extra>'
                ))

        # è®¾ç½®å›¾è¡¨å¸ƒå±€
        fig.update_layout(
            title=f'å‘¨åº¦ {nowcast_display_name} vs. {target_display_name}',
            xaxis_title="æ—¥æœŸ",
            yaxis_title="(%)",
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=-0.2,
                xanchor="center",
                x=0.5
            ),
            hovermode='x unified',
            height=500,
            margin=dict(t=50, b=100, l=50, r=50)
        )

        # æ·»åŠ éªŒè¯æœŸæ ‡è®°
        try:
            val_start_dt = pd.to_datetime(val_start) if pd.notna(val_start) and val_start != 'N/A' else None
            val_end_dt = pd.to_datetime(val_end) if pd.notna(val_end) and val_end != 'N/A' else None
            if val_start_dt and val_end_dt:
                fig.add_vrect(
                    x0=str(val_start_dt), x1=str(val_end_dt),
                    fillcolor="yellow", opacity=0.2,
                    layer="below", line_width=0
                )
        except Exception as e_vrect:
            logger.warning(f"æ ‡è®°éªŒè¯æœŸæ—¶å‡ºé”™: {e_vrect}")

        # æ˜¾ç¤ºå›¾è¡¨
        st.plotly_chart(fig, use_container_width=True)

        # æä¾›æ•°æ®ä¸‹è½½
        try:
            csv_data = comparison_df.to_csv(index=True).encode('utf-8-sig')
            st.download_button(
                label="æ•°æ®ä¸‹è½½",
                data=csv_data,
                file_name=f"nowcast_vs_{target_variable_name_for_plot}_aligned.csv",
                mime="text/csv"
            )
        except Exception as e:
            st.error(f"ç”Ÿæˆä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    else:
        st.error("âŒ æ— æ³•æ˜¾ç¤ºNowcastå¯¹æ¯”å›¾ï¼šæœªæ‰¾åˆ°complete_aligned_tableæ•°æ®ã€‚")

        # ğŸ”¥ æ–°å¢ï¼šæä¾›æ•°æ®ä¿®å¤é€‰é¡¹
        st.markdown("### ğŸ”§ æ•°æ®ä¿®å¤é€‰é¡¹")

        # æ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹æ•°æ®å¯ä»¥é‡æ–°ç”Ÿæˆ
        has_nowcast = 'calculated_nowcast_orig' in metadata and metadata['calculated_nowcast_orig'] is not None
        has_target = 'original_target_series' in metadata and metadata['original_target_series'] is not None
        has_all_data = 'all_data_aligned_weekly' in metadata and metadata['all_data_aligned_weekly'] is not None
        target_var = metadata.get('target_variable')

        # æ˜¾ç¤ºæ•°æ®å¯ç”¨æ€§çŠ¶æ€
        col1, col2 = st.columns(2)
        with col1:
            st.write("**æ•°æ®å¯ç”¨æ€§æ£€æŸ¥:**")
            st.write(f"- calculated_nowcast_orig: {'âœ…' if has_nowcast else 'âŒ'}")
            st.write(f"- original_target_series: {'âœ…' if has_target else 'âŒ'}")
            st.write(f"- all_data_aligned_weekly: {'âœ…' if has_all_data else 'âŒ'}")
            st.write(f"- target_variable: {'âœ…' if target_var else 'âŒ'}")

        with col2:
            st.write("**ä¿®å¤å»ºè®®:**")
            if has_nowcast and has_target:
                st.success("âœ… å¯ä»¥ä»ç°æœ‰æ•°æ®é‡æ–°ç”Ÿæˆcomplete_aligned_table")
                if st.button("ğŸ”§ ç«‹å³ä¿®å¤æ•°æ®", key="repair_data_btn"):
                    try:
                        # å°è¯•ä»ç°æœ‰æ•°æ®é‡æ–°ç”Ÿæˆ
                        nowcast_data = metadata['calculated_nowcast_orig']
                        target_data = metadata['original_target_series']

                        # åˆ›å»ºå¯¹é½è¡¨æ ¼
                        repaired_df = pd.DataFrame({
                            'Nowcast (Original Scale)': nowcast_data,
                            target_var: target_data
                        })

                        # åªä¿ç•™æœ‰æ•°æ®çš„è¡Œ
                        repaired_df = repaired_df.dropna(how='all')

                        if not repaired_df.empty:
                            # æ›´æ–°session stateä¸­çš„æ•°æ®
                            metadata['complete_aligned_table'] = repaired_df
                            st.success(f"âœ… æ•°æ®ä¿®å¤æˆåŠŸï¼ç”Ÿæˆäº†åŒ…å« {len(repaired_df)} è¡Œæ•°æ®çš„å¯¹é½è¡¨æ ¼")
                            st.info("ğŸ”„ è¯·åˆ·æ–°é¡µé¢æŸ¥çœ‹ä¿®å¤åçš„å›¾è¡¨")

                            # æ˜¾ç¤ºä¿®å¤åçš„æ•°æ®é¢„è§ˆ
                            st.write("**ä¿®å¤åçš„æ•°æ®é¢„è§ˆ:**")
                            st.dataframe(repaired_df.head(10))
                        else:
                            st.error("âŒ ä¿®å¤å¤±è´¥ï¼šç”Ÿæˆçš„æ•°æ®ä¸ºç©º")
                    except Exception as e:
                        st.error(f"âŒ ä¿®å¤è¿‡ç¨‹å‡ºé”™: {e}")
            elif has_all_data and target_var:
                st.warning("âš ï¸ å¯ä»¥ä»åŸå§‹æ•°æ®ç”ŸæˆåŸºæœ¬å¯¹é½è¡¨æ ¼")
                if st.button("ğŸ”§ ç”ŸæˆåŸºæœ¬æ•°æ®", key="generate_basic_btn"):
                    try:
                        all_data = metadata['all_data_aligned_weekly']
                        if target_var in all_data.columns:
                            target_data = all_data[target_var].dropna()
                            if len(target_data) > 0:
                                # åˆ›å»ºåŸºæœ¬å¯¹é½è¡¨æ ¼
                                basic_df = pd.DataFrame({
                                    'Nowcast (Original Scale)': target_data,
                                    target_var: target_data
                                })
                                metadata['complete_aligned_table'] = basic_df
                                st.success(f"âœ… ç”ŸæˆåŸºæœ¬æ•°æ®æˆåŠŸï¼åŒ…å« {len(basic_df)} è¡Œæ•°æ®")
                                st.info("ğŸ”„ è¯·åˆ·æ–°é¡µé¢æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨")
                            else:
                                st.error("âŒ ç›®æ ‡å˜é‡æ•°æ®ä¸ºç©º")
                        else:
                            st.error(f"âŒ ç›®æ ‡å˜é‡ {target_var} ä¸åœ¨æ•°æ®ä¸­")
                    except Exception as e:
                        st.error(f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")
            else:
                st.error("âŒ ç¼ºå°‘å¿…è¦æ•°æ®ï¼Œæ— æ³•ä¿®å¤")
                st.info("ğŸ’¡ å»ºè®®é‡æ–°è®­ç»ƒæ¨¡å‹ä»¥ç”Ÿæˆå®Œæ•´æ•°æ®")

        # è¯¦ç»†è°ƒè¯•ä¿¡æ¯ï¼ˆå¯æŠ˜å ï¼‰
        with st.expander("ğŸ” è¯¦ç»†è°ƒè¯•ä¿¡æ¯", expanded=False):
            st.write("**å…ƒæ•°æ®æ¦‚è§ˆ:**")
            st.write(f"- æ€»é”®æ•°: {len(metadata) if metadata else 0}")
            st.write(f"- complete_aligned_tableå­˜åœ¨: {'complete_aligned_table' in metadata}")

            if metadata:
                st.write("**æ‰€æœ‰å¯ç”¨é”®:**")
                available_keys = sorted(metadata.keys())
                for i in range(0, len(available_keys), 3):
                    cols = st.columns(3)
                    for j, key in enumerate(available_keys[i:i+3]):
                        with cols[j]:
                            value = metadata[key]
                            if value is None:
                                st.write(f"- {key}: None")
                            else:
                                st.write(f"- {key}: {type(value).__name__}")

        comparison_df = None

    # --- "è¯¦ç»†åˆ†æç»“æœ" - ç›´æ¥æ˜¾ç¤ºå†…å®¹ ---
    # åŸ with st.expander("è¯¦ç»†åˆ†æç»“æœ", expanded=False):
    st.markdown("**PCAç»“æœåˆ†æ**")
    pca_results = metadata.get('pca_results_df')
    # ä¿®æ­£å› å­æ•°é‡è·å–ï¼Œä¸è®­ç»ƒæ¨¡å—çš„å…ƒæ•°æ®é”®åŒ¹é…
    k = metadata.get('best_params', {}).get('k_factors', metadata.get('n_factors', 0))
    if not isinstance(k, int) or k <= 0:
        if not isinstance(k, int) or k <= 0:
            logger.warning("æ— æ³•ç¡®å®šæœ€ç»ˆå› å­æ•° kï¼Œå°†å°è¯•ä» PCA æ•°æ®æ¨æ–­ã€‚")
            k = len(pca_results.index) if pca_results is not None and isinstance(pca_results, pd.DataFrame) else 0
    
    if pca_results is not None and isinstance(pca_results, pd.DataFrame) and not pca_results.empty:
        pca_df_display = pca_results.head(k if k > 0 else len(pca_results.index)).copy()
        if 'ä¸»æˆåˆ† (PC)' in pca_df_display.columns:
            pca_df_display = pca_df_display.drop(columns=['ä¸»æˆåˆ† (PC)'])
        pca_df_display.insert(0, 'ä¸»æˆåˆ† (PC)', [f"PC{i+1}" for i in range(len(pca_df_display.index))])
        if not isinstance(pca_df_display.index, pd.RangeIndex):
            pca_df_display = pca_df_display.reset_index()
            if 'index' in pca_df_display.columns:
                pca_df_display = pca_df_display.rename(columns={'index': 'Original Index'})
        pca_df_display = pca_df_display.rename(columns={
            'è§£é‡Šæ–¹å·® (%)': 'è§£é‡Šæ–¹å·®(%)',
            'ç´¯è®¡è§£é‡Šæ–¹å·® (%)': 'ç´¯è®¡è§£é‡Šæ–¹å·®(%)',
            'ç‰¹å¾å€¼ (Eigenvalue)': 'ç‰¹å¾å€¼(Eigenvalue)'
        })
        st.dataframe(pca_df_display, use_container_width=True)
    else:
        st.write("æœªæ‰¾åˆ° PCA ç»“æœã€‚")
    
    st.markdown("--- ")
    st.markdown("**RÂ² åˆ†æ**")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€æ˜¾ç¤ºRÂ²åˆ†æè¡¨æ ¼
    r2_col1, r2_col2 = st.columns(2)
    
    with r2_col1:
        st.markdown("**æ•´ä½“ RÂ² (æŒ‰è¡Œä¸š)**")
        industry_r2 = metadata.get('industry_r2_results')
        if industry_r2 is not None and isinstance(industry_r2, pd.Series) and not industry_r2.empty:
            st.dataframe(industry_r2.to_frame(name="Industry R2 (All Factors)"), use_container_width=True)
            # --- æ·»åŠ è§£é‡Š ---
            st.caption("é™„æ³¨ï¼šè¡¡é‡æ‰€æœ‰å› å­å…±åŒè§£é‡Šè¯¥è¡Œä¸šå†…æ‰€æœ‰å˜é‡æ•´ä½“å˜åŠ¨çš„ç™¾åˆ†æ¯”ã€‚è®¡ç®—æ–¹å¼ä¸ºå¯¹è¡Œä¸šå†…å„å˜é‡åˆ†åˆ«å¯¹æ‰€æœ‰å› å­è¿›è¡ŒOLSå›å½’åï¼Œæ±‡æ€»å„å˜é‡çš„æ€»å¹³æ–¹å’Œ(TSS)ä¸æ®‹å·®å¹³æ–¹å’Œ(RSS)ï¼Œè®¡ç®— Pooled RÂ² = 1 - (Sum(RSS) / Sum(TSS))ã€‚")
        else:
            st.write("æœªæ‰¾åˆ°è¡Œä¸šæ•´ä½“ RÂ² æ•°æ®ã€‚")
         
    with r2_col2:
        st.markdown("**å› å­å¯¹è¡Œä¸š Pooled RÂ²**")
        factor_industry_r2 = metadata.get('factor_industry_r2_results')
        if factor_industry_r2 and isinstance(factor_industry_r2, dict):
            try:
                factor_industry_df = pd.DataFrame(factor_industry_r2)
                st.dataframe(factor_industry_df, use_container_width=True)
                # --- æ·»åŠ è§£é‡Š ---
                st.caption("é™„æ³¨ï¼šè¡¡é‡å•ä¸ªå› å­è§£é‡Šè¯¥è¡Œä¸šå†…æ‰€æœ‰å˜é‡æ•´ä½“å˜åŠ¨çš„ç™¾åˆ†æ¯”ã€‚è®¡ç®—æ–¹å¼ä¸ºå¯¹è¡Œä¸šå†…å„å˜é‡åˆ†åˆ«å¯¹å•ä¸ªå› å­è¿›è¡ŒOLSå›å½’åï¼Œæ±‡æ€»TSSä¸RSSï¼Œè®¡ç®— Pooled RÂ² = 1 - (Sum(RSS) / Sum(TSS))ã€‚")
            except ValueError as ve:
                st.warning(f"å› å­å¯¹è¡Œä¸š Pooled RÂ² æ•°æ®æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è½¬æ¢ä¸ºDataFrame: {ve}")
                logger.warning(f"Error converting factor_industry_r2 to DataFrame: {factor_industry_r2}")
            except Exception as e:
                st.error(f"æ˜¾ç¤ºå› å­å¯¹è¡Œä¸š Pooled RÂ² æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        elif factor_industry_r2 is not None: # It's not a dict or it's an empty dict but not None
            st.write("å› å­å¯¹è¡Œä¸š Pooled RÂ² æ•°æ®æ ¼å¼ä¸æ­£ç¡®æˆ–ä¸ºç©ºã€‚")
        else:
            st.write("æœªæ‰¾åˆ°å› å­å¯¹è¡Œä¸š Pooled RÂ² æ•°æ®ã€‚")

    st.markdown("---") # Add a separator
    st.markdown("**å› å­è½½è·çƒ­åŠ›å›¾**")

    factor_loadings_df = metadata.get('factor_loadings_df') # Assuming this key exists

    if factor_loadings_df is not None and isinstance(factor_loadings_df, pd.DataFrame) and not factor_loadings_df.empty:
        
        # --- ä¿®æ”¹çƒ­åŠ›å›¾é€»è¾‘ä»¥å®ç° å› å­åœ¨Xè½´, èšç±»å˜é‡åœ¨Yè½´ ---
        data_for_clustering = factor_loadings_df.copy() # å˜é‡ä¸ºè¡Œï¼Œå› å­ä¸ºåˆ—
        variable_names_original = data_for_clustering.index.tolist()
        factor_names_original = data_for_clustering.columns.tolist()
        
        # --- åˆå§‹åŒ– y_labels_heatmap å¹¶æ”¹è¿›èšç±»é€»è¾‘ä¸­çš„èµ‹å€¼ ---
        y_labels_heatmap = variable_names_original # é»˜è®¤ä½¿ç”¨åŸå§‹é¡ºåº
        clustering_performed_successfully = False

        # 1. å¯¹å˜é‡è¿›è¡Œèšç±» (å¦‚æœå˜é‡å¤šäº1ä¸ª)
        if data_for_clustering.shape[0] > 1:
            try:
                from scipy.cluster import hierarchy as sch
                linked = sch.linkage(data_for_clustering.values, method='ward', metric='euclidean')
                dendro = sch.dendrogram(linked, no_plot=True)
                clustered_indices = dendro['leaves']
                data_for_clustering = data_for_clustering.iloc[clustered_indices, :]
                y_labels_heatmap = data_for_clustering.index.tolist() # èšç±»æˆåŠŸåæ›´æ–°
                clustering_performed_successfully = True
                logger.info("å› å­è½½è·çƒ­åŠ›å›¾ï¼šå˜é‡èšç±»æˆåŠŸã€‚")
            except Exception as e_cluster_heatmap:
                st.warning(f"å› å­è½½è·çƒ­åŠ›å›¾çš„å˜é‡èšç±»å¤±è´¥: {e_cluster_heatmap}. å°†æŒ‰åŸå§‹é¡ºåºæ˜¾ç¤ºå˜é‡ã€‚")
                logger.warning(f"å› å­è½½è·çƒ­åŠ›å›¾çš„å˜é‡èšç±»å¤±è´¥: {e_cluster_heatmap}")
                # y_labels_heatmap ä¿æŒä¸ºä¹‹å‰åˆå§‹åŒ–çš„ variable_names_original
        else:
            logger.info("å› å­è½½è·çƒ­åŠ›å›¾ï¼šåªæœ‰ä¸€ä¸ªå˜é‡ï¼Œè·³è¿‡èšç±»ã€‚")
            # y_labels_heatmap ä¿æŒä¸ºä¹‹å‰åˆå§‹åŒ–çš„ variable_names_original

        # 2. å‡†å¤‡ç»˜å›¾æ•°æ® (zå€¼, xè½´æ ‡ç­¾, yè½´æ ‡ç­¾)
        z_values = data_for_clustering.values # (num_clustered_vars, num_factors)
        x_labels_heatmap = factor_names_original # å› å­åä½œä¸ºXè½´

        fig_heatmap = go.Figure(data=go.Heatmap(
            z=z_values,
            x=x_labels_heatmap,
            y=y_labels_heatmap, # <--- ç¡®ä¿è¿™é‡Œä½¿ç”¨çš„æ˜¯èšç±»åçš„ y_labels_heatmap
            colorscale='RdBu',  # ä¿®æ”¹é¢œè‰²æ–¹æ¡ˆï¼šæ­£å€¼ä¸ºçº¢è‰²ï¼Œè´Ÿå€¼ä¸ºè“è‰²
            zmid=0,
            colorbar=dict(title='è½½è·å€¼'),
            xgap=1,
            ygap=1,
            hovertemplate=(
                "å˜é‡ (Variable): %{y}<br>" +
                "å› å­ (Factor): %{x}<br>" +
                "è½½è·å€¼ (Loading): %{z:.4f}<extra></extra>"
            )
        ))

        # Annotate heatmap cells
        annotations = []
        for i, var_name in enumerate(y_labels_heatmap): # éå†å˜é‡ (Yè½´)
            for j, factor_name in enumerate(x_labels_heatmap): # éå†å› å­ (Xè½´)
                val = z_values[i][j]
                annotations.append(
                    go.layout.Annotation(
                        text=f"{val:.2f}",
                        x=factor_name,  # Xè½´æ˜¯å› å­
                        y=var_name,     # Yè½´æ˜¯å˜é‡
                        xref='x1',
                        yref='y1',
                        showarrow=False,
                        font=dict(color='white' if abs(val) > 0.5 else 'black')
                    )
                )
            
        fig_heatmap.update_layout(
            title="å› å­è½½è·èšç±»çƒ­åŠ›å›¾ (Factor Loadings Clustermap)", # ä¿®æ”¹æ ‡é¢˜ï¼Œæ˜ç¡®è¡¨ç¤ºèšç±»åŠŸèƒ½
            xaxis_title="å› å­ (Factors)",
            yaxis_title="å˜é‡ (Predictors)",
            yaxis=dict( # ç¡®ä¿Yè½´æŒ‰èšç±»é¡ºåºæ˜¾ç¤º
                type='category',
                categoryorder='array', # å¼ºåˆ¶ä½¿ç”¨ categoryarray çš„é¡ºåº
                categoryarray=y_labels_heatmap # <--- å†æ¬¡ç¡®è®¤è¿™é‡Œä½¿ç”¨çš„æ˜¯èšç±»åçš„ y_labels_heatmap
            ),
            height=max(600, len(y_labels_heatmap) * 35 + 200),  # å¢åŠ é«˜åº¦
            # --- ä¿®æ”¹å®½åº¦ã€è¾¹è·ï¼Œå¹¶å°†Xè½´ç§»åˆ°é¡¶éƒ¨ -- -
            width=max(1000, len(x_labels_heatmap) * 100 + max(200, max(len(name) for name in y_labels_heatmap)*8 if y_labels_heatmap else 200) + 50),  # å¢åŠ å®½åº¦
            margin=dict(l=max(200, max(len(name) for name in y_labels_heatmap)*8 if y_labels_heatmap else 200), r=50, t=100, b=200),  # å¢åŠ è¾¹è·
            annotations=annotations,
            xaxis=dict(
                side='top',       # å°†Xè½´ç§»åˆ°é¡¶éƒ¨
                tickangle=-45    # ä¿æŒXè½´æ ‡ç­¾æ—‹è½¬è§’åº¦
            )
        )
            
        # ä½¿ç”¨å±…ä¸­æ˜¾ç¤ºçš„å®¹å™¨
        heatmap_col1, heatmap_col2, heatmap_col3 = st.columns([1, 8, 1])
        with heatmap_col2:
            st.plotly_chart(fig_heatmap, use_container_width=True)

        # Download button for factor loadings data
        try:
            # --- ä¸‹è½½åŸå§‹ï¼ˆæœªè½¬ç½®ï¼‰æ•°æ® ---
            csv_loadings = factor_loadings_df.to_csv(index=True).encode('utf-8-sig') # utf-8-sig for Excel compatibility
            st.download_button(
                label="æ•°æ®ä¸‹è½½",
                data=csv_loadings,
                file_name="factor_loadings.csv",
                mime="text/csv",
            )
        except Exception as e_csv_loadings:
            st.error(f"ç”Ÿæˆå› å­è½½è·ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e_csv_loadings}")
        
        # --- å› å­æ—¶é—´åºåˆ—å›¾å±•ç¤º ---
        st.markdown("---")
        st.markdown("**å› å­æ—¶é—´åºåˆ—æ¼”å˜å›¾**")
        
        # è·å–å› å­æ—¶é—´åºåˆ—æ•°æ®
        factor_series_data = metadata.get('factor_series')
        
        if factor_series_data is not None and isinstance(factor_series_data, pd.DataFrame) and not factor_series_data.empty:
            factor_names = factor_series_data.columns.tolist()
            num_factors = len(factor_names)
            
            if num_factors > 0:
                # ç¡®å®šæ¯è¡Œæ˜¾ç¤ºçš„å›¾è¡¨æ•°é‡
                if CONFIG_AVAILABLE:
                    cols_per_row = VisualizationDefaults.FACTOR_PLOT_COLS_EVEN if num_factors % 2 == 0 else VisualizationDefaults.FACTOR_PLOT_COLS_ODD
                else:
                    cols_per_row = 2 if num_factors % 2 == 0 else 3
                
                # è®¡ç®—éœ€è¦çš„è¡Œæ•°
                num_rows = (num_factors + cols_per_row - 1) // cols_per_row
                
                # ä¸ºæ¯ä¸ªå› å­åˆ›å»ºæ—¶é—´åºåˆ—å›¾
                for row in range(num_rows):
                    # åˆ›å»ºåˆ—å¸ƒå±€
                    cols = st.columns(cols_per_row)
                    
                    for col_idx in range(cols_per_row):
                        factor_idx = row * cols_per_row + col_idx
                        
                        if factor_idx < num_factors:
                            factor_name = factor_names[factor_idx]
                            
                            with cols[col_idx]:
                                # åˆ›å»ºå•ä¸ªå› å­çš„æ—¶é—´åºåˆ—å›¾
                                factor_data = factor_series_data[factor_name].dropna()
                                
                                if not factor_data.empty:
                                    fig_factor = go.Figure()
                                    
                                    fig_factor.add_trace(go.Scatter(
                                        x=factor_data.index,
                                        y=factor_data.values,
                                        mode='lines+markers',
                                        name=factor_name,
                                        line=dict(width=2),
                                        marker=dict(size=4),
                                        hovertemplate=(
                                            f"æ—¥æœŸ: %{{x|%Y/%m/%d}}<br>" +
                                            f"{factor_name}: %{{y:.4f}}<extra></extra>"
                                        )
                                    ))
                                    
                                    fig_factor.update_layout(
                                        title=f"{factor_name}",
                                        xaxis_title="æ—¥æœŸ",
                                        yaxis_title="å› å­å€¼",
                                        height=400,
                                        margin=dict(t=60, b=80, l=60, r=30),
                                        showlegend=False,  # éšè—å›¾ä¾‹ä»¥èŠ‚çœç©ºé—´
                                        hovermode='x unified'
                                    )
                                    
                                    # æ·»åŠ é›¶è½´çº¿
                                    fig_factor.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
                                    
                                    st.plotly_chart(fig_factor, use_container_width=True)
                                else:
                                    st.warning(f"{factor_name}æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨ã€‚")
                
                # æä¾›æ‰€æœ‰å› å­æ•°æ®çš„ç»Ÿä¸€ä¸‹è½½
                
                try:
                    all_factors_csv = factor_series_data.to_csv(index=True).encode('utf-8-sig')
                    st.download_button(
                        label="æ•°æ®ä¸‹è½½",
                        data=all_factors_csv,
                        file_name="æ‰€æœ‰å› å­æ—¶é—´åºåˆ—.csv",
                        mime="text/csv",
                        key="download_all_factors"
                    )
                except Exception as e_all_factors:
                    st.error(f"ç”Ÿæˆæ‰€æœ‰å› å­ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e_all_factors}")
            else:
                st.write("æœªæ‰¾åˆ°æœ‰æ•ˆçš„å› å­æ•°æ®ã€‚")
        else:
            st.write("æœªåœ¨å…ƒæ•°æ®ä¸­æ‰¾åˆ°å› å­æ—¶é—´åºåˆ—æ•°æ®ã€‚é¢„æœŸçš„é”®å: 'factor_series'ã€‚")
    
    elif factor_loadings_df is not None and not isinstance(factor_loadings_df, pd.DataFrame):
        st.warning("å› å­è½½è·æ•°æ® (factor_loadings_df) å­˜åœ¨ä½†ä¸æ˜¯æœ‰æ•ˆçš„ DataFrame æ ¼å¼ã€‚")
    else:
        st.write("æœªåœ¨å…ƒæ•°æ®ä¸­æ‰¾åˆ°å› å­è½½è·æ•°æ® (expected key: 'factor_loadings_df')ã€‚")


