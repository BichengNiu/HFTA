# -*- coding: utf-8 -*-
# Test comment added by AI
import sys
import os

# --- BEGIN UPDATED SYS.PATH SETUP ---
# Get the directory of the current file (DFM_Nowcasting.py, which is in news_analysis folder)
current_script_dir = os.path.dirname(os.path.abspath(__file__))
# Get the DFM directory (parent of news_analysis)
dfm_directory = os.path.abspath(os.path.join(current_script_dir, '..'))
# Get the project root directory (parent of DFM)
project_root_dir = os.path.abspath(os.path.join(dfm_directory, '..', '..'))
# Get the dashboard directory (parent of DFM)
dashboard_actual_dir = os.path.abspath(os.path.join(dfm_directory, '..'))

# Add project root directory to sys.path
if project_root_dir not in sys.path:
    sys.path.insert(0, project_root_dir)
    print(f"[DFM_Nowcasting] Added project_root ('{project_root_dir}') to sys.path.")

# ğŸ”¥ å…³é”®ä¿®å¤ï¼šåˆ›å»ºæ¨¡å—åˆ«åä»¥å…¼å®¹joblibæ–‡ä»¶ä¸­çš„æ—§è·¯å¾„
try:
    import train_model.DynamicFactorModel as DynamicFactorModel
    import train_model.DiscreteKalmanFilter as DiscreteKalmanFilter
    sys.modules['DynamicFactorModel'] = DynamicFactorModel
    sys.modules['DiscreteKalmanFilter'] = DiscreteKalmanFilter
    print("[DFM_Nowcasting] æ¨¡å—åˆ«åå·²è®¾ç½®ï¼Œå¯å…¼å®¹æ—§çš„joblibæ–‡ä»¶")
except ImportError as e:
    print(f"[DFM_Nowcasting] æ¨¡å—åˆ«åè®¾ç½®å¤±è´¥: {e}")

# Add DFM directory to sys.path for potential imports from DFM or other subdirectories like news_analysis
if dfm_directory not in sys.path:
    sys.path.insert(0, dfm_directory)
    # print(f"[DFM_Nowcasting] Added dfm_directory ('{dfm_directory}') to sys.path.")

# Add dashboard directory to sys.path
if dashboard_actual_dir not in sys.path:
    sys.path.insert(0, dashboard_actual_dir)
    # print(f"[DFM_Nowcasting] Added dashboard_actual_dir ('{dashboard_actual_dir}') to sys.path.")

# Add news_analysis directory (current_script_dir) for imports within news_analysis itself (e.g. if split further)
if current_script_dir not in sys.path:
    sys.path.insert(0, current_script_dir)
    # print(f"[DFM_Nowcasting] Added current_script_dir ('{current_script_dir}') to sys.path.")
# --- END UPDATED SYS.PATH SETUP ---

"""
DFM_Nowcasting.py

åŒ…å« DFMNowcastModel ç±»ï¼Œç”¨äºåŸºäºå·²ä¼°è®¡çš„ DFM æ¨¡å‹è¿›è¡Œå³æ—¶é¢„æµ‹æ›´æ–°ã€
é¢„æµ‹å’Œæ–°é—»åˆ†æã€‚
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Union

# ä¿®æ”¹å¯¼å…¥è¯­å¥ï¼Œä»æœ¬åœ°æ¨¡å—å¯¼å…¥
try:
    # å°è¯•ä»train_modelç›®å½•å¯¼å…¥DFMæ¨¡å— - ä½¿ç”¨ç»å¯¹è·¯å¾„å¯¼å…¥
    from train_model.DynamicFactorModel import DFMEMResultsWrapper
    from train_model.DiscreteKalmanFilter import KalmanFilter, FIS, KalmanFilterResultsWrapper, SKFResultsWrapper
    print("[DFM_Nowcasting] æˆåŠŸä»æœ¬åœ° train_model æ¨¡å—å¯¼å…¥")
except ImportError as e_import:
    print(f"[DFM_Nowcasting] å¯¼å…¥æœ¬åœ°DFMæ¨¡å—å¤±è´¥: {e_import}")
    print("ç¡®ä¿ DynamicFactorModel.py å’Œ DiscreteKalmanFilter.py åœ¨ train_model ç›®å½•ä¸­ã€‚")
    try:
        # å¤‡ç”¨ï¼šå°è¯•ç›´æ¥å¯¼å…¥ï¼ˆå¦‚æœsys.pathè®¾ç½®æ­£ç¡®ï¼‰
        from DynamicFactorModel import DFMEMResultsWrapper
        from DiscreteKalmanFilter import KalmanFilter, FIS, KalmanFilterResultsWrapper, SKFResultsWrapper
        print("[DFM_Nowcasting] æˆåŠŸä½¿ç”¨å¤‡ç”¨å¯¼å…¥è·¯å¾„")
    except ImportError as e_backup:
        print(f"[DFM_Nowcasting] å¤‡ç”¨å¯¼å…¥ä¹Ÿå¤±è´¥: {e_backup}")
        raise ImportError("æ— æ³•å¯¼å…¥å¿…éœ€çš„DFMæ¨¡å—") from e_import

class DFMNowcastModel:
    """
    å°è£…ä¸€ä¸ªå·²ä¼°è®¡çš„åŠ¨æ€å› å­æ¨¡å‹ï¼Œå¹¶æä¾›å³æ—¶é¢„æµ‹ã€æ›´æ–°å’Œæ–°é—»åˆ†æåŠŸèƒ½ã€‚
    """
    def __init__(self,
                 baseline_results: DFMEMResultsWrapper,
                 obs_mean: Union[pd.Series, Dict[str, float]],
                 state_names: List[str],
                 n_shocks: int,
                 baseline_kf_results: Optional[KalmanFilterResultsWrapper] = None, # ç”¨äºå­˜å‚¨åŸºçº¿çš„KFç»“æœ
                 baseline_smooth_results: Optional[SKFResultsWrapper] = None):   # ç”¨äºå­˜å‚¨åŸºçº¿çš„å¹³æ»‘ç»“æœ
        """
        åˆå§‹åŒ– DFMNowcastModelã€‚

        Args:
            baseline_results: ä» DFM_EMalgo è¿”å›çš„åŒ…å«æœ€ç»ˆä¼°è®¡å‚æ•°çš„å¯¹è±¡ã€‚
            obs_mean: ç”¨äºä¸­å¿ƒåŒ–è§‚æµ‹æ•°æ®çš„å‡å€¼ (Series æˆ–å­—å…¸)ã€‚
            state_names: çŠ¶æ€ï¼ˆå› å­ï¼‰çš„åç§°åˆ—è¡¨ã€‚
            n_shocks: æ¨¡å‹ä¸­å†²å‡»çš„æ•°é‡ã€‚
            baseline_kf_results: (å¯é€‰) è¿è¡ŒåŸºçº¿æ•°æ®å¾—åˆ°çš„ KalmanFilterResultsWrapperã€‚
            baseline_smooth_results: (å¯é€‰) è¿è¡ŒåŸºçº¿æ•°æ®å¾—åˆ°çš„ SKFResultsWrapperã€‚
        """
        if not isinstance(baseline_results, DFMEMResultsWrapper):
            raise TypeError("baseline_results å¿…é¡»æ˜¯ DFMEMResultsWrapper çš„å®ä¾‹ã€‚")

        # --- å­˜å‚¨æ ¸å¿ƒå‚æ•° ---
        self.A = np.array(baseline_results.A)
        self.B = np.array(baseline_results.B) # æ³¨æ„ï¼šB çš„ä¼°è®¡å¯èƒ½å¾ˆç®€å•
        self.Q = np.array(baseline_results.Q)
        self.R = np.array(baseline_results.R)
        self.Lambda = np.array(baseline_results.Lambda) # H in KalmanFilter

        # --- å­˜å‚¨æ¨¡å‹ç»´åº¦å’Œåç§° ---
        self.n_factors = self.A.shape[0]
        self.n_obs = self.Lambda.shape[0]
        self.n_shocks = n_shocks
        self.state_names = state_names
        self.obs_mean = pd.Series(obs_mean) if isinstance(obs_mean, dict) else obs_mean
        # å°è¯•ä» Lambda è·å–è§‚æµ‹å˜é‡åç§°é¡ºåºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.obs_names = self.obs_mean.index.tolist() # å‡è®¾ obs_mean çš„ç´¢å¼•æ˜¯æ­£ç¡®çš„é¡ºåº

        # --- å­˜å‚¨åˆå§‹æ¡ä»¶ (æ¥è‡ªåŸºçº¿æ¨¡å‹çš„æœ«å°¾æˆ–å¼€å§‹) ---
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å¹³æ»‘ç»“æœï¼Œå¦åˆ™ä» baseline_results è·å–
        smoothed_states_base = baseline_smooth_results.x_sm if baseline_smooth_results else baseline_results.x_sm
        smoothed_cov_base = baseline_smooth_results.P_sm if baseline_smooth_results else getattr(baseline_results, 'P_sm', None) # æ£€æŸ¥ P_sm æ˜¯å¦å­˜åœ¨

        if smoothed_states_base is None or smoothed_states_base.empty:
             raise ValueError("æ— æ³•è·å–åŸºçº¿å¹³æ»‘çŠ¶æ€ (x_sm) ä»¥è®¾ç½®åˆå§‹æ¡ä»¶ã€‚")

        self.x0 = smoothed_states_base.iloc[0].values.copy() # åˆå§‹çŠ¶æ€ç”¨ç¬¬ä¸€ä¸ªå¹³æ»‘çŠ¶æ€
        if smoothed_cov_base is not None and len(smoothed_cov_base) > 0:
            self.P0 = smoothed_cov_base[0].copy() # åˆå§‹åæ–¹å·®ç”¨ç¬¬ä¸€ä¸ªå¹³æ»‘åæ–¹å·®
        else:
            print("è­¦å‘Š: æ— æ³•ä» baseline_results è·å– P_smã€‚ä½¿ç”¨å•ä½çŸ©é˜µåˆå§‹åŒ– P0ã€‚")
            self.P0 = np.eye(self.n_factors)

        # --- å­˜å‚¨å®Œæ•´çš„åŸºçº¿ç»“æœä¾›å‚è€ƒ ---
        self._baseline_em_results = baseline_results

        # --- æ‰“å°å…³é”®å‚æ•°ä»¥ä¾›è°ƒè¯• ---
        print("\n--- Debug: æ‰“å°æ¨¡å‹å‚æ•° A å’Œ Q ---")
        try:
            print(f"  A çŸ©é˜µ (çŠ¶æ€è½¬ç§»):\n{self.A}")
            print(f"  Q çŸ©é˜µ (çŠ¶æ€å™ªå£°åæ–¹å·®):\n{self.Q}")
            print(f"  R çŸ©é˜µ (è§‚æµ‹å™ªå£°åæ–¹å·®ï¼Œéƒ¨åˆ†å¯¹è§’çº¿):\n{np.diag(self.R)[:10]}...") # ä»…æ‰“å°å‰10ä¸ªå¯¹è§’çº¿å…ƒç´ 
            print(f"  R çŸ©é˜µå¯¹è§’çº¿æœ€å°å€¼: {np.min(np.diag(self.R))}")
            print(f"  R çŸ©é˜µå¯¹è§’çº¿æœ€å¤§å€¼: {np.max(np.diag(self.R))}")
            # è®¡ç®— A çš„ç‰¹å¾å€¼
            eigenvalues_A = np.linalg.eigvals(self.A)
            print(f"  A çŸ©é˜µçš„ç‰¹å¾å€¼:\n{eigenvalues_A}")
            print(f"  A çŸ©é˜µç‰¹å¾å€¼çš„ç»å¯¹å€¼:\n{np.abs(eigenvalues_A)}")
            # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å¾å€¼çš„ç»å¯¹å€¼ >= 1
            if np.any(np.abs(eigenvalues_A) >= 1.0):
                print("  è­¦å‘Š: A çŸ©é˜µå­˜åœ¨ç»å¯¹å€¼å¤§äºç­‰äº 1 çš„ç‰¹å¾å€¼ï¼Œæ¨¡å‹å¯èƒ½ä¸ç¨³å®šå¯¼è‡´é¢„æµ‹å‘æ•£ï¼")
            else:
                print("  A çŸ©é˜µç‰¹å¾å€¼ç»å¯¹å€¼å‡å°äº 1ï¼Œæ¨¡å‹çŠ¶æ€è½¬ç§»çœ‹ä¼¼ç¨³å®šã€‚")
        except Exception as e_param_print:
            print(f"  æ‰“å°å‚æ•°æˆ–è®¡ç®—ç‰¹å¾å€¼æ—¶å‡ºé”™: {e_param_print}")
        # --- End Debug ---

        self.current_kf_results = baseline_kf_results # å¦‚æœä¼ å…¥ï¼Œå­˜å‚¨KFç»“æœ
        self.current_smooth_results = baseline_smooth_results if baseline_smooth_results else SKFResultsWrapper(x_sm=smoothed_states_base, P_sm=smoothed_cov_base, z=baseline_results.z)

        # --- ç¡®ä¿ B çŸ©é˜µå½¢çŠ¶æ­£ç¡® ---
        if self.B.shape != (self.n_factors, self.n_shocks):
             print(f"è­¦å‘Š: å­˜å‚¨çš„ B çŸ©é˜µå½¢çŠ¶ {self.B.shape} ä¸é¢„æœŸçš„ ({self.n_factors}, {self.n_shocks}) ä¸ç¬¦ã€‚å°†å°è¯•é‡å¡‘æˆ–ä½¿ç”¨é›¶çŸ©é˜µã€‚")
             # ç®€å•çš„å¤„ç†ï¼šå¦‚æœå½¢çŠ¶ä¸åŒ¹é…ï¼Œåˆ›å»ºä¸€ä¸ªé›¶çŸ©é˜µ
             self.B = np.zeros((self.n_factors, self.n_shocks))


    def _preprocess_data(self, observation_data: pd.DataFrame) -> pd.DataFrame:
        """
        å¯¹è¾“å…¥çš„è§‚æµ‹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ˆç¡®ä¿åˆ—é¡ºåºæ­£ç¡®ï¼‰ã€‚
        æ³¨æ„ï¼šæ­¤ç‰ˆæœ¬ä¸å†æ‰§è¡Œä¸­å¿ƒåŒ–ï¼Œå‡å®šè¾“å…¥æ•°æ®å·²æ ‡å‡†åŒ–ã€‚

        Args:
            observation_data: åŒ…å«è§‚æµ‹æ•°æ®çš„ DataFrame (å‡å®šå·²æ ‡å‡†åŒ–)ã€‚

        Returns:
            åˆ—é¡ºåºä¸æ¨¡å‹æœŸæœ›ä¸€è‡´çš„æ•°æ® DataFrameã€‚
        """
        if not isinstance(observation_data, pd.DataFrame):
            raise TypeError("observation_data å¿…é¡»æ˜¯ Pandas DataFrameã€‚")
        if not isinstance(observation_data.index, pd.DatetimeIndex):
             print("è­¦å‘Š: observation_data çš„ç´¢å¼•ä¸æ˜¯ DatetimeIndexã€‚")

        # ç¡®ä¿åˆ—é¡ºåºä¸ self.obs_names (ä» obs_mean.index æ¨æ–­) ä¸€è‡´
        # è¿™æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºå¡å°”æ›¼æ»¤æ³¢å™¨çš„ H çŸ©é˜µ (Lambda) çš„è¡Œé¡ºåºæ˜¯å›ºå®šçš„
        try:
            # --- ä¿®æ”¹ï¼šåªè¿›è¡Œåˆ—æ£€æŸ¥å’Œé‡æ’ï¼Œä¸è¿›è¡Œä¸­å¿ƒåŒ– ---
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ‰€æœ‰éœ€è¦çš„åˆ—
            missing_cols = set(self.obs_names) - set(observation_data.columns)
            if missing_cols:
                 raise ValueError(f"è¾“å…¥æ•°æ®ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}")
            
            # ç¡®ä¿åˆ—çš„é¡ºåºæ­£ç¡®
            data_reordered = observation_data[self.obs_names].copy()
            
        except KeyError as e:
            # è¿™ä¸ª KeyError å¯èƒ½åœ¨ observation_data[self.obs_names] æ—¶è§¦å‘ (è™½ç„¶ä¸Šé¢çš„æ£€æŸ¥åº”è¯¥èƒ½æ•æ‰åˆ°)
            missing_cols_alt = set(self.obs_names) - set(observation_data.columns)
            extra_cols = set(observation_data.columns) - set(self.obs_names)
            msg = f"è¾“å…¥æ•°æ®çš„åˆ—ä¸æ¨¡å‹æœŸæœ›çš„åˆ—ä¸åŒ¹é…ã€‚\\nç¼ºå¤±: {missing_cols_alt}\\nå¤šä½™: {extra_cols}"
            raise ValueError(msg) from e

        # --- ç§»é™¤ä¸­å¿ƒåŒ–æ­¥éª¤ ---
        # centered_data = data_reordered - self.obs_mean

        # --- Debug (å¯é€‰): æ£€æŸ¥å¤„ç†åçš„è¾“å…¥æ•°æ® ---
        # print("\n--- Debug: æ£€æŸ¥é¢„å¤„ç†åçš„è¾“å…¥æ•°æ® (data_reordered, åº”å·²æ ‡å‡†åŒ–) ---\")
        # try:
        #     print("  data_reordered æ•´ä½“æè¿°:\")
        #     print(data_reordered.describe().to_string())
        #     max_abs_val = data_reordered.abs().max().max()
        #     print(f"  data_reordered ä¸­çš„æœ€å¤§ç»å¯¹å€¼: {max_abs_val:.6f}\")
        # except Exception as e_prep_debug:
        #     print(f"  æ£€æŸ¥ data_reordered æ—¶å‡ºé”™: {e_prep_debug}\")
        # --- End Debug ---

        # --- ä¿®æ”¹ï¼šè¿”å›é‡æ’åçš„æ•°æ®ï¼Œè€Œä¸æ˜¯ä¸­å¿ƒåŒ–åçš„ ---
        return data_reordered

    def smooth(self, observation_data: pd.DataFrame) -> tuple[KalmanFilterResultsWrapper, SKFResultsWrapper]:
        """
        ä½¿ç”¨å­˜å‚¨çš„å›ºå®šæ¨¡å‹å‚æ•°å¯¹æ–°çš„è§‚æµ‹æ•°æ®è¿è¡Œå¡å°”æ›¼æ»¤æ³¢å’Œå¹³æ»‘ã€‚

        Args:
            observation_data: åŒ…å«æ–°è§‚æµ‹æ•°æ®çš„ DataFrameã€‚

        Returns:
            ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å« KalmanFilterResultsWrapper å’Œ SKFResultsWrapper å¯¹è±¡ï¼Œ
            å¯¹åº”äºåœ¨æ–°æ•°æ®ä¸Šè¿è¡Œçš„ç»“æœã€‚
        """
        print(f"å¯¹æ–°æ•°æ®è¿è¡Œæ»¤æ³¢å’Œå¹³æ»‘ (æ•°æ®é•¿åº¦: {len(observation_data)})...")
        # 1. é¢„å¤„ç†æ•°æ®
        centered_data = self._preprocess_data(observation_data)

        # --- æ¢å¤ï¼šä½¿ç”¨çº¿æ€§æ’å€¼å¡«å…… NaN ---
        print("  æ­£åœ¨å¯¹ centered_data (KalmanFilter è¾“å…¥ Z) è¿›è¡Œçº¿æ€§æ’å€¼ä»¥å¡«å…… NaN...")
        initial_nan_count = centered_data.isna().sum().sum()
        if initial_nan_count > 0:
            # æŒ‰æ—¶é—´è½´ï¼ˆåˆ—ï¼‰è¿›è¡Œçº¿æ€§æ’å€¼
            centered_data = centered_data.interpolate(method='linear', axis=0, limit_direction='both')
            remaining_nan_count = centered_data.isna().sum().sum()
            print(f"    æ’å€¼å®Œæˆã€‚åˆå§‹ NaN æ•°é‡: {initial_nan_count}, å‰©ä½™ NaN æ•°é‡: {remaining_nan_count}")
            if remaining_nan_count > 0:
                 print("    è­¦å‘Šï¼šæ’å€¼åä»æœ‰å‰©ä½™ NaNï¼å¯èƒ½æ˜¯å› ä¸ºåˆ—çš„å¼€å¤´æˆ–ç»“å°¾æœ‰è¿ç»­ NaNã€‚")
                 # å¯ä»¥é€‰æ‹©æ›´å¤æ‚çš„å¡«å……ç­–ç•¥ï¼Œå¦‚å‰å‘/åå‘å¡«å……å‰©ä½™ NaN
                 # centered_data = centered_data.ffill().bfill()
                 # print("    å·²å°è¯•ä½¿ç”¨ ffill/bfill å¡«å……å‰©ä½™ NaNã€‚")
        else:
            print("    è¾“å…¥æ•°æ®ä¸­æœªå‘ç° NaNï¼Œè·³è¿‡æ’å€¼ã€‚")
        # --- ç»“æŸæ¢å¤æ’å€¼ ---

        # --- æ–°å¢ï¼šæ£€æŸ¥ centered_data æ˜¯å¦åŒ…å« NaN ---
        print("  æ£€æŸ¥ KalmanFilter çš„è¾“å…¥ Z (centered_data)...")
        if centered_data.isnull().values.any():
            print("    é”™è¯¯: è¾“å…¥åˆ° KalmanFilter çš„ centered_data åŒ…å« NaN!")
            nan_counts_input = centered_data.isna().sum()
            print("    è¾“å…¥ Z æ¯åˆ— NaN æ•°é‡ (éé›¶éƒ¨åˆ†):")
            print(nan_counts_input[nan_counts_input > 0].to_string())
            # å¯ä»¥é€‰æ‹©åœ¨è¿™é‡Œå¼•å‘é”™è¯¯æˆ–ä»…ä»…æ‰“å°è­¦å‘Š
            # raise ValueError("è¾“å…¥æ•°æ®åŒ…å« NaNï¼Œæ— æ³•ç»§ç»­è¿›è¡Œ KalmanFilterã€‚")
        else:
            print("    è¾“å…¥ Z (centered_data) æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç° NaNã€‚")
        # --- ç»“æŸæ–°å¢ ---

        # 2. å‡†å¤‡æ»¤æ³¢å™¨çš„è¾“å…¥
        Z_new = centered_data
        U_new = np.zeros((len(Z_new), self.n_shocks)) # å‡è®¾æ— å¤–ç”Ÿè¾“å…¥
        error_df_new = pd.DataFrame(data=U_new, columns=[f'shock{i+1}' for i in range(self.n_shocks)], index=Z_new.index)

        # ä½¿ç”¨å­˜å‚¨çš„å‚æ•°å’Œåˆå§‹æ¡ä»¶
        # æ³¨æ„ï¼šè¿™é‡Œçš„ x0, P0 æ˜¯åŸºçº¿æ¨¡å‹çš„åˆå§‹å€¼ï¼Œå¯¹äºå¢é‡æ›´æ–°å¯èƒ½éœ€è¦è°ƒæ•´
        # æ›´ç¨³å¥çš„æ–¹æ³•å¯èƒ½æ˜¯ä»ä¸Šä¸€ä¸ªæ—¶é—´ç‚¹çš„ç»“æœå¼€å§‹ï¼Œä½†è¿™éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
        # è¿™é‡Œæˆ‘ä»¬å‡è®¾æ¯æ¬¡éƒ½ä»å¤´å¼€å§‹æ»¤æ³¢/å¹³æ»‘æ•´ä¸ªæ–°æ•°æ®é›†
        print("  è°ƒç”¨ KalmanFilter...")
        kf_results = KalmanFilter(Z=Z_new, U=error_df_new, A=self.A, B=self.B, H=self.Lambda,
                                  state_names=self.state_names, x0=self.x0, P0=self.P0,
                                  Q=self.Q, R=self.R)

        # --- æ–°å¢ï¼šæ£€æŸ¥ kf_results --- 
        print("  æ£€æŸ¥ KalmanFilter è¾“å‡º...")
        nan_found_kf = False
        # ç§»é™¤å¯¹ä¸å­˜åœ¨çš„ x_hat å’Œ P_hat çš„æ£€æŸ¥
        # if kf_results.x_hat is not None and kf_results.x_hat.isna().any().any():
        #     print("    è­¦å‘Š: kf_results.x_hat åŒ…å« NaN!")
        #     nan_found_kf = True
        if kf_results.x_minus is not None and kf_results.x_minus.isna().any().any():
            print("    è­¦å‘Š: kf_results.x_minus åŒ…å« NaN!")
            nan_found_kf = True
        # for i, p_hat in enumerate(kf_results.P_hat):
        #     if p_hat is not None and np.isnan(p_hat).any():
        #         print(f"    è­¦å‘Š: kf_results.P_hat[{i}] åŒ…å« NaN!")
        #         nan_found_kf = True
        #         break # æ‰¾åˆ°ä¸€ä¸ªå°±åœæ­¢æ£€æŸ¥
        for i, p_minus in enumerate(kf_results.P_minus):
            if p_minus is not None and np.isnan(p_minus).any():
                print(f"    è­¦å‘Š: kf_results.P_minus[{i}] åŒ…å« NaN!")
                nan_found_kf = True
                break
        if not nan_found_kf:
            print("    KalmanFilter è¾“å‡º (x_minus, P_minus) æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç° NaNã€‚") # ä¿®æ”¹æ‰“å°ä¿¡æ¯
        # --- ç»“æŸæ–°å¢ --- 

        print("  è°ƒç”¨ FIS (å¹³æ»‘å™¨)...")
        smooth_results = FIS(kf_results)
        print("æ»¤æ³¢å’Œå¹³æ»‘å®Œæˆã€‚")

        # --- æ–°å¢ï¼šæ£€æŸ¥ smooth_results (åŒ…æ‹¬ z, x_sm, P_sm) --- 
        print("  æ£€æŸ¥ FIS è¾“å‡º (smooth_results)...)")
        nan_found_smooth = False
        if smooth_results.z is not None and smooth_results.z.isna().any().any():
            print("    é”™è¯¯: smooth_results.z åŒ…å« NaN!")
            nan_counts_z = smooth_results.z.isna().sum()
            print("    å¹³æ»‘å z æ¯åˆ— NaN æ•°é‡ (éé›¶éƒ¨åˆ†):")
            print(nan_counts_z[nan_counts_z > 0].to_string())
            nan_found_smooth = True
        elif smooth_results.z is None:
            print("    é”™è¯¯: smooth_results.z is None!")
            nan_found_smooth = True
            
        if smooth_results.x_sm is not None and smooth_results.x_sm.isna().any().any():
            print("    é”™è¯¯: smooth_results.x_sm åŒ…å« NaN!")
            nan_found_smooth = True
        elif smooth_results.x_sm is None:
            print("    é”™è¯¯: smooth_results.x_sm is None!")
            nan_found_smooth = True
            
        # æ£€æŸ¥ P_sm (åˆ—è¡¨)
        if smooth_results.P_sm is not None:
            for i, p_sm in enumerate(smooth_results.P_sm):
                if p_sm is not None and np.isnan(p_sm).any():
                    print(f"    é”™è¯¯: smooth_results.P_sm[{i}] åŒ…å« NaN!")
                    nan_found_smooth = True
                    break
        elif smooth_results.P_sm is None:
            print("    é”™è¯¯: smooth_results.P_sm is None!")
            nan_found_smooth = True
            
        if not nan_found_smooth:
            print("    FIS è¾“å‡ºæ£€æŸ¥é€šè¿‡ï¼Œsmooth_results (z, x_sm, P_sm) ä¸åŒ…å« NaNã€‚") # ä¿®æ”¹æ‰“å°ä¿¡æ¯
        # --- ç»“æŸæ–°å¢ ---

        return kf_results, smooth_results

    def forecast(self, steps: int, last_state: Optional[np.ndarray] = None,
                 last_covariance: Optional[np.ndarray] = None) -> tuple[pd.DataFrame, List[np.ndarray]]:
        """
        ä»æœ€åä¸€ä¸ªå·²çŸ¥çŠ¶æ€å‘å‰é¢„æµ‹å› å­çŠ¶æ€å’Œåæ–¹å·®ã€‚

        Args:
            steps: è¦é¢„æµ‹çš„æ­¥æ•°ã€‚
            last_state: é¢„æµ‹çš„èµ·å§‹çŠ¶æ€ (n_factors,)ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨æœ€æ–°å¹³æ»‘çŠ¶æ€ã€‚
            last_covariance: é¢„æµ‹çš„èµ·å§‹çŠ¶æ€åæ–¹å·® (n_factors, n_factors)ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨æœ€æ–°å¹³æ»‘åæ–¹å·®ã€‚

        Returns:
            ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ï¼š
            - forecast_states: åŒ…å«é¢„æµ‹çŠ¶æ€çš„ DataFrame (steps x n_factors)ã€‚
            - forecast_covariances: åŒ…å«é¢„æµ‹åæ–¹å·®çŸ©é˜µçš„åˆ—è¡¨ (é•¿åº¦ä¸º steps)ã€‚
        """
        if self.current_smooth_results is None:
            raise ValueError("æ— æ³•è¿›è¡Œé¢„æµ‹ï¼Œå› ä¸ºæ²¡æœ‰å¯ç”¨çš„å¹³æ»‘ç»“æœã€‚è¯·å…ˆè¿è¡Œ smooth æˆ– applyã€‚")

        if last_state is None:
            current_state = self.current_smooth_results.x_sm.iloc[-1].values
        else:
            current_state = np.array(last_state)
            if current_state.shape != (self.n_factors,):
                raise ValueError(f"last_state å½¢çŠ¶å¿…é¡»æ˜¯ ({self.n_factors},)")

        if last_covariance is None:
            if self.current_smooth_results.P_sm is not None and len(self.current_smooth_results.P_sm) > 0:
                 current_cov = self.current_smooth_results.P_sm[-1]
            else:
                 raise ValueError("æ— æ³•è·å–æœ€åçš„å¹³æ»‘åæ–¹å·®ç”¨äºé¢„æµ‹ã€‚")
        else:
            current_cov = np.array(last_covariance)
            if current_cov.shape != (self.n_factors, self.n_factors):
                raise ValueError(f"last_covariance å½¢çŠ¶å¿…é¡»æ˜¯ ({self.n_factors}, {self.n_factors})")

        forecast_states_list = []
        forecast_covariances_list = []

        # è·å–æœ€åä¸€ä¸ªæ—¥æœŸç”¨äºç”Ÿæˆé¢„æµ‹ç´¢å¼•
        last_date = self.current_smooth_results.x_sm.index[-1]
        # å‡è®¾é¢‘ç‡å¯ä»¥æ¨æ–­ï¼Œæˆ–è€…éœ€è¦ç”¨æˆ·æŒ‡å®š
        freq = pd.infer_freq(self.current_smooth_results.x_sm.index)
        if freq is None:
            print("è­¦å‘Šï¼šæ— æ³•æ¨æ–­åŸå§‹æ•°æ®çš„é¢‘ç‡ï¼Œé¢„æµ‹æ—¥æœŸå¯èƒ½ä¸å‡†ç¡®ã€‚")
            # å°è¯•ä½¿ç”¨ 'D' ä½œä¸ºé»˜è®¤é¢‘ç‡
            try:
                 forecast_index = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=steps, freq='D')
            except: # æ›´é€šç”¨çš„å¼‚å¸¸æ•è·
                 forecast_index = pd.RangeIndex(start=len(self.current_smooth_results.x_sm), stop=len(self.current_smooth_results.x_sm) + steps)
        else:
             forecast_index = pd.date_range(start=last_date, periods=steps + 1, freq=freq)[1:] # ä»ä¸‹ä¸€ä¸ªæ—¥æœŸå¼€å§‹

        print(f"å¼€å§‹å› å­é¢„æµ‹ {steps} æ­¥...")
        for _ in range(steps):
            # é¢„æµ‹ä¸‹ä¸€æ­¥çŠ¶æ€ (å¿½ç•¥ B*u)
            next_state = self.A @ current_state
            # é¢„æµ‹ä¸‹ä¸€æ­¥åæ–¹å·®
            next_cov = self.A @ current_cov @ self.A.T + self.Q

            forecast_states_list.append(next_state)
            forecast_covariances_list.append(next_cov)

            # æ›´æ–°å½“å‰çŠ¶æ€å’Œåæ–¹å·®ä»¥è¿›è¡Œä¸‹ä¸€æ­¥é¢„æµ‹
            current_state = next_state
            current_cov = next_cov
        
        # --- ä¿®æ”¹ï¼šå¤„ç† steps = 0 çš„æƒ…å†µ ---
        if steps == 0:
            # å¦‚æœé¢„æµ‹ 0 æ­¥ï¼Œç›´æ¥è¿”å›æœ€åä¸€ä¸ªå·²çŸ¥çŠ¶æ€ (å¹³æ»‘çŠ¶æ€)
            # ä½¿ç”¨ last_date ä½œä¸ºç´¢å¼•
            last_known_state = self.current_smooth_results.x_sm.iloc[-1].values
            forecast_states_df = pd.DataFrame([last_known_state], index=[last_date], columns=self.state_names)
            forecast_covariances_list = [] # æ²¡æœ‰é¢„æµ‹åæ–¹å·®
        else:
            forecast_states_df = pd.DataFrame(forecast_states_list, index=forecast_index[:len(forecast_states_list)], columns=self.state_names)
        # --- ç»“æŸä¿®æ”¹ ---
        print("é¢„æµ‹å®Œæˆã€‚")

        return forecast_states_df, forecast_covariances_list

    def apply(self, new_observation_data: pd.DataFrame) -> 'DFMNowcastModel':
        """
        å°†æ¨¡å‹ï¼ˆå›ºå®šå‚æ•°ï¼‰åº”ç”¨äºæ–°çš„è§‚æµ‹æ•°æ®é›†ã€‚

        è¿™æœ¬è´¨ä¸Šæ˜¯åœ¨æ–°æ•°æ®ä¸Šè¿è¡Œ smoothï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–°çš„ DFMNowcastModel å®ä¾‹ï¼Œ
        è¯¥å®ä¾‹åŒ…å«æ›´æ–°åçš„çŠ¶æ€ï¼Œä½†ä¿ç•™åŸå§‹çš„åŸºå‡†å‚æ•°ã€‚

        Args:
            new_observation_data: æ–°çš„è§‚æµ‹æ•°æ® DataFrameã€‚

        Returns:
            ä¸€ä¸ªæ–°çš„ DFMNowcastModel å®ä¾‹ï¼Œä»£è¡¨åº”ç”¨æ–°æ•°æ®åçš„æ¨¡å‹çŠ¶æ€ã€‚
        """
        print(f"åº”ç”¨æ¨¡å‹åˆ°æ–°æ•°æ® (æ•°æ®é•¿åº¦: {len(new_observation_data)})...")
        # è¿è¡Œæ»¤æ³¢å’Œå¹³æ»‘
        kf_results_new, smooth_results_new = self.smooth(new_observation_data)

        # åˆ›å»ºä¸€ä¸ªæ–°çš„å®ä¾‹æ¥ä»£è¡¨è¿™ä¸ª vintage
        # å®ƒå…±äº«ç›¸åŒçš„å‚æ•° (A, Lambda, Q, R, B) å’Œ obs_mean, n_shocks ç­‰
        # ä½†å…·æœ‰æ–°çš„ kf_results å’Œ smooth_results
        new_model_instance = DFMNowcastModel(
            baseline_results=self._baseline_em_results, # ä¼ é€’åŸå§‹EMç»“æœ
            obs_mean=self.obs_mean,
            state_names=self.state_names,
            n_shocks=self.n_shocks,
            baseline_kf_results=kf_results_new,      # å­˜å‚¨æ–°çš„KFç»“æœ
            baseline_smooth_results=smooth_results_new # å­˜å‚¨æ–°çš„å¹³æ»‘ç»“æœ
        )
        print("æ¨¡å‹åº”ç”¨å®Œæˆï¼Œè¿”å›æ–°çš„æ¨¡å‹å®ä¾‹ã€‚")
        return new_model_instance

    def news(self,
             previous_vintage_model: 'DFMNowcastModel',
             impact_date: Union[str, pd.Timestamp],
             impacted_variable: str,
             model_frequency: str = 'M') -> pd.DataFrame: # é»˜è®¤æœˆåº¦é¢‘ç‡
        """
        è®¡ç®—æ–°æ•°æ® vintage ç›¸å¯¹äºå‰ä¸€ä¸ª vintage çš„ "æ–°é—»" åŠå…¶å¯¹ç‰¹å®šå˜é‡é¢„æµ‹çš„å½±å“ã€‚

        Args:
            previous_vintage_model: ä»£è¡¨ä¸Šä¸€ä¸ªæ•°æ® vintage çš„ DFMNowcastModel å®ä¾‹ã€‚
            impact_date: è¦è®¡ç®—å½±å“çš„ç›®æ ‡æ—¥æœŸ (ä¸æ¨¡å‹é¢‘ç‡å¯¹é½)ã€‚
            impacted_variable: è¦è®¡ç®—å½±å“çš„ç›®æ ‡è§‚æµ‹å˜é‡åç§°ã€‚
            model_frequency: æ¨¡å‹çš„åŸºæœ¬é¢‘ç‡ (ä» config.py è·å–é»˜è®¤å€¼)ã€‚

        Returns:
            ä¸€ä¸ª DataFrameï¼ŒåŒ…å«æ–°é—»åˆ†è§£ç»“æœã€‚åˆ—åŒ…æ‹¬:
            - update date: æ–°é—»å‘ç”Ÿçš„æ—¶é—´ç‚¹ tã€‚
            - updated variable: å‘ç”Ÿæ–°é—»çš„å˜é‡ jã€‚
            - observed: åœ¨å½“å‰ vintage ä¸­è§‚æµ‹åˆ°çš„å€¼ (åä¸­å¿ƒåŒ–)ã€‚
            - forecast (prev): åŸºäºå‰ä¸€ä¸ª vintage ä¿¡æ¯å¯¹ t æ—¶åˆ»å˜é‡ j çš„é¢„æµ‹ (åä¸­å¿ƒåŒ–)ã€‚
            - news: æ–°é—»å€¼ (observed - forecast (prev)ï¼Œä¸­å¿ƒåŒ–)ã€‚
            - weight: å•ä½æ–°é—»å¯¹ impact_date æ—¶åˆ» impacted_variable é¢„æµ‹çš„å½±å“ã€‚
            - impact: è¯¥æ–°é—»å¯¹ impact_date æ—¶åˆ» impacted_variable é¢„æµ‹çš„æ€»å½±å“ã€‚

        æ³¨æ„: æ­¤å®ç°å‡è®¾æ¨¡å‹å‚æ•°åœ¨ä¸¤ä¸ª vintages ä¹‹é—´æ˜¯å›ºå®šçš„ã€‚
              å®ƒä¾§é‡äºæ•°æ®å‘å¸ƒå’Œä¿®è®¢çš„å½±å“ã€‚
        """
        print(f"å¼€å§‹è®¡ç®— 'æ–°é—»' å½±å“ (å¯¹æ¯”å½“å‰ vs å‰ä¸€ vintage)...")
        # ä½¿ç”¨ä¼ å…¥çš„ model_frequency æˆ–æ¥è‡ª config çš„é»˜è®¤å€¼
        effective_frequency = model_frequency 
        print(f"  ç›®æ ‡æ—¥æœŸ: {impact_date}, ç›®æ ‡å˜é‡: {impacted_variable}, æ¨¡å‹é¢‘ç‡: {effective_frequency}")

        # --- ç§»é™¤ï¼šè·Ÿè¸ªç‚¹ 1 --- 
        # print("[News Debug] Entering news method successfully.")

        # --- åŸºæœ¬æ£€æŸ¥å’Œè®¾ç½® ---
        if not isinstance(previous_vintage_model, DFMNowcastModel):
            raise TypeError("previous_vintage_model å¿…é¡»æ˜¯ DFMNowcastModel çš„å®ä¾‹ã€‚")
        if impacted_variable not in self.obs_names:
             raise ValueError(f"ç›®æ ‡å˜é‡ '{impacted_variable}' ä¸åœ¨æ¨¡å‹è§‚æµ‹å˜é‡åˆ—è¡¨ä¸­ã€‚")
        try:
            # ç¡®ä¿ impact_date æ˜¯ Timestamp å¹¶ä¸é¢‘ç‡å¯¹é½
            impact_date_ts = pd.Timestamp(impact_date)
            # å¯é€‰ï¼šæ ¹æ®é¢‘ç‡å¯¹é½ impact_date_tsï¼Œä¾‹å¦‚å¯¹äº 'MS'ï¼Œç¡®ä¿æ˜¯æœˆåˆ
            # impact_date_ts = impact_date_ts.to_period(model_frequency).to_timestamp()
        except ValueError:
             raise ValueError(f"æ— æ³•å°† impact_date '{impact_date}' è½¬æ¢ä¸ºæ—¶é—´æˆ³ã€‚")

        current_z = self.current_smooth_results.z
        previous_z = previous_vintage_model.current_smooth_results.z
        prev_kf_results = previous_vintage_model.current_kf_results

        # --- æ–°å¢ Debug: æ£€æŸ¥ä¼ å…¥çš„ Z æ•°æ® ---
        print("\n--- [News Debug] æ£€æŸ¥ä¼ å…¥çš„ Z æ•°æ® --- ")
        print(f"  current_z shape: {current_z.shape}")
        print(f"  previous_z shape: {previous_z.shape}")
        debug_var = 'MEGï¼šäº§èƒ½åˆ©ç”¨ç‡ï¼šä¸­å›½ï¼ˆå‘¨ï¼‰' # é€‰æ‹©ä¸€ä¸ªå·²çŸ¥æœ‰æ–°é—»çš„å˜é‡
        debug_dates = ['2024-12-20', '2024-12-27']
        if debug_var in current_z.columns:
            print(f"  Values for '{debug_var}' at key dates:")
            for dt_str in debug_dates:
                dt = pd.Timestamp(dt_str)
                val_curr = current_z.loc[dt, debug_var] if dt in current_z.index else '[Not Found]'
                val_prev = previous_z.loc[dt, debug_var] if dt in previous_z.index else '[Not Found]'
                print(f"    {dt_str}: current_z = {val_curr}, previous_z = {val_prev}")
        else:
            print(f"  è°ƒè¯•å˜é‡ '{debug_var}' ä¸åœ¨ Z çš„åˆ—ä¸­ã€‚")
        print("--- [News Debug] ç»“æŸæ£€æŸ¥ ---\n")
        # --- ç»“æŸæ–°å¢ Debug ---

        if prev_kf_results is None or prev_kf_results.x_minus is None or prev_kf_results.Kalman_gain is None:
            raise ValueError("æ— æ³•è®¡ç®—æ–°é—»ï¼Œå‰ä¸€ä¸ª vintage çš„å¡å°”æ›¼æ»¤æ³¢ç»“æœ (x_minus, Kalman_gain) ä¸å¯ç”¨ã€‚")

        impacted_var_index = self.obs_names.index(impacted_variable)
        lambda_impacted_row = self.Lambda[impacted_var_index, :]
        obs_mean_impacted = self.obs_mean.get(impacted_variable, 0)

        # åˆå¹¶å¹¶æ’åºç´¢å¼•ï¼Œåªè€ƒè™‘å½±å“æ—¥æœŸä¹‹å‰æˆ–å½“å¤©çš„
        combined_index = current_z.index.union(previous_z.index).sort_values()
        relevant_index = combined_index[combined_index <= impact_date_ts]

        # --- å‡†å¤‡å­˜å‚¨ç»“æœ ---
        results_list = []

        # --- è¿­ä»£æ—¶é—´æ­¥ t ---
        print(f"è¿­ä»£ {len(relevant_index)} ä¸ªç›¸å…³æ—¶é—´ç‚¹è¿›è¡Œæ–°é—»åˆ†æ...")
        # --- æ–°å¢ï¼šè·å–æ—§ vintage çš„æœ€åæ—¶é—´å’ŒçŠ¶æ€ä¿¡æ¯ ---
        last_date_prev = previous_z.index.max()
        last_x_sm_prev = None
        last_P_sm_prev = None
        if previous_vintage_model.current_smooth_results and previous_vintage_model.current_smooth_results.x_sm is not None:
             try:
                 last_x_sm_prev = previous_vintage_model.current_smooth_results.x_sm.loc[last_date_prev].values
                 last_P_sm_prev = previous_vintage_model.current_smooth_results.P_sm.loc[last_date_prev].values # å‡è®¾P_smæ˜¯DataFrame
             except (KeyError, AttributeError):
                 print(f"è­¦å‘Šï¼šæ— æ³•ä»æ—§ vintage è·å–æœ€åçš„å¹³æ»‘çŠ¶æ€ (x_sm) æˆ–åæ–¹å·® (P_sm) åœ¨ {last_date_prev}ã€‚é¢„æµ‹å¯èƒ½ä¸å‡†ç¡®ã€‚")
        # --- ç»“æŸæ–°å¢ ---

        for timestamp in relevant_index:
            # --- ç§»é™¤ï¼šè·Ÿè¸ªç‚¹ 2 ---
            # print(f"[News Debug] Processing timestamp: {timestamp}")
            # è·å–å‰ä¸€ä¸ª vintage åœ¨ t æ—¶åˆ»çš„é¢„æµ‹çŠ¶æ€ x_{t|t-1}
            x_minus_t_prev = None # åˆå§‹åŒ–
            try:
                # --- ä¿®æ”¹ï¼šåŒºåˆ† timestamp æ˜¯å¦åœ¨æ—§ vintage èŒƒå›´å†… ---
                if timestamp <= last_date_prev:
                    # å¦‚æœåœ¨èŒƒå›´å†…ï¼Œç›´æ¥æŸ¥æ‰¾
                    x_minus_t_prev = prev_kf_results.x_minus.loc[timestamp].values
                elif last_x_sm_prev is not None:
                    # å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œä¸”æˆ‘ä»¬æœ‰æ—§ vintage çš„æœ€åçŠ¶æ€ï¼Œåˆ™é¢„æµ‹
                    # è®¡ç®—éœ€è¦é¢„æµ‹çš„æ­¥æ•°
                    steps_to_forecast_state = 0
                    try:
                        start_period_pred = pd.Period(last_date_prev, freq=effective_frequency)
                        end_period_pred = pd.Period(timestamp, freq=effective_frequency)
                        steps_to_forecast_state = pd.period_range(start=start_period_pred, end=end_period_pred).size - 1
                        if steps_to_forecast_state < 1: steps_to_forecast_state = 1 # è‡³å°‘é¢„æµ‹ä¸€æ­¥

                    except ValueError as e_step:
                         print(f"è­¦å‘Š: è®¡ç®—é¢„æµ‹ x_minus_t_prev çš„æ­¥æ•°æ—¶å‡ºé”™ ({last_date_prev} -> {timestamp}): {e_step}ã€‚å‡è®¾é¢„æµ‹ 1 æ­¥ã€‚")
                         steps_to_forecast_state = 1

                    # é¢„æµ‹çŠ¶æ€ x_t = A^k * x_{t-k}
                    if steps_to_forecast_state > 0:
                        try:
                            A_pow_k_pred = np.linalg.matrix_power(self.A, steps_to_forecast_state)
                            # æ³¨æ„ï¼šè¿™é‡Œç”¨çš„æ˜¯æ—§ vintage çš„æœ€å *å¹³æ»‘* çŠ¶æ€ x_sm ä½œä¸ºèµ·ç‚¹é¢„æµ‹ x_minus
                            # ç†è®ºä¸Šæ›´ç²¾ç¡®çš„æ˜¯ç”¨æ—§ vintage çš„æœ€å *é¢„æµ‹* çŠ¶æ€ x_minusï¼Œä½†å¹³æ»‘çŠ¶æ€é€šå¸¸æ›´ç¨³å®š
                            x_minus_t_prev = A_pow_k_pred @ last_x_sm_prev
                        except np.linalg.LinAlgError as e_pow:
                            print(f"è­¦å‘Š: è®¡ç®— A^{steps_to_forecast_state} (ç”¨äºé¢„æµ‹ x_minus_t_prev) æ—¶å‡ºé”™: {e_pow}ã€‚")
                        except Exception as e_pred:
                            print(f"è­¦å‘Š: é¢„æµ‹ x_minus_t_prev (ä» {last_date_prev} åˆ° {timestamp}) æ—¶å‡ºé”™: {e_pred}ã€‚")
                    else: # steps <= 0 çš„æƒ…å†µï¼Œç†è®ºä¸Šä¸åº”å‘ç”Ÿï¼Œä½†ä½œä¸ºå›é€€
                         x_minus_t_prev = last_x_sm_prev # ç›´æ¥ä½¿ç”¨æœ€åçŠ¶æ€
                # --- ç»“æŸä¿®æ”¹ ---

                # --- æ–°å¢ï¼šå¦‚æœ x_minus_t_prev ä»ç„¶æ˜¯ Noneï¼Œåˆ™è·³è¿‡ ---
                if x_minus_t_prev is None:
                    print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}: æ— æ³•è·å–æˆ–é¢„æµ‹å‰ä¸€ vintage çš„çŠ¶æ€ x_minus_t_prevã€‚è·³è¿‡æ­¤æ—¶é—´ç‚¹ã€‚")
                    continue
                # --- ç»“æŸæ–°å¢ ---

            except KeyError:
                # --- ç§»é™¤ï¼šæ—§çš„è­¦å‘Šï¼Œå·²è¢«ä¸Šé¢çš„é€»è¾‘è¦†ç›– ---
                # print(f"[News Debug] Processing timestamp: {timestamp}")
                # print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}: æœªæ‰¾åˆ°å‰ä¸€ vintage çš„é¢„æµ‹çŠ¶æ€ x_minus_t_prevã€‚è·³è¿‡æ­¤æ—¶é—´ç‚¹è¿›è¡Œæ–°é—»è®¡ç®—ã€‚")
                # continue # æ¢å¤ continue
                # --- ç»“æŸç§»é™¤ ---
                # --- æ–°å¢ï¼šå¦‚æœæŸ¥æ‰¾å¤±è´¥ï¼ˆç†è®ºä¸Šä¸åº”å‘ç”Ÿï¼Œå› å·²è¢« if timestamp <= last_date_prev å¤„ç†ï¼‰ï¼Œè®°å½•å¹¶è·³è¿‡ ---
                print(f"    [News Error] t={timestamp.strftime('%Y-%m-%d')}: å°è¯•ç›´æ¥æŸ¥æ‰¾æ—§ vintage x_minus æ—¶å‘ç”Ÿæœªé¢„æœŸçš„ KeyErrorã€‚è·³è¿‡ã€‚")
                continue
                # --- ç»“æŸæ–°å¢ ---

            # è®¡ç®—å‰ä¸€ä¸ª vintage å¯¹ t æ—¶åˆ»è§‚æµ‹å€¼ z_t çš„é¢„æµ‹
            forecast_z_t_prev_centered = self.Lambda @ x_minus_t_prev
            forecast_z_t_prev_series = pd.Series(forecast_z_t_prev_centered, index=self.obs_names)

            # --- ä¿®æ”¹ï¼šè·å– *å½“å‰* vintage åœ¨ t æ—¶åˆ»çš„å¡å°”æ›¼å¢ç›Š K_t ---
            # è·å–å¡å°”æ›¼å¢ç›Š K_t (æ¥è‡ªå½“å‰ vintage)
            current_kf_results = self.current_kf_results # ä½¿ç”¨å½“å‰ vintage çš„ KF ç»“æœ
            if current_kf_results is None or current_kf_results.Kalman_gain is None:
                 print(f"    [News Error] t={timestamp.strftime('%Y-%m-%d')}: å½“å‰ vintage çš„ Kalman_gain ä¸å¯ç”¨ï¼Œæ— æ³•è®¡ç®—æƒé‡ã€‚è·³è¿‡æ­¤æ—¶é—´ç‚¹ã€‚")
                 continue # æ— æ³•è®¡ç®—ï¼Œè·³è¿‡

            try:
                # éœ€è¦æ‰¾åˆ° timestamp åœ¨ *å½“å‰* KF ç»“æœç´¢å¼•ä¸­çš„ä½ç½®
                t_idx = current_kf_results.x_minus.index.get_loc(timestamp) # å‡è®¾ x_minus å’Œ Kalman_gain ç´¢å¼•å¯¹é½

                if t_idx >= len(current_kf_results.Kalman_gain) or current_kf_results.Kalman_gain[t_idx] is None:
                    print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}: åœ¨å½“å‰ vintage çš„ Kalman_gain åˆ—è¡¨ç´¢å¼• {t_idx} å¤„æ‰¾ä¸åˆ°æœ‰æ•ˆå¢ç›Šï¼Œå‡è®¾ä¸ºé›¶ã€‚")
                    K_t_current = np.zeros((self.n_factors, self.n_obs))
                else:
                    K_t_current = np.array(current_kf_results.Kalman_gain[t_idx])
                    if K_t_current.shape != (self.n_factors, self.n_obs):
                         print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}: å½“å‰ vintage åœ¨ç´¢å¼• {t_idx} çš„å¡å°”æ›¼å¢ç›Šå½¢çŠ¶ {K_t_current.shape} ä¸æ­£ç¡®ï¼Œåº”ä¸º {(self.n_factors, self.n_obs)}ã€‚å‡è®¾ä¸ºé›¶ã€‚")
                         K_t_current = np.zeros((self.n_factors, self.n_obs))
            except KeyError:
                 print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}: æ—¶é—´æˆ³ä¸åœ¨å½“å‰ vintage çš„ KF ç»“æœç´¢å¼•ä¸­ï¼Œæ— æ³•è·å–å¡å°”æ›¼å¢ç›Šï¼Œå‡è®¾ä¸ºé›¶ã€‚")
                 K_t_current = np.zeros((self.n_factors, self.n_obs))
            except IndexError:
                 print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}: è®¡ç®—å‡ºçš„ç´¢å¼• {t_idx} è¶…å‡ºäº†å½“å‰ vintage å¡å°”æ›¼å¢ç›Šåˆ—è¡¨çš„èŒƒå›´ï¼Œå‡è®¾ä¸ºé›¶ã€‚")
                 K_t_current = np.zeros((self.n_factors, self.n_obs))
            # --- ç»“æŸä¿®æ”¹ ---


            # è·å–å½“å‰å’Œä¹‹å‰çš„è§‚æµ‹å€¼ (ä¸­å¿ƒåŒ–)
            z_t_current = current_z.loc[timestamp] if timestamp in current_z.index else pd.Series(index=self.obs_names, dtype=float) * np.nan
            z_t_previous = previous_z.loc[timestamp] if timestamp in previous_z.index else pd.Series(index=self.obs_names, dtype=float) * np.nan

            # --- è¯†åˆ«å¹¶è®¡ç®—æ¯ä¸ªå˜é‡çš„æ–°é—» ---
            news_items_at_t = []
            for j, var_name in enumerate(self.obs_names):
                # --- ç§»é™¤ï¼šè·Ÿè¸ªç‚¹ 3 --- 
                # print(f"[News Debug] Processing variable j={j}, name={var_name}")
                obs_curr_centered = z_t_current.iloc[j]
                obs_prev_centered = z_t_previous.iloc[j]
                fcst_prev_centered = forecast_z_t_prev_series.iloc[j]

                is_news = False
                news_value = 0.0

                if pd.notna(obs_curr_centered):
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°å‘å¸ƒæˆ–ä¿®æ­£
                    if pd.isna(obs_prev_centered) or obs_curr_centered != obs_prev_centered:
                        is_news = True
                        # ä¿®å¤ç¬¦å·é”™è¯¯ï¼šæ–°é—»å®šä¹‰ä¸ºé¢„æµ‹ - å®é™…è§‚æµ‹ï¼Œä½¿ç¬¦å·ä¸å½±å“æ–¹å‘ä¸€è‡´
                        news_value = fcst_prev_centered - obs_curr_centered
                        # --- ç§»é™¤ï¼šè¿‡æ»¤æ‰å‡ ä¹ä¸ºé›¶çš„æ–°é—» --- 
                        # if np.abs(news_value) < 1e-9:
                        #     is_news = False
                        # --- ç»“æŸç§»é™¤ ---


                if is_news:
                    # è®¡ç®—å½±å“ä¼ æ’­æ­¥æ•° k = T - t
                    try:
                        # ä½¿ç”¨ pandas Period æ¥è®¡ç®—æ­¥æ•°å·®å¼‚
                        start_period = pd.Period(timestamp, freq=effective_frequency)
                        end_period = pd.Period(impact_date_ts, freq=effective_frequency)
                        # PeriodIndex å¯ä»¥è®¡ç®—æ•´æ•°å·®å¼‚
                        steps_to_propagate = pd.period_range(start=start_period, end=end_period).size -1

                    except ValueError as e:
                        print(f"è­¦å‘Š: æ— æ³•ä½¿ç”¨é¢‘ç‡ '{effective_frequency}' è®¡ç®— {timestamp} å’Œ {impact_date_ts} ä¹‹é—´çš„æ­¥æ•°: {e}ã€‚å°†ä½¿ç”¨ç®€åŒ–æ–¹æ³•ã€‚")
                        # ç®€åŒ–ï¼šå°è¯•æŒ‰æœˆè®¡ç®—ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
                        if 'M' in effective_frequency.upper():
                             steps_to_propagate = (impact_date_ts.year - timestamp.year) * 12 + (impact_date_ts.month - timestamp.month)
                        elif 'Q' in effective_frequency.upper():
                             steps_to_propagate = (impact_date_ts.year - timestamp.year) * 4 + (impact_date_ts.quarter - timestamp.quarter)
                        else: # å…¶ä»–æƒ…å†µï¼Œä¾‹å¦‚æ—¥ï¼Œä½¿ç”¨å¤©æ•°ï¼ˆå¯èƒ½ä¸å‡†ç¡®ï¼‰
                             steps_to_propagate = (impact_date_ts - timestamp).days

                        if steps_to_propagate < 0: # ç¡®ä¿éè´Ÿ
                             print(f"è­¦å‘Š: è®¡ç®—å‡ºçš„ä¼ æ’­æ­¥æ•°ä¸ºè´Ÿ ({steps_to_propagate})ï¼Œå°†è®¾ä¸º 0ã€‚")
                             steps_to_propagate = 0


                    if steps_to_propagate < 0:
                        # print(f"è°ƒè¯•: æ›´æ–°æ—¥æœŸ {timestamp} åœ¨å½±å“æ—¥æœŸ {impact_date_ts} ä¹‹åï¼Œè·³è¿‡ä¼ æ’­ã€‚")
                        continue # æ–°é—»å‘ç”Ÿåœ¨å½±å“æ—¥æœŸä¹‹å

                    # è®¡ç®— A^k
                    if steps_to_propagate == 0:
                         A_pow_k = np.eye(self.n_factors)
                    else:
                         try:
                              A_pow_k = np.linalg.matrix_power(self.A, steps_to_propagate)
                         except np.linalg.LinAlgError as e:
                             print(f"è­¦å‘Š: è®¡ç®— A^{steps_to_propagate} æ—¶å‘ç”Ÿçº¿æ€§ä»£æ•°é”™è¯¯: {e}ã€‚å½±å“è®¡ç®—å¯èƒ½ä¸å‡†ç¡®ã€‚")
                             A_pow_k = np.eye(self.n_factors) # æˆ–è€…å…¶ä»–å›é€€ç­–ç•¥

                    # è·å– K_t çš„ç¬¬ j åˆ—
                    # --- å¢å¼ºæ£€æŸ¥ï¼šç¡®ä¿ K_t_prev æœ‰æ•ˆä¸”ç´¢å¼• j åœ¨èŒƒå›´å†… ---
                    # --- ä¿®æ”¹ï¼šæ£€æŸ¥ K_t_current ---
                    if not isinstance(K_t_current, np.ndarray) or K_t_current.shape[1] != self.n_obs:
                        print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}, var={var_name}: K_t_current æ— æ•ˆæˆ–åˆ—æ•° ({K_t_current.shape[1] if isinstance(K_t_current, np.ndarray) else 'N/A'}) ä¸ n_obs ({self.n_obs}) ä¸åŒ¹é…, skipping.")
                        continue
                    if j >= K_t_current.shape[1]:
                        print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}, var={var_name}: Index j={j} è¶…å‡º K_t_current åˆ—èŒƒå›´ ({K_t_current.shape[1]}), skipping.")
                        continue
                    # --- ç»“æŸå¢å¼ºæ£€æŸ¥ ---

                    try:
                        # --- ä¿®æ”¹ï¼šä½¿ç”¨ K_t_current ---
                        K_t_j = K_t_current[:, j]
                    except IndexError: # å†—ä½™æ£€æŸ¥ï¼Œä»¥é˜²ä¸‡ä¸€
                        print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}, var={var_name}: Index j={j} out of bounds for K_t_current columns, skipping.")
                        continue

                    # è®¡ç®—æƒé‡å’Œå½±å“
                    # --- å¢å¼ºæ£€æŸ¥ï¼šç¡®ä¿ lambda_impacted_row, A_pow_k, K_t_j æœ‰æ•ˆ ---
                    valid_inputs = True
                    if not isinstance(lambda_impacted_row, np.ndarray) or lambda_impacted_row.shape != (self.n_factors,):
                        print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}, var={var_name}: lambda_impacted_row æ— æ•ˆæˆ–å½¢çŠ¶é”™è¯¯ ({lambda_impacted_row.shape if isinstance(lambda_impacted_row, np.ndarray) else 'N/A'}), skipping.")
                        valid_inputs = False
                    if not isinstance(A_pow_k, np.ndarray) or A_pow_k.shape != (self.n_factors, self.n_factors):
                        print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}, var={var_name}: A_pow_k æ— æ•ˆæˆ–å½¢çŠ¶é”™è¯¯ ({A_pow_k.shape if isinstance(A_pow_k, np.ndarray) else 'N/A'}), skipping.")
                        valid_inputs = False
                    if not isinstance(K_t_j, np.ndarray) or K_t_j.shape != (self.n_factors,):
                        print(f"    [News Warning] t={timestamp.strftime('%Y-%m-%d')}, var={var_name}: K_t_j æ— æ•ˆæˆ–å½¢çŠ¶é”™è¯¯ ({K_t_j.shape if isinstance(K_t_j, np.ndarray) else 'N/A'}), skipping.")
                        valid_inputs = False
                    
                    if not valid_inputs:
                        continue
                    # --- ç»“æŸå¢å¼ºæ£€æŸ¥ ---

                    weight = lambda_impacted_row @ A_pow_k @ K_t_j
                    item_impact = weight * news_value

                    # å­˜å‚¨ç»“æœï¼ˆåä¸­å¿ƒåŒ–è§‚æµ‹å€¼å’Œé¢„æµ‹å€¼ï¼‰
                    obs_mean_j = self.obs_mean.get(var_name, 0)
                    results_list.append({
                        'update date': timestamp,
                        'updated variable': var_name,
                        'observed': obs_curr_centered + obs_mean_j, # åä¸­å¿ƒåŒ–
                        'forecast (prev)': fcst_prev_centered + obs_mean_j, # åä¸­å¿ƒåŒ–
                        'news': news_value, # æ–°é—»å€¼ä¿æŒä¸­å¿ƒåŒ–
                        'weight': weight,
                        'impact': item_impact
                    })

        # --- Finalize DataFrame ---
        if not results_list:
            print("åœ¨æ­¤ vintage æ›´æ–°ä¸­æœªæ‰¾åˆ°å¯è®¡ç®—çš„æ–°é—»ã€‚")
            return pd.DataFrame(columns=['update date', 'updated variable', 'observed', 'forecast (prev)', 'news', 'weight', 'impact'])

        news_df = pd.DataFrame(results_list)

        # æŒ‰å½±å“ç»å¯¹å€¼æ’åº
        news_df['abs_impact'] = news_df['impact'].abs()
        # ä¼˜å…ˆæŒ‰æ›´æ–°æ—¥æœŸæ’åºï¼Œç„¶åæŒ‰ç»å¯¹å½±å“æ’åº
        news_df = news_df.sort_values(by=['update date', 'abs_impact'], ascending=[True, False])
        news_df = news_df.drop(columns='abs_impact')
        news_df = news_df.set_index(['update date', 'updated variable'])

        print(f"'æ–°é—»'å½±å“è®¡ç®—å®Œæˆï¼Œå…±æ‰¾åˆ° {len(news_df)} æ¡æ–°é—»ã€‚")
        return news_df

# --- å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ç¤ºä¾‹ç”¨æ³• ---
if __name__ == '__main__':
    # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œè¯´æ˜å¦‚ä½•ä½¿ç”¨ DFMNowcastModel
    # ä¾‹å¦‚ï¼š
    # 1. åŠ è½½ä¸€ä¸ªé¢„å…ˆä¼°è®¡å¥½çš„ DFMEMResultsWrapper å¯¹è±¡ (å¯èƒ½éœ€è¦ä»æ–‡ä»¶åŠ è½½)
    # 2. åˆ›å»º DFMNowcastModel å®ä¾‹
    # 3. åŠ è½½æ–°çš„è§‚æµ‹æ•°æ®
    # 4. è°ƒç”¨ model.apply(new_data)
    # 5. è°ƒç”¨ model.forecast(steps)
    # 6. è°ƒç”¨ model.news(previous_model, ...)
    print("DFM_Nowcasting.py è„šæœ¬å¯ä»¥ç›´æ¥è¿è¡Œï¼ˆåŒ…å«ç¤ºä¾‹ç”¨æ³•ï¼‰ã€‚")

    # ç¤ºä¾‹éœ€è¦ DFMEMResultsWrapper å®ä¾‹ç­‰ï¼Œè¿™é‡Œä»…ä½œç»“æ„æ¼”ç¤º
    pass 