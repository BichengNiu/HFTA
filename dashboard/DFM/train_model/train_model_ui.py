# === å¯¼å…¥ä¼˜åŒ–ï¼šé™é»˜å¯¼å…¥æ¨¡å¼ ===
import os
_SILENT_IMPORTS = os.getenv('STREAMLIT_SILENT_IMPORTS', 'true').lower() == 'true'

def _silent_print(*args, **kwargs):
    """æ¡ä»¶åŒ–çš„printå‡½æ•°"""
    if not _SILENT_IMPORTS:
        print(*args, **kwargs)

import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import unicodedata
from datetime import datetime, timedelta, time
from streamlit import session_state
from collections import defaultdict
# import threading  # ğŸ”§ å·²ç¦ç”¨ï¼šå•çº¿ç¨‹æ¨¡å¼
import traceback
from typing import Dict, List, Optional, Union

# æ·»åŠ å½“å‰ç›®å½•å’Œçˆ¶ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)  # DFMç›®å½•
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

# å¼ºåˆ¶æ·»åŠ data_prepç›®å½•åˆ°è·¯å¾„
data_prep_dir = os.path.join(parent_dir, 'data_prep')
if data_prep_dir not in sys.path:
    sys.path.insert(0, data_prep_dir)

# å¯¼å…¥é…ç½®
try:
    from ..config import (
        DataDefaults, TrainDefaults, UIDefaults, VisualizationDefaults,
        FileDefaults, FormatDefaults, AnalysisDefaults
    )
    CONFIG_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ æ— æ³•å¯¼å…¥é…ç½®æ¨¡å—: {e}")
    CONFIG_AVAILABLE = False

# --- æ–°å¢ï¼šå¯¼å…¥çŠ¶æ€ç®¡ç†å™¨ ---
try:
    # å°è¯•ä»ç›¸å¯¹è·¯å¾„å¯¼å…¥çŠ¶æ€ç®¡ç†å™¨
    dashboard_root = os.path.abspath(os.path.join(current_dir, '..', '..'))
    if dashboard_root not in sys.path:
        sys.path.insert(0, dashboard_root)

    from core.state_manager import StateManager
    from core.compat import CompatibilityAdapter
    from core.state_keys import StateKeys
    DFM_STATE_MANAGER_AVAILABLE = True
    _silent_print("[DFM] State manager modules imported successfully")
except ImportError as e:
    DFM_STATE_MANAGER_AVAILABLE = False
    _silent_print(f"[DFM] Warning: State manager not available, using legacy state management: {e}")
# --- ç»“æŸæ–°å¢ ---

# --- Module Import Error Handling --- 
_CONFIG_MODULE = None
_DATA_PREPARATION_MODULE = None
_TRAIN_UI_IMPORT_ERROR_MESSAGE = None # Stores combined error messages

# 1. å°è¯•å¯¼å…¥é…ç½®æ¨¡å—
try:
    if CONFIG_AVAILABLE:
        # ä½¿ç”¨ç»Ÿä¸€é…ç½®
        class ConfigWrapper:
            TYPE_MAPPING_SHEET = DataDefaults.TYPE_MAPPING_SHEET
            TARGET_VARIABLE = DataDefaults.TARGET_VARIABLE
            INDICATOR_COLUMN_NAME_IN_EXCEL = DataDefaults.INDICATOR_COLUMN
            INDUSTRY_COLUMN_NAME_IN_EXCEL = DataDefaults.INDUSTRY_COLUMN
            TYPE_COLUMN_NAME_IN_EXCEL = DataDefaults.TYPE_COLUMN
            
            # ä¸å†ä½¿ç”¨å›ºå®šçš„è¾“å‡ºç›®å½•è®¾ç½®
        
        _CONFIG_MODULE = ConfigWrapper()
    else:
        # åˆ›å»ºåŸºäºé¡¹ç›®ç»“æ„çš„é…ç½®ç±»ä½œä¸ºåå¤‡
        class TrainModelConfig:
            # åŸºäºé¡¹ç›®ç»“æ„çš„è·¯å¾„è®¾ç½®
            PROJECT_ROOT = os.path.abspath(os.path.join(current_dir, '..', '..', '..'))
            
            # UIé»˜è®¤é…ç½®å€¼ï¼ˆä½¿ç”¨é…ç½®æ¨¡å—æˆ–ç¡¬ç¼–ç ä½œä¸ºæœ€åçš„åå¤‡ï¼‰
            TYPE_MAPPING_SHEET = DataDefaults.TYPE_MAPPING_SHEET if 'DataDefaults' in globals() else 'æŒ‡æ ‡ä½“ç³»'
            TARGET_VARIABLE = DataDefaults.TARGET_VARIABLE if 'DataDefaults' in globals() else 'è§„æ¨¡ä»¥ä¸Šå·¥ä¸šå¢åŠ å€¼:å½“æœˆåŒæ¯”'
            INDICATOR_COLUMN_NAME_IN_EXCEL = DataDefaults.INDICATOR_COLUMN if 'DataDefaults' in globals() else 'é«˜é¢‘æŒ‡æ ‡'
            INDUSTRY_COLUMN_NAME_IN_EXCEL = DataDefaults.INDUSTRY_COLUMN if 'DataDefaults' in globals() else 'è¡Œä¸š'
            TYPE_COLUMN_NAME_IN_EXCEL = DataDefaults.TYPE_COLUMN if 'DataDefaults' in globals() else 'ç±»å‹'
            
            # ä¸å†ä½¿ç”¨å›ºå®šçš„è¾“å‡ºç›®å½•è®¾ç½®
        
        _CONFIG_MODULE = TrainModelConfig()

except Exception as e_config:
    error_msg_config = (
        f"Failed to create configuration: {e_config}. "
        "Using fallback configuration. Functionality may be limited."
    )
    if _TRAIN_UI_IMPORT_ERROR_MESSAGE:
        _TRAIN_UI_IMPORT_ERROR_MESSAGE += f"\n{error_msg_config}"
    else:
        _TRAIN_UI_IMPORT_ERROR_MESSAGE = error_msg_config
    
    class FallbackConfig:
        TYPE_MAPPING_SHEET = DataDefaults.TYPE_MAPPING_SHEET if 'DataDefaults' in globals() else 'æŒ‡æ ‡ä½“ç³»'
        TARGET_VARIABLE = DataDefaults.TARGET_VARIABLE if 'DataDefaults' in globals() else 'è§„æ¨¡ä»¥ä¸Šå·¥ä¸šå¢åŠ å€¼:å½“æœˆåŒæ¯”'
        INDICATOR_COLUMN_NAME_IN_EXCEL = DataDefaults.INDICATOR_COLUMN if 'DataDefaults' in globals() else 'é«˜é¢‘æŒ‡æ ‡'
        INDUSTRY_COLUMN_NAME_IN_EXCEL = DataDefaults.INDUSTRY_COLUMN if 'DataDefaults' in globals() else 'è¡Œä¸š'
        TYPE_COLUMN_NAME_IN_EXCEL = DataDefaults.TYPE_COLUMN if 'DataDefaults' in globals() else 'ç±»å‹'
    _CONFIG_MODULE = FallbackConfig()

# 2. å°è¯•å¯¼å…¥æ•°æ®é¢„å¤„ç†æ¨¡å—
try:
    # ä»data_prepç›®å½•å¯¼å…¥
    data_prep_dir = os.path.join(parent_dir, 'data_prep')
    if data_prep_dir not in sys.path:
        sys.path.insert(0, data_prep_dir)
    
    from data_preparation import load_mappings
    
    class DataPreparationWrapper:
        @staticmethod
        def load_mappings(*args, **kwargs):
            return load_mappings(*args, **kwargs)
    
    _DATA_PREPARATION_MODULE = DataPreparationWrapper()

except ImportError as e_dp:
    error_msg_dp = (
        f"Failed to import data_preparation: {e_dp}. "
        "Using mock data preparation. Functionality may be limited."
    )
    if _TRAIN_UI_IMPORT_ERROR_MESSAGE:
        _TRAIN_UI_IMPORT_ERROR_MESSAGE += f"\n{error_msg_dp}"
    else:
        _TRAIN_UI_IMPORT_ERROR_MESSAGE = error_msg_dp
    
    class MockDataPreparation:
        @staticmethod
        def load_mappings(excel_path, sheet_name, indicator_col, type_col, industry_col):
            try:
                # å°è¯•ç›´æ¥è¯»å–Excelæ–‡ä»¶ä½œä¸ºfallback
                if os.path.exists(excel_path):
                    df = pd.read_excel(excel_path, sheet_name=sheet_name)
                    if indicator_col in df.columns and industry_col in df.columns:
                        var_industry_map = dict(zip(df[indicator_col].fillna(''), df[industry_col].fillna('')))
                        var_type_map = {}
                        if type_col in df.columns:
                            var_type_map = dict(zip(df[indicator_col].fillna(''), df[type_col].fillna('')))
                        return var_type_map, var_industry_map
            except Exception as e:
                pass  # é™é»˜å¤„ç†é”™è¯¯
            return {}, {} # Return empty mappings if all fails
    
    _DATA_PREPARATION_MODULE = MockDataPreparation()

# Make the config and data_preparation (real or mock) available for the rest of the module
config = _CONFIG_MODULE
data_preparation = _DATA_PREPARATION_MODULE

# 3. å¯¼å…¥DFMè®­ç»ƒè„šæœ¬
try:
    # ç®€åŒ–çš„å¯¼å…¥æ–¹å¼ - ç¡®ä¿è·¯å¾„æ­£ç¡®
    import sys
    import os

    # è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•
    current_dir = os.path.dirname(os.path.abspath(__file__))

    # ç¡®ä¿å½“å‰ç›®å½•åœ¨Pythonè·¯å¾„ä¸­
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)

    # ç›´æ¥å¯¼å…¥æ¨¡å—
    import tune_dfm

    # æ£€æŸ¥å‡½æ•°æ˜¯å¦å­˜åœ¨
    if hasattr(tune_dfm, 'train_and_save_dfm_results'):
        train_and_save_dfm_results = tune_dfm.train_and_save_dfm_results
        # ä¼˜åŒ–ï¼šç§»é™¤å¯¼å…¥æ—¶çš„printè¯­å¥
    else:
        raise ImportError("train_and_save_dfm_results function not found in tune_dfm module")
        
except ImportError as e_tune_dfm:
    error_msg_tune_dfm = (
        f"Failed to import 'tune_dfm.train_and_save_dfm_results': {e_tune_dfm}. "
        "Actual model training will not be possible."
    )
    if _TRAIN_UI_IMPORT_ERROR_MESSAGE:
        _TRAIN_UI_IMPORT_ERROR_MESSAGE += f"\n{error_msg_tune_dfm}"
    else:
        _TRAIN_UI_IMPORT_ERROR_MESSAGE = error_msg_tune_dfm
    # Define a mock function if import fails
    def train_and_save_dfm_results(*args, **kwargs):
        st.error("Mock train_and_save_dfm_results called due to import error. No training will occur.")
        # Simulate an error or empty result as training didn't happen
        raise RuntimeError("Model training function (train_and_save_dfm_results) is not available due to import error.")

# --- End Module Import Error Handling ---

# --- DFMçŠ¶æ€ç®¡ç†è¾…åŠ©å‡½æ•° ---
def get_dfm_state_manager_instance():
    """è·å–çŠ¶æ€ç®¡ç†å™¨å®ä¾‹ï¼ˆDFMæ¨¡å—ä¸“ç”¨ï¼‰"""
    if DFM_STATE_MANAGER_AVAILABLE and hasattr(st.session_state, 'state_manager_initialized'):
        try:
            state_manager = StateManager(st.session_state)
            compat_adapter = CompatibilityAdapter(st.session_state)
            return state_manager, compat_adapter
        except Exception as e:
            _silent_print(f"[DFM] Error getting state manager: {e}")
            return None, None
    return None, None


def get_dfm_state(key, default=None):
    """è·å–DFMçŠ¶æ€å€¼ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰"""
    state_manager, compat_adapter = get_dfm_state_manager_instance()

    if compat_adapter is not None:
        return compat_adapter.get_value(key, default)
    else:
        # å›é€€åˆ°ä¼ ç»Ÿæ–¹å¼
        return st.session_state.get(key, default)


def set_dfm_state(key, value):
    """è®¾ç½®DFMçŠ¶æ€å€¼ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰"""
    state_manager, compat_adapter = get_dfm_state_manager_instance()

    if compat_adapter is not None:
        compat_adapter.set_value(key, value, use_new_key=True)
    else:
        # å›é€€åˆ°ä¼ ç»Ÿæ–¹å¼
        st.session_state[key] = value


# --- è¾…åŠ©å‡½æ•° ---
def convert_to_datetime(date_input):
    """å°†æ—¥æœŸè¾“å…¥è½¬æ¢ä¸ºdatetimeå¯¹è±¡"""
    from datetime import date, datetime, time
    
    if date_input is None:
        return None
    if isinstance(date_input, datetime):
        return date_input
    if isinstance(date_input, date):
        # å¦‚æœæ˜¯dateå¯¹è±¡ï¼Œè½¬æ¢ä¸ºdatetimeå¯¹è±¡
        return datetime.combine(date_input, time())
    if isinstance(date_input, str):
        return pd.to_datetime(date_input).to_pydatetime()
    # å¦‚æœæ˜¯å…¶ä»–pandasæ—¶é—´ç±»å‹ï¼Œè½¬æ¢ä¸ºdatetime
    if hasattr(date_input, 'to_pydatetime'):
        return date_input.to_pydatetime()
    return date_input

# --- å…¨å±€å˜é‡å­˜å‚¨è®­ç»ƒçŠ¶æ€ ---
_training_state = {
    'status': 'ç­‰å¾…å¼€å§‹',
    'log': [],
    'results': None,
    'error': None
}

# --- æ–°å¢ï¼šçŠ¶æ€é‡ç½®æ£€æŸ¥å‡½æ•° ---
def _should_reset_training_state(session_state):
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡ç½®è®­ç»ƒçŠ¶æ€"""
    global _training_state
    
    # æ£€æŸ¥æ˜¯å¦å·²æ ‡è®°éœ€è¦é‡ç½®
    force_reset = session_state.get('dfm_force_reset_training_state', False)
    if force_reset:
        return True
    
    # å¦‚æœæ•°æ®å‡†å¤‡çŠ¶æ€å˜åŒ–ï¼Œé‡ç½®è®­ç»ƒçŠ¶æ€
    data_ready = session_state.get('dfm_prepared_data_df', None) is not None
    
    # å¦‚æœæœ‰è®­ç»ƒç»“æœä½†æ•°æ®å·²ä¸å­˜åœ¨ï¼Œè¯´æ˜æ•°æ®è¢«é‡æ–°å‡†å¤‡æˆ–æ¸…ç©º
    has_training_results = (_training_state['status'] == 'è®­ç»ƒå®Œæˆ' and 
                           _training_state['results'] is not None)
    
    if has_training_results and not data_ready:
        return True
    
    # å¦‚æœæ˜¯æ–°ä¼šè¯ä¸”æ²¡æœ‰ç›¸å…³çŠ¶æ€åˆå§‹åŒ–æ ‡è®°
    if not session_state.get('dfm_training_state_initialized', False):
        session_state.dfm_training_state_initialized = True
        # å¦‚æœå…¨å±€çŠ¶æ€ä¸æ˜¯åˆå§‹çŠ¶æ€ï¼Œè¯´æ˜æ˜¯é¡µé¢åˆ·æ–°
        if _training_state['status'] != 'ç­‰å¾…å¼€å§‹':
            return True
    
    return False

def _reset_training_state(session_state):
    """é‡ç½®æ‰€æœ‰è®­ç»ƒç›¸å…³çŠ¶æ€"""
    global _training_state
    
    # é‡ç½®å…¨å±€çŠ¶æ€
    _training_state['status'] = 'ç­‰å¾…å¼€å§‹'
    _training_state['log'] = []
    _training_state['results'] = None
    _training_state['error'] = None
    
    # æ¸…ç†session_stateä¸­çš„è®­ç»ƒç›¸å…³çŠ¶æ€
    keys_to_clear = [
        'dfm_training_status',
        'dfm_model_results_paths', 
        'dfm_training_log',
        'existing_results_checked',
        'training_completed_refreshed',
        'dfm_force_reset_training_state'
    ]
    
    for key in keys_to_clear:
        if key in session_state:
            del session_state[key]
    
    # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ¸…ç†çŠ¶æ€
    set_dfm_state('dfm_training_status', 'ç­‰å¾…å¼€å§‹')
    set_dfm_state('dfm_model_results_paths', None)
    set_dfm_state('dfm_training_log', [])
    set_dfm_state('existing_results_checked', None)
    set_dfm_state('training_completed_refreshed', None)

# --- è¾…åŠ©å‡½æ•°ï¼šè®­ç»ƒçº¿ç¨‹ ---
def _run_training_thread(params, st_instance_ref, log_callback_ref):
    """Helper function to run the training in a separate thread."""
    global _training_state
    
    try:
        # è®¾ç½®åˆå§‹çŠ¶æ€
        _training_state['status'] = 'æ­£åœ¨è®­ç»ƒ...'
        _training_state['log'] = ['[è®­ç»ƒå¼€å§‹] å¼€å§‹DFMæ¨¡å‹è®­ç»ƒ...']
        _training_state['results'] = None
        _training_state['error'] = None
        
        # çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—å›è°ƒå‡½æ•°
        def thread_log_callback(message):
            """å®Œå…¨çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—å›è°ƒï¼Œé¿å…ä»»ä½•Streamlitä¸Šä¸‹æ–‡è°ƒç”¨"""
            try:
                # å¿½ç•¥æ‰€æœ‰Streamlitç›¸å…³çš„è­¦å‘Šå’Œæ¶ˆæ¯
                if not message or not message.strip():
                    return
                    
                # è¿‡æ»¤æ‰æ‰€æœ‰ä¸éœ€è¦çš„æ¶ˆæ¯ç±»å‹
                skip_patterns = [
                    '[DEBUG]', '  [DEBUG]', '[TRAIN_LOG_ERROR]', '[UI_SYNC]',
                    'ScriptRunContext', 'Thread \'MainThread\':', 'missing ScriptRunContext',
                    'WARNING streamlit', 'æˆåŠŸå¯¼å…¥', 'å°è¯•å¯¼å…¥', 'sys.pathå‰3ä¸ª',
                    'current_dir:', 'parent_dir:', 'data_prep_dir:', 'âœ“ æˆåŠŸåˆ›å»ºé…ç½®æ¨¡å—',
                    '[OK] æˆåŠŸå¯¼å…¥', 'æ¨¡å—å¯¼å…¥çŠ¶æ€æ€»ç»“:', 'DEBUG', 'No runtime found',
                    'Matplotlib Font Setup', 'Thread \'MainThread\': missing ScriptRunContext',
                    'MainThread', 'ScriptRunner', 'streamlit', 'can be ignored when running in bare mode'
                ]
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«éœ€è¦è·³è¿‡çš„æ¨¡å¼
                for pattern in skip_patterns:
                    if pattern in message:
                        return
                
                # æ¸…ç†æ¶ˆæ¯æ ¼å¼
                clean_message = message.replace('[TRAIN] ', '').replace('[TRAIN_LOG] ', '').strip()
                if clean_message and clean_message not in _training_state['log']:
                    # æ·»åŠ æ—¶é—´æˆ³
                    from datetime import datetime
                    timestamp = datetime.now().strftime('%H:%M:%S')
                    formatted_message = f"[{timestamp}] {clean_message}"
                    _training_state['log'].append(formatted_message)
                    # åªä¿ç•™æœ€è¿‘50æ¡æ—¥å¿—ï¼Œé¿å…å†…å­˜å ç”¨è¿‡å¤š
                    if len(_training_state['log']) > 50:
                        _training_state['log'] = _training_state['log'][-50:]
            except Exception:
                # å®Œå…¨é™é»˜å¤„ç†æ—¥å¿—é”™è¯¯ï¼Œé¿å…å¹²æ‰°è®­ç»ƒè¿‡ç¨‹
                pass
        
        # è®¾ç½®è¿›åº¦å›è°ƒ
        params_copy = params.copy()
        params_copy['progress_callback'] = thread_log_callback
        
        _training_state['log'].append("[è®­ç»ƒå‚æ•°] å¼€å§‹å‡†å¤‡è®­ç»ƒæ•°æ®...")
        thread_log_callback("å¼€å§‹DFMæ¨¡å‹è®­ç»ƒ...")
        
        # è°ƒç”¨è®­ç»ƒå‡½æ•°
        saved_files_paths = train_and_save_dfm_results(**params_copy)
        
        # è®¾ç½®è®­ç»ƒå®ŒæˆçŠ¶æ€
        _training_state['status'] = "è®­ç»ƒå®Œæˆ"
        _training_state['results'] = saved_files_paths
        
        thread_log_callback("âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼")
        thread_log_callback(f"ğŸ“ ç”Ÿæˆ {len(saved_files_paths)} ä¸ªæ–‡ä»¶")
        
        # æ›´æ–°session_stateä»¥ä¾¿UIæ˜¾ç¤º
        if hasattr(st_instance_ref, 'session_state'):
            st_instance_ref.session_state.dfm_training_status = "è®­ç»ƒå®Œæˆ"
            st_instance_ref.session_state.dfm_model_results_paths = saved_files_paths
        
    except Exception as e:
        _training_state['status'] = f"è®­ç»ƒå¤±è´¥: {str(e)}"
        _training_state['error'] = str(e)
        error_msg = f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}"
        thread_log_callback(error_msg)
        
        # æ›´æ–°session_state
        if hasattr(st_instance_ref, 'session_state'):
            st_instance_ref.session_state.dfm_training_status = f"è®­ç»ƒå¤±è´¥: {str(e)}"
    
    # è®­ç»ƒçº¿ç¨‹ç»“æŸï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°

# --- è¾…åŠ©å‡½æ•°ï¼šåŠ è½½å’Œè§£ææŒ‡æ ‡ä½“ç³» (ä¿æŒä¸å˜) ---
# ğŸ”¥ ä¿®å¤ï¼šç§»é™¤ç¼“å­˜è£…é¥°å™¨é¿å… ScriptRunContext è­¦å‘Š
# @st.cache_data 

# æ—§çš„åŸºäºæœ¬åœ°æ–‡ä»¶è·¯å¾„çš„ç¼“å­˜å‡½æ•°å·²åˆ é™¤ï¼Œç°åœ¨ä½¿ç”¨åŸºäºä¸Šä¼ æ–‡ä»¶çš„å‡½æ•°

@st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶ï¼Œé¿å…é‡å¤è¯»å–Excelæ–‡ä»¶
def load_indicator_mappings_from_data_prep(uploaded_excel_file=None, type_mapping_sheet=None, available_data_columns=None):
    """ä»UIä¸Šä¼ çš„Excelæ–‡ä»¶ä¸­åŠ è½½è¡Œä¸šåŠæŒ‡æ ‡æ˜ å°„ï¼Œå¹¶åªè¿”å›å®é™…å­˜åœ¨äºæ•°æ®ä¸­çš„å˜é‡ã€‚
    Args:
        uploaded_excel_file: Streamlitä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡ï¼ˆæ¥è‡ªdata_prepæ¨¡å—ï¼‰
        type_mapping_sheet: æŒ‡æ ‡ä½“ç³»å·¥ä½œè¡¨åç§°
        available_data_columns: å®é™…æ•°æ®ä¸­å¯ç”¨çš„åˆ—ååˆ—è¡¨ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
    Returns: 
        unique_industries (list): å”¯ä¸€è¡Œä¸šåç§°åˆ—è¡¨ã€‚
        industry_to_indicators_map (dict): {'è¡Œä¸šå': ['æŒ‡æ ‡åˆ—è¡¨']}ã€‚
        all_indicators_flat (list): æ‰€æœ‰æ˜ å°„ä¸­å‡ºç°çš„æŒ‡æ ‡çš„æ‰å¹³åŒ–åˆ—è¡¨ã€‚
    """
    # ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
    if type_mapping_sheet is None:
        if CONFIG_AVAILABLE:
            type_mapping_sheet = DataDefaults.TYPE_MAPPING_SHEET
        else:
            type_mapping_sheet = DataDefaults.TYPE_MAPPING_SHEET if 'DataDefaults' in globals() else 'æŒ‡æ ‡ä½“ç³»'
    if uploaded_excel_file is None:
        st.warning("âš ï¸ å°šæœªä¸Šä¼ Excelæ•°æ®æ–‡ä»¶ã€‚è¯·å…ˆåœ¨ã€Œæ•°æ®å‡†å¤‡ã€æ¨¡å—ä¸Šä¼ Excelæ–‡ä»¶ã€‚")
        return [], {}, []
    
    try:
        import io
        import unicodedata
        
        # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        uploaded_excel_file.seek(0)
        excel_file_like_object = io.BytesIO(uploaded_excel_file.getvalue())
        
        # ä½¿ç”¨UIä¸Šä¼ çš„æ–‡ä»¶è€Œä¸æ˜¯æœ¬åœ°è·¯å¾„
        if CONFIG_AVAILABLE:
            indicator_col = DataDefaults.INDICATOR_COLUMN
            type_col = DataDefaults.TYPE_COLUMN
            industry_col = DataDefaults.INDUSTRY_COLUMN
        else:
            indicator_col = DataDefaults.INDICATOR_COLUMN if 'DataDefaults' in globals() else 'é«˜é¢‘æŒ‡æ ‡'
            type_col = DataDefaults.TYPE_COLUMN if 'DataDefaults' in globals() else 'ç±»å‹'
            industry_col = DataDefaults.INDUSTRY_COLUMN if 'DataDefaults' in globals() else 'è¡Œä¸š'
            
        _, var_industry_map_all = _cached_load_mappings_silent_from_uploaded_file(
            excel_file_obj=excel_file_like_object,
            sheet_name=type_mapping_sheet,
            indicator_col=indicator_col, 
            type_col=type_col, 
            industry_col=industry_col
        )

        if not var_industry_map_all:
            st.warning(f"ä»ä¸Šä¼ æ–‡ä»¶çš„'{type_mapping_sheet}'å·¥ä½œè¡¨ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¡Œä¸šæ˜ å°„æ•°æ®ã€‚è¯·æ£€æŸ¥å·¥ä½œè¡¨åç§°å’Œåˆ—ç»“æ„ã€‚")
            return [], {}, [] 

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåªä¿ç•™å®é™…å­˜åœ¨äºæ•°æ®ä¸­çš„å˜é‡ï¼Œå¹¶åˆ›å»ºåŒå‘æ˜ å°„
        if available_data_columns is not None:
            # æ ‡å‡†åŒ–å®é™…æ•°æ®çš„åˆ—å
            normalized_data_columns = {}  # æ”¹ä¸ºå­—å…¸ï¼šnormalized_name -> original_name
            for col in available_data_columns:
                if col and pd.notna(col):
                    norm_col = unicodedata.normalize('NFKC', str(col)).strip().lower()
                    if norm_col:
                        normalized_data_columns[norm_col] = col

            # è¿‡æ»¤æ˜ å°„ï¼Œåªä¿ç•™å®é™…å­˜åœ¨çš„å˜é‡ï¼Œå¹¶åˆ›å»ºåå‘æ˜ å°„
            var_industry_map = {}
            indicator_to_actual_column = {}  # æ–°å¢ï¼šæŒ‡æ ‡ä½“ç³»åç§° -> å®é™…åˆ—åçš„æ˜ å°„

            for indicator_norm, industry in var_industry_map_all.items():
                if indicator_norm in normalized_data_columns:
                    actual_col_name = normalized_data_columns[indicator_norm]
                    var_industry_map[indicator_norm] = industry
                    indicator_to_actual_column[indicator_norm] = actual_col_name

            # å­˜å‚¨æ˜ å°„å…³ç³»åˆ°session_stateï¼Œä¾›åç»­ä½¿ç”¨
            if 'dfm_indicator_to_actual_column_map' not in st.session_state:
                st.session_state.dfm_indicator_to_actual_column_map = {}
            st.session_state.dfm_indicator_to_actual_column_map.update(indicator_to_actual_column)

            st.info(f"ğŸ“Š å˜é‡è¿‡æ»¤ç»“æœ: æŒ‡æ ‡ä½“ç³»ä¸­æœ‰ {len(var_industry_map_all)} ä¸ªå˜é‡ï¼Œå®é™…æ•°æ®ä¸­æœ‰ {len(available_data_columns)} ä¸ªå˜é‡ï¼ŒåŒ¹é…åˆ° {len(var_industry_map)} ä¸ªå˜é‡")

            # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºæœªåŒ¹é…çš„å˜é‡ç»Ÿè®¡
            unmatched_count = len(var_industry_map_all) - len(var_industry_map)
            if unmatched_count > 0:
                st.warning(f"âš ï¸ æœ‰ {unmatched_count} ä¸ªæŒ‡æ ‡ä½“ç³»å˜é‡åœ¨å®é™…æ•°æ®ä¸­æœªæ‰¾åˆ°ï¼Œè¿™äº›å˜é‡å°†ä¸ä¼šæ˜¾ç¤ºåœ¨é€‰æ‹©åˆ—è¡¨ä¸­")
        else:
            var_industry_map = var_industry_map_all
            st.warning("âš ï¸ æœªæä¾›å®é™…æ•°æ®åˆ—åï¼Œæ— æ³•è¿‡æ»¤å˜é‡ï¼Œå°†æ˜¾ç¤ºæŒ‡æ ‡ä½“ç³»ä¸­çš„æ‰€æœ‰å˜é‡")

        all_indicators = list(var_industry_map.keys()) 
        industry_to_indicators_temp = defaultdict(list)
        for indicator, industry in var_industry_map.items():
            if indicator and industry: 
                industry_to_indicators_temp[str(industry).strip()].append(str(indicator).strip())
        
        industries = sorted(list(industry_to_indicators_temp.keys()))
        industry_to_indicators = {k: sorted(v) for k, v in industry_to_indicators_temp.items()}
        all_indicators = sorted(all_indicators)

        if not industries or not all_indicators:
            st.info(f"ä»ä¸Šä¼ æ–‡ä»¶çš„'{type_mapping_sheet}'å·¥ä½œè¡¨è§£æåæœªæ‰¾åˆ°æœ‰æ•ˆçš„è¡Œä¸šæˆ–æŒ‡æ ‡ã€‚")

        return industries, industry_to_indicators, all_indicators

    except Exception as e:
        st.error(f"ä»ä¸Šä¼ çš„Excelæ–‡ä»¶åŠ è½½æŒ‡æ ‡æ˜ å°„æ—¶å‡ºé”™ï¼š{e}")
        return [], {}, []

@st.cache_data(ttl=3600, show_spinner=False)  # ç¼“å­˜1å°æ—¶ï¼Œä¸æ˜¾ç¤ºspinner
def _cached_load_mappings_silent_from_uploaded_file(excel_file_obj, sheet_name: str, indicator_col: str, type_col: str, industry_col: str):
    """ä»ä¸Šä¼ çš„Excelæ–‡ä»¶å¯¹è±¡é™é»˜åœ°åŠ è½½æ˜ å°„æ•°æ®"""
    import io
    from contextlib import redirect_stdout, redirect_stderr
    
    # æ•è·å¹¶é™é»˜æ‰€æœ‰è¾“å‡º
    with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):
        try:
            # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            excel_file_obj.seek(0)
            
            # ç›´æ¥ä½¿ç”¨pandasè¯»å–ä¸Šä¼ çš„æ–‡ä»¶
            excel_file = pd.ExcelFile(excel_file_obj)
            if sheet_name not in excel_file.sheet_names:
                return {}, {}
                
            indicator_sheet = pd.read_excel(excel_file, sheet_name=sheet_name)
            
            # æ¸…ç†åˆ—å
            indicator_sheet.columns = indicator_sheet.columns.str.strip()
            
            # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
            if indicator_col not in indicator_sheet.columns or industry_col not in indicator_sheet.columns:
                return {}, {}
            
            # åˆ›å»ºè¡Œä¸šæ˜ å°„
            import unicodedata
            var_industry_map = {}
            for _, row in indicator_sheet.iterrows():
                indicator_name = row.get(indicator_col)
                industry_name = row.get(industry_col)
                
                if pd.notna(indicator_name) and pd.notna(industry_name):
                    # æ ‡å‡†åŒ–æŒ‡æ ‡åç§°
                    norm_indicator = unicodedata.normalize('NFKC', str(indicator_name)).strip().lower()
                    norm_industry = str(industry_name).strip()
                    if norm_indicator and norm_industry:
                        var_industry_map[norm_indicator] = norm_industry
            
            # åˆ›å»ºç±»å‹æ˜ å°„ï¼ˆå¦‚æœéœ€è¦ï¼‰
            var_type_map = {}
            if type_col in indicator_sheet.columns:
                for _, row in indicator_sheet.iterrows():
                    indicator_name = row.get(indicator_col)
                    type_name = row.get(type_col)
                    
                    if pd.notna(indicator_name) and pd.notna(type_name):
                        norm_indicator = unicodedata.normalize('NFKC', str(indicator_name)).strip().lower()
                        norm_type = str(type_name).strip()
                        if norm_indicator and norm_type:
                            var_type_map[norm_indicator] = norm_type
            
            return var_type_map, var_industry_map
            
        except Exception:
            return {}, {}

# --- æ–°å¢è¾…åŠ©å‡½æ•°ï¼šé‡ç½®æ¨¡å‹å‚æ•° --- 
def reset_model_parameters(ss):
    """å°†æ¨¡å‹è®­ç»ƒç›¸å…³çš„å‚æ•°é‡ç½®ä¸ºåˆå§‹å€¼ã€‚"""
    from datetime import datetime, timedelta
    
    # æ—¶é—´çª—å£è®¾ç½® - ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
    today = datetime.now().date()
    
    # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
    if CONFIG_AVAILABLE:
        years_back = TrainDefaults.TRAINING_YEARS_BACK
        val_end_year = TrainDefaults.VALIDATION_END_YEAR
        val_end_month = TrainDefaults.VALIDATION_END_MONTH
        val_end_day = TrainDefaults.VALIDATION_END_DAY
    else:
        # åå¤‡ç¡¬ç¼–ç å€¼
        years_back = 5
        val_end_year = 2024
        val_end_month = 12
        val_end_day = 31
    
    # é»˜è®¤è®­ç»ƒæœŸï¼šä»é…ç½®çš„å¹´æ•°å‰å¼€å§‹åˆ°1ä¸ªæœˆå‰
    ss.dfm_train_start_date_value = datetime(today.year - years_back, today.month, today.day)
    ss.dfm_train_end_date_value = datetime.combine(today - timedelta(days=30), datetime.min.time())
    
    # é»˜è®¤éªŒè¯æœŸç»“æŸæ—¥æœŸï¼šä½¿ç”¨é…ç½®
    ss.dfm_oos_validation_end_date_value = datetime(val_end_year, val_end_month, val_end_day)

    # å› å­å‚æ•°è®¾ç½® - ä½¿ç”¨é…ç½®
    if CONFIG_AVAILABLE:
        default_factor_strategy_options = list(UIDefaults.FACTOR_SELECTION_STRATEGY_OPTIONS.keys())
        default_strategy = TrainDefaults.FACTOR_SELECTION_STRATEGY
        max_iter = TrainDefaults.EM_MAX_ITER
        fixed_factors = TrainDefaults.FIXED_NUMBER_OF_FACTORS
        cum_threshold = TrainDefaults.CUM_VARIANCE_THRESHOLD
    else:
        # åå¤‡ç¡¬ç¼–ç å€¼
        default_factor_strategy_options = ['information_criteria', 'fixed_number', 'cumulative_variance']
        default_strategy = 'information_criteria'
        max_iter = TrainDefaults.EM_MAX_ITER if 'TrainDefaults' in globals() else 100
        if CONFIG_AVAILABLE:
            fixed_factors = TrainDefaults.FIXED_NUMBER_OF_FACTORS
        else:
            # ä½¿ç”¨é…ç½®æ¨¡å—å®šä¹‰çš„é»˜è®¤å€¼
            try:
                from ..config import TrainDefaults as FallbackDefaults
                fixed_factors = FallbackDefaults.FIXED_NUMBER_OF_FACTORS
            except ImportError:
                fixed_factors = 3  # æœ€ç»ˆåå¤‡å€¼
        if CONFIG_AVAILABLE:
            cum_threshold = TrainDefaults.CUM_VARIANCE_THRESHOLD
        else:
            cum_threshold = 0.8  # åå¤‡å€¼
    
    ss.dfm_factor_selection_strategy_idx = 0
    ss.dfm_factor_selection_strategy_value = default_strategy
    ss.dfm_n_factors_manual_value = ""

    # å› å­é€‰æ‹©ç­–ç•¥ç›¸å…³å‚æ•°çš„é»˜è®¤å€¼
    # ä¿¡æ¯å‡†åˆ™é˜ˆå€¼ä½¿ç”¨é»˜è®¤å€¼
    ss.dfm_information_criterion_threshold_value = UIDefaults.IC_MAX_FACTORS_DEFAULT if CONFIG_AVAILABLE else 0.1
    ss.dfm_fixed_factor_number_value = fixed_factors
    ss.dfm_common_variance_contribution_threshold_value = cum_threshold
    # æ–¹å·®é˜ˆå€¼ä½¿ç”¨é»˜è®¤å€¼
    ss.dfm_variance_threshold_value = UIDefaults.CUM_VARIANCE_MIN if CONFIG_AVAILABLE else 0.1

    # é«˜çº§å‚æ•°
    ss.dfm_max_iter = max_iter
    default_em_criterion_options = ['params', 'likelihood']
    ss.dfm_em_convergence_criterion_idx = 0
    ss.dfm_em_convergence_criterion_value = default_em_criterion_options[0]
    
    # å¦‚æœæœ‰å…¶ä»–é€šè¿‡keyç›´æ¥åœ¨UIä¸­è®¾ç½®çš„session_stateå˜é‡ï¼Œä¹Ÿéœ€è¦åœ¨è¿™é‡Œé‡ç½®
    # ä¾‹å¦‚ï¼šss.ss_dfm_max_iter = max_iter (å¦‚æœkeyä¸dfm_max_iterä¸åŒ)
    # ä½†é€šå¸¸æˆ‘ä»¬ä¼šç”¨ä¸€ä¸ªç»Ÿä¸€çš„dfm_ prefixed keyæ¥å­˜å‚¨å€¼ï¼ŒUIçš„keyåªç”¨äºstreamlitå†…éƒ¨

# å·²ç§»é™¤è‡ªåŠ¨æ—¥æœŸè®¾ç½®åŠŸèƒ½ï¼Œç”¨æˆ·å®Œå…¨æ§åˆ¶æ—¥æœŸè¾“å…¥

def render_dfm_train_model_tab(st_instance, session_state):
    # ç¡®ä¿datetimeåœ¨å‡½æ•°å¼€å¤´å°±å¯ç”¨
    from datetime import datetime, time

    # --- NEW: Display import errors if they occurred --- 
    if _TRAIN_UI_IMPORT_ERROR_MESSAGE:
        st_instance.error(f"æ¨¡å—å¯¼å…¥é”™è¯¯ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™:\n{_TRAIN_UI_IMPORT_ERROR_MESSAGE}")
        # Optionally, return here if critical modules failed to load
        # return 

    # --- ğŸ”¥ æ–°å¢ï¼šè‡ªåŠ¨çŠ¶æ€é‡ç½®æ£€æŸ¥ ---
    if _should_reset_training_state(session_state):
        _reset_training_state(session_state)
        st_instance.info("ğŸ”„ æ£€æµ‹åˆ°é¡µé¢åˆ·æ–°æˆ–æ•°æ®å˜æ›´ï¼Œå·²è‡ªåŠ¨é‡ç½®è®­ç»ƒçŠ¶æ€")

    # --- åˆå§‹åŒ–DFMæ¨¡å—çŠ¶æ€å˜é‡ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰ ---
    # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨åˆå§‹åŒ–DFMçŠ¶æ€
    if get_dfm_state('dfm_training_status') is None:
        set_dfm_state('dfm_training_status', "ç­‰å¾…å¼€å§‹")
    if get_dfm_state('dfm_model_results') is None:
        set_dfm_state('dfm_model_results', None)
    if get_dfm_state('dfm_training_log') is None:
        set_dfm_state('dfm_training_log', [])
    if get_dfm_state('dfm_model_results_paths') is None:
        set_dfm_state('dfm_model_results_paths', None)
    
    # åŒæ­¥å…¨å±€çŠ¶æ€åˆ°çŠ¶æ€ç®¡ç†å™¨ï¼ˆä»…åœ¨çŠ¶æ€æœªè¢«é‡ç½®æ—¶ï¼‰
    global _training_state
    
    if not session_state.get('dfm_force_reset_training_state', False):
        # å¼ºåˆ¶å®æ—¶çŠ¶æ€åŒæ­¥ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰
        set_dfm_state('dfm_training_status', _training_state['status'])
        set_dfm_state('dfm_training_log', _training_state['log'].copy())

        # ç‰¹åˆ«å¤„ç†è®­ç»ƒå®ŒæˆçŠ¶æ€
        if _training_state['status'] == 'è®­ç»ƒå®Œæˆ' and _training_state['results']:
            set_dfm_state('dfm_model_results_paths', _training_state['results'])
        elif _training_state['status'] == 'è®­ç»ƒå¤±è´¥':
            set_dfm_state('dfm_model_results_paths', None)
    
    # === è‡ªåŠ¨æ£€æµ‹åŠŸèƒ½å·²ç¦ç”¨ - ç”¨æˆ·ä¸å¸Œæœ›è‡ªåŠ¨æ¢å¤è®­ç»ƒçŠ¶æ€ ===
    
    # ç§»é™¤å·²æœ‰è®­ç»ƒç»“æœæ£€æµ‹åŠŸèƒ½ï¼Œä¸å†æ£€æŸ¥dym_estimateç›®å½•
    def _detect_existing_results():
        """ä¸å†æ£€æµ‹å·²å­˜åœ¨çš„è®­ç»ƒç»“æœæ–‡ä»¶ï¼Œæ‰€æœ‰ç»“æœé€šè¿‡UIä¸‹è½½è·å¾—"""
        return None
    
    # æ£€æµ‹å·²æœ‰ç»“æœå¹¶æ›´æ–°çŠ¶æ€ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰
    if (_training_state['status'] == 'ç­‰å¾…å¼€å§‹' and
        get_dfm_state('dfm_training_status') == 'ç­‰å¾…å¼€å§‹' and
        get_dfm_state('existing_results_checked') is None):

        set_dfm_state('existing_results_checked', True)
        existing_results = _detect_existing_results()

        if existing_results:
            # æ›´æ–°å…¨å±€çŠ¶æ€å’ŒçŠ¶æ€ç®¡ç†å™¨
            _training_state['status'] = 'è®­ç»ƒå®Œæˆ'
            _training_state['results'] = existing_results
            _training_state['log'] = ['[è‡ªåŠ¨æ£€æµ‹] å‘ç°å·²æœ‰è®­ç»ƒç»“æœï¼Œå·²è‡ªåŠ¨åŠ è½½']

            set_dfm_state('dfm_training_status', 'è®­ç»ƒå®Œæˆ')
            set_dfm_state('dfm_model_results_paths', existing_results)
            set_dfm_state('dfm_training_log', ['[è‡ªåŠ¨æ£€æµ‹] å‘ç°å·²æœ‰è®­ç»ƒç»“æœï¼Œå·²è‡ªåŠ¨åŠ è½½'])

            # åˆ·æ–°UIæ˜¾ç¤º
            st_instance.rerun()

    # ä»…åœ¨è®­ç»ƒçœŸæ­£å®Œæˆæ—¶åˆ·æ–°ä¸€æ¬¡ï¼ˆé¿å…é‡å¤ï¼‰
    if (_training_state['status'] == 'è®­ç»ƒå®Œæˆ' and
        get_dfm_state('dfm_training_status') != 'è®­ç»ƒå®Œæˆ' and
        get_dfm_state('training_completed_refreshed') is None):
        set_dfm_state('training_completed_refreshed', True)
        st_instance.rerun()

    # ç”¨æˆ·å®Œå…¨æ§åˆ¶æ—¥æœŸè®¾ç½®ï¼Œä¸è®¾ç½®ä»»ä½•è‡ªåŠ¨é»˜è®¤å€¼

    # --- æ•°æ®åŠ è½½ä¸å‡†å¤‡ ---
    input_df = session_state.get('dfm_prepared_data_df', None)
    available_target_vars = []
    if input_df is not None:
        # ä»å·²åŠ è½½æ•°æ®ä¸­è·å–å¯é€‰çš„ç›®æ ‡å˜é‡
        available_target_vars = [col for col in input_df.columns if 'date' not in col.lower() and 'time' not in col.lower() and col not in getattr(config, 'EXCLUDE_COLS_FROM_TARGET', [])]
        if not available_target_vars and hasattr(config, 'TARGET_VARIABLE') and config.TARGET_VARIABLE in input_df.columns:
            available_target_vars = [config.TARGET_VARIABLE] # Fallback to config if filtering results in empty
        elif not available_target_vars:
            st_instance.warning("é¢„å¤„ç†æ•°æ®ä¸­æœªæ‰¾åˆ°åˆé€‚çš„ç›®æ ‡å˜é‡å€™é€‰ã€‚")
    else:
        st_instance.warning("æ•°æ®å°šæœªå‡†å¤‡ï¼Œè¯·å…ˆåœ¨\"æ•°æ®å‡†å¤‡\"é€‰é¡¹å¡ä¸­å¤„ç†æ•°æ®ã€‚å˜é‡é€‰æ‹©åŠŸèƒ½å°†å—é™ã€‚")
        # å³ä½¿æ•°æ®æœªå‡†å¤‡å¥½ï¼Œä¹Ÿå°è¯•åŠ è½½æ˜ å°„ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥é¢„å…ˆæŸ¥çœ‹å¯é€‰å˜é‡ç»“æ„
        # å¦‚æœconfigä¸­å®šä¹‰äº†é»˜è®¤ç›®æ ‡å˜é‡ï¼Œå¯ä»¥è€ƒè™‘åœ¨è¿™é‡ŒåŠ å…¥ï¼Œä½†è¿™é€šå¸¸ä¾èµ–æ•°æ®åˆ—å­˜åœ¨
        if hasattr(config, 'TARGET_VARIABLE'):
             # We can't be sure it's a valid choice without data, so leave available_target_vars empty or add with caution
             pass 
    
    # åŠ è½½è¡Œä¸šä¸æŒ‡æ ‡æ˜ å°„
    # è·å–ä¸Šä¼ çš„è®­ç»ƒæ•°æ®æ–‡ä»¶ï¼ˆæ¥è‡ªdata_prepæ¨¡å—ï¼‰
    uploaded_training_file = session_state.get('dfm_training_data_file', None)
    
    # ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
    if CONFIG_AVAILABLE:
        default_type_sheet = DataDefaults.TYPE_MAPPING_SHEET
    else:
        default_type_sheet = DataDefaults.TYPE_MAPPING_SHEET if 'DataDefaults' in globals() else 'æŒ‡æ ‡ä½“ç³»'
    
    type_mapping_sheet = session_state.get('dfm_param_type_mapping_sheet', default_type_sheet)
    
    # ğŸ”¥ ä¿®å¤ï¼šä¼ å…¥å®é™…æ•°æ®çš„åˆ—åæ¥è¿‡æ»¤æŒ‡æ ‡ä½“ç³»
    available_data_columns = list(input_df.columns) if input_df is not None else None
    
    # load_indicator_mappings_from_data_prep ç°åœ¨è¿”å›: unique_industries, var_to_indicators_map_by_industry, _ (all_flat_indicators, not directly used here)
    map_data = load_indicator_mappings_from_data_prep(uploaded_training_file, type_mapping_sheet, available_data_columns)
    if map_data and len(map_data) == 3:
        unique_industries, var_to_indicators_map_by_industry, _ = map_data # è§£åŒ…ä¸‰ä¸ªå€¼
        if not unique_industries or not var_to_indicators_map_by_industry:
            st_instance.warning("è­¦å‘Šï¼šåŠ è½½çš„è¡Œä¸šæˆ–æŒ‡æ ‡æ˜ å°„ä¸å®Œæ•´æˆ–ä¸ºç©ºã€‚è¯·æ£€æŸ¥ `load_indicator_mappings_from_data_prep` å‡½æ•°å’ŒExcelæ–‡ä»¶ã€‚")
            # Fallback to empty to prevent errors, but UI will be limited
            if not unique_industries: unique_industries = []
            if not var_to_indicators_map_by_industry: var_to_indicators_map_by_industry = {}
    else:
        st_instance.error("é”™è¯¯ï¼š`load_indicator_mappings_from_data_prep`æœªèƒ½è¿”å›é¢„æœŸçš„æ˜ å°„æ•°æ® (é¢„æœŸ3ä¸ªå…ƒç´ )ã€‚")
        unique_industries = []
        var_to_indicators_map_by_industry = {}

    # ä¸»å¸ƒå±€ï¼šç°åœ¨æ˜¯ä¸Šä¸‹ç»“æ„ï¼Œä¸å†ä½¿ç”¨åˆ—
    # REMOVED: var_selection_col, param_col = st_instance.columns([1, 1.5]) 

    # --- å˜é‡é€‰æ‹©éƒ¨åˆ† (ä¹‹å‰åœ¨ var_selection_col) ---

    # 1. é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰
    # åˆå§‹åŒ–ç›®æ ‡å˜é‡çŠ¶æ€
    if get_dfm_state('dfm_target_variable') is None and available_target_vars:
        set_dfm_state('dfm_target_variable', available_target_vars[0])
    elif not available_target_vars:
        set_dfm_state('dfm_target_variable', None)

    current_target_var = get_dfm_state('dfm_target_variable')
    selected_target_var = st_instance.selectbox(
        "**é€‰æ‹©ç›®æ ‡å˜é‡**",
        options=available_target_vars,
        index=available_target_vars.index(current_target_var) if current_target_var and current_target_var in available_target_vars else 0,
        key="ss_dfm_target_variable",
        help="é€‰æ‹©æ‚¨å¸Œæœ›æ¨¡å‹é¢„æµ‹çš„ç›®æ ‡åºåˆ—ã€‚"
    )
    set_dfm_state('dfm_target_variable', selected_target_var)
    

    # 2. é€‰æ‹©è¡Œä¸šå˜é‡ (å¤é€‰æ¡†å½¢å¼ï¼Œé»˜è®¤å…¨é€‰)ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰
    st_instance.markdown("**é€‰æ‹©è¡Œä¸š**")
    if get_dfm_state('dfm_industry_checkbox_states') is None and unique_industries:
        set_dfm_state('dfm_industry_checkbox_states', {industry: True for industry in unique_industries})
    elif not unique_industries:
        set_dfm_state('dfm_industry_checkbox_states', {})
    
    # ä¸ºäº†é¿å…åœ¨æ²¡æœ‰è¡Œä¸šæ—¶å‡ºé”™ï¼Œæ£€æŸ¥ unique_industries
    if not unique_industries:
        st_instance.info("æ²¡æœ‰å¯ç”¨çš„è¡Œä¸šæ•°æ®ã€‚")
    else:
        # åˆ›å»ºåˆ—ä»¥æ›´å¥½åœ°å¸ƒå±€å¤é€‰æ¡†
        if CONFIG_AVAILABLE:
            num_cols_industry = UIDefaults.NUM_COLS_INDUSTRY
        else:
            num_cols_industry = 3
        
        industry_cols = st_instance.columns(num_cols_industry)
        col_idx = 0
        current_checkbox_states = get_dfm_state('dfm_industry_checkbox_states', {})
        for industry_name in unique_industries:
            with industry_cols[col_idx % num_cols_industry]:
                new_state = st_instance.checkbox(
                    industry_name,
                    value=current_checkbox_states.get(industry_name, True),
                    key=f"ss_dfm_industry_cb_{industry_name}"
                )
                current_checkbox_states[industry_name] = new_state
            col_idx += 1

        # æ›´æ–°çŠ¶æ€ç®¡ç†å™¨
        set_dfm_state('dfm_industry_checkbox_states', current_checkbox_states)

        # å›è°ƒå‡½æ•°ï¼šå–æ¶ˆå…¨é€‰è¡Œä¸š
        def on_deselect_all_industries_change():
            if get_dfm_state('ss_dfm_deselect_all_industries', False):
                set_dfm_state('dfm_industry_checkbox_states', {industry: False for industry in unique_industries})
                # é‡ç½®"å–æ¶ˆå…¨é€‰è¡Œä¸š"å¤é€‰æ¡†çš„çŠ¶æ€ï¼Œä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨
                set_dfm_state('ss_dfm_deselect_all_industries', False)

        st_instance.checkbox(
            "å–æ¶ˆå…¨é€‰è¡Œä¸š", 
            key='ss_dfm_deselect_all_industries',
            on_change=on_deselect_all_industries_change,
            help="å‹¾é€‰æ­¤æ¡†å°†å–æ¶ˆæ‰€æœ‰å·²é€‰ä¸­çš„è¡Œä¸šã€‚"
        )

    # æ›´æ–°å½“å‰é€‰ä¸­çš„è¡Œä¸šåˆ—è¡¨ï¼ˆå…¼å®¹æ–°æ—§çŠ¶æ€ç®¡ç†ï¼‰
    current_checkbox_states = get_dfm_state('dfm_industry_checkbox_states', {})
    selected_industries = [
        industry for industry, checked in current_checkbox_states.items() if checked
    ]
    set_dfm_state('dfm_selected_industries', selected_industries)
 
    # 3. æ ¹æ®é€‰å®šè¡Œä¸šé€‰æ‹©é¢„æµ‹æŒ‡æ ‡ (æ¯ä¸ªè¡Œä¸šä¸€ä¸ªå¤šé€‰ä¸‹æ‹‰èœå•ï¼Œé»˜è®¤å…¨é€‰)
    st_instance.markdown("**é€‰æ‹©é¢„æµ‹æŒ‡æ ‡**")
    if 'dfm_selected_indicators_per_industry' not in session_state:
        session_state.dfm_selected_indicators_per_industry = {}

    final_selected_indicators_flat = []
    if not session_state.dfm_selected_industries:
        st_instance.info("è¯·å…ˆåœ¨ä¸Šæ–¹é€‰æ‹©è‡³å°‘ä¸€ä¸ªè¡Œä¸šã€‚")
    else:
        for industry_name in session_state.dfm_selected_industries:
            st_instance.markdown(f"**è¡Œä¸š: {industry_name}**")
            indicators_for_this_industry = var_to_indicators_map_by_industry.get(industry_name, [])
            
            if not indicators_for_this_industry:
                st_instance.text(f"  (è¯¥è¡Œä¸šæ— å¯ç”¨æŒ‡æ ‡)")
                session_state.dfm_selected_indicators_per_industry[industry_name] = []
                continue

            # é»˜è®¤é€‰ä¸­è¯¥è¡Œä¸šä¸‹çš„æ‰€æœ‰æŒ‡æ ‡
            default_selection_for_industry = session_state.dfm_selected_indicators_per_industry.get(
                industry_name, 
                indicators_for_this_industry # é»˜è®¤å…¨é€‰
            )
            # ç¡®ä¿é»˜è®¤å€¼æ˜¯å®é™…å¯é€‰åˆ—è¡¨çš„å­é›†
            valid_default = [item for item in default_selection_for_industry if item in indicators_for_this_industry]
            if not valid_default and indicators_for_this_industry: # å¦‚æœä¹‹å‰å­˜çš„é»˜è®¤å€¼æ— æ•ˆäº†ï¼Œä¸”å½“å‰æœ‰å¯é€‰æŒ‡æ ‡ï¼Œåˆ™å…¨é€‰
                valid_default = indicators_for_this_industry
            
            # å›è°ƒå‡½æ•°å·¥å‚ï¼šä¸ºç‰¹å®šè¡Œä¸šçš„æŒ‡æ ‡å–æ¶ˆå…¨é€‰
            def make_on_deselect_all_indicators_change(current_industry_key):
                def on_change_callback():
                    checkbox_key = f'ss_dfm_deselect_all_indicators_{current_industry_key}'
                    multiselect_key = f'ss_dfm_indicators_{current_industry_key}'
                    if session_state.get(checkbox_key, False):
                        session_state[multiselect_key] = [] # æ¸…ç©ºè¯¥è¡Œä¸šå·²é€‰æŒ‡æ ‡
                        session_state[checkbox_key] = False # é‡ç½®å–æ¶ˆå…¨é€‰å¤é€‰æ¡†
                        # st_instance.rerun() # åŒæ ·ï¼Œrerunéœ€è°¨æ…
                return on_change_callback

            st_instance.checkbox(
                f"å–æ¶ˆå…¨é€‰ {industry_name} æŒ‡æ ‡",
                key=f'ss_dfm_deselect_all_indicators_{industry_name}',
                on_change=make_on_deselect_all_indicators_change(industry_name),
                help=f"å‹¾é€‰æ­¤æ¡†å°†å–æ¶ˆæ‰€æœ‰å·²ä¸º '{industry_name}' é€‰ä¸­çš„æŒ‡æ ‡ã€‚"
            )

            selected_in_widget = st_instance.multiselect(
                f"ä¸º '{industry_name}' é€‰æ‹©æŒ‡æ ‡",
                options=indicators_for_this_industry,
                default=valid_default,
                key=f"ss_dfm_indicators_{industry_name}",
                help=f"ä» {industry_name} è¡Œä¸šä¸­é€‰æ‹©é¢„æµ‹æŒ‡æ ‡ã€‚"
            )

            # ğŸ”¥ ä¿®å¤ï¼šæ›´æ–°session_stateä¸­çš„é€‰æ‹©çŠ¶æ€
            session_state.dfm_selected_indicators_per_industry[industry_name] = selected_in_widget

            # ğŸ”¥ æ–°å¢ï¼šå®æ—¶è°ƒè¯•æ¯ä¸ªè¡Œä¸šçš„å˜é‡é€‰æ‹©
            print(f"ğŸ” [è¡Œä¸šå˜é‡é€‰æ‹©] {industry_name}:")
            print(f"   å¯ç”¨æŒ‡æ ‡æ•°: {len(indicators_for_this_industry)}")
            print(f"   é»˜è®¤é€‰æ‹©æ•°: {len(valid_default)}")
            print(f"   å®é™…é€‰æ‹©æ•°: {len(selected_in_widget)}")
            print(f"   session_stateä¸­è®°å½•æ•°: {len(session_state.dfm_selected_indicators_per_industry.get(industry_name, []))}")
            if len(selected_in_widget) != len(indicators_for_this_industry):
                unselected = set(indicators_for_this_industry) - set(selected_in_widget)
                print(f"   âŒ æœªé€‰æ‹©çš„æŒ‡æ ‡: {list(unselected)[:3]}{'...' if len(unselected) > 3 else ''}")

            final_selected_indicators_flat.extend(selected_in_widget)
        
        # æ¸…ç† session_state.dfm_selected_indicators_per_industry ä¸­ä¸å†è¢«é€‰ä¸­çš„è¡Œä¸šæ¡ç›®
        industries_to_remove_from_state = [
            ind for ind in session_state.dfm_selected_indicators_per_industry 
            if ind not in session_state.dfm_selected_industries
        ]
        for ind_to_remove in industries_to_remove_from_state:
            del session_state.dfm_selected_indicators_per_industry[ind_to_remove]

    # æ›´æ–°æœ€ç»ˆçš„æ‰å¹³åŒ–é¢„æµ‹æŒ‡æ ‡åˆ—è¡¨ (å»é‡)
    session_state.dfm_selected_indicators = sorted(list(set(final_selected_indicators_flat)))

    # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¯¦ç»†çš„å˜é‡é€‰æ‹©è°ƒè¯•ä¿¡æ¯
    print(f"\n" + "="*80)
    print(f"ğŸ”ğŸ”ğŸ” [UIå˜é‡é€‰æ‹©è°ƒè¯•] è¯¦ç»†åˆ†æå˜é‡é€‰æ‹©è¿‡ç¨‹")
    print(f"="*80)

    print(f"ğŸ“‹ è¡Œä¸šé€‰æ‹©çŠ¶æ€:")
    print(f"   é€‰æ‹©çš„è¡Œä¸šæ•°é‡: {len(session_state.dfm_selected_industries)}")
    print(f"   é€‰æ‹©çš„è¡Œä¸šåˆ—è¡¨: {session_state.dfm_selected_industries}")

    print(f"\nğŸ“Š æ¯ä¸ªè¡Œä¸šçš„å˜é‡é€‰æ‹©è¯¦æƒ…:")
    total_available_vars = 0
    total_selected_vars = 0

    for industry_name in session_state.dfm_selected_industries:
        available_vars = var_to_indicators_map_by_industry.get(industry_name, [])
        selected_vars = session_state.dfm_selected_indicators_per_industry.get(industry_name, [])

        total_available_vars += len(available_vars)
        total_selected_vars += len(selected_vars)

        print(f"   ğŸ­ {industry_name}:")
        print(f"      å¯ç”¨å˜é‡æ•°: {len(available_vars)}")
        print(f"      å·²é€‰å˜é‡æ•°: {len(selected_vars)}")
        print(f"      é€‰æ‹©ç‡: {len(selected_vars)/len(available_vars)*100:.1f}%" if available_vars else "N/A")

        if len(selected_vars) < len(available_vars):
            missing_vars = set(available_vars) - set(selected_vars)
            print(f"      âŒ æœªé€‰æ‹©çš„å˜é‡ ({len(missing_vars)}ä¸ª): {list(missing_vars)[:5]}{'...' if len(missing_vars) > 5 else ''}")

    print(f"\nğŸ“ˆ å˜é‡é€‰æ‹©æ±‡æ€»:")
    print(f"   æ€»å¯ç”¨å˜é‡æ•°: {total_available_vars}")
    print(f"   æ€»å·²é€‰å˜é‡æ•°: {total_selected_vars}")
    print(f"   æ€»ä½“é€‰æ‹©ç‡: {total_selected_vars/total_available_vars*100:.1f}%" if total_available_vars else "N/A")

    print(f"\nğŸ”§ æœ€ç»ˆå˜é‡åˆ—è¡¨å¤„ç†:")
    print(f"   final_selected_indicators_flaté•¿åº¦: {len(final_selected_indicators_flat)}")
    print(f"   å»é‡å‰å˜é‡æ•°: {len(final_selected_indicators_flat)}")
    print(f"   å»é‡åå˜é‡æ•°: {len(session_state.dfm_selected_indicators)}")

    if len(final_selected_indicators_flat) != len(session_state.dfm_selected_indicators):
        duplicates = len(final_selected_indicators_flat) - len(session_state.dfm_selected_indicators)
        print(f"   âš ï¸ å‘ç°é‡å¤å˜é‡: {duplicates}ä¸ª")

    print(f"\nğŸ¯ æœ€ç»ˆç»“æœ:")
    print(f"   ç›®æ ‡å˜é‡: {session_state.dfm_target_variable}")
    print(f"   é¢„æµ‹å˜é‡æ•°: {len(session_state.dfm_selected_indicators)}")
    print(f"   é¢„æµ‹å˜é‡åˆ—è¡¨: {session_state.dfm_selected_indicators}")

    print(f"="*80)

    # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯ (å¯é€‰)
    st_instance.markdown("--- ")
    st_instance.text(f" - ç›®æ ‡å˜é‡: {session_state.dfm_target_variable if session_state.dfm_target_variable else 'æœªé€‰æ‹©'}")
    st_instance.text(f" - é€‰å®šè¡Œä¸šæ•°: {len(session_state.dfm_selected_industries)}")
    st_instance.text(f" - é€‰å®šé¢„æµ‹æŒ‡æ ‡æ€»æ•°: {len(session_state.dfm_selected_indicators)}")

    # ğŸ”¥ æ–°å¢ï¼šåœ¨UIä¸­æ˜¾ç¤ºè¯¦ç»†çš„å˜é‡é€‰æ‹©ä¿¡æ¯
    with st_instance.expander("ğŸ” å˜é‡é€‰æ‹©è¯¦æƒ… (è°ƒè¯•ä¿¡æ¯)", expanded=False):
        st_instance.write("**æ¯ä¸ªè¡Œä¸šçš„å˜é‡é€‰æ‹©çŠ¶æ€:**")

        debug_info = []
        for industry_name in session_state.dfm_selected_industries:
            available_vars = var_to_indicators_map_by_industry.get(industry_name, [])
            selected_vars = session_state.dfm_selected_indicators_per_industry.get(industry_name, [])

            selection_rate = len(selected_vars)/len(available_vars)*100 if available_vars else 0

            debug_info.append({
                "è¡Œä¸š": industry_name,
                "å¯ç”¨å˜é‡æ•°": len(available_vars),
                "å·²é€‰å˜é‡æ•°": len(selected_vars),
                "é€‰æ‹©ç‡": f"{selection_rate:.1f}%"
            })

        if debug_info:
            debug_df = pd.DataFrame(debug_info)
            st_instance.dataframe(debug_df, use_container_width=True)

            total_available = sum(row["å¯ç”¨å˜é‡æ•°"] for row in debug_info)
            total_selected = sum(row["å·²é€‰å˜é‡æ•°"] for row in debug_info)

            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨å®é™…é€‰æ‹©çš„å˜é‡æ•°é‡è€Œä¸æ˜¯debug_infoçš„ç»Ÿè®¡
            # é—®é¢˜ï¼šdebug_infoå¯èƒ½åŒ…å«æ‰€æœ‰å¯ç”¨å˜é‡ï¼Œå¯¼è‡´æ˜¾ç¤ºé”™è¯¯çš„é€‰æ‹©ç‡
            actual_selected_count = len(session_state.dfm_selected_indicators)

            # ğŸ”¥ æ–°å¢ï¼šè¯¦ç»†çš„å˜é‡è®¡æ•°è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ” [UIå˜é‡è®¡æ•°ä¿®å¤] å˜é‡è®¡æ•°å¯¹æ¯”:")
            print(f"   debug_infoç»Ÿè®¡çš„å·²é€‰å˜é‡æ•°: {total_selected}")
            print(f"   session_stateå®é™…é€‰æ‹©å˜é‡æ•°: {actual_selected_count}")
            print(f"   debug_infoç»Ÿè®¡çš„å¯ç”¨å˜é‡æ•°: {total_available}")

            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨å®é™…çš„å˜é‡é€‰æ‹©æ•°é‡æ˜¾ç¤º
            if actual_selected_count > 0:
                # ä½¿ç”¨å®é™…é€‰æ‹©çš„å˜é‡æ•°é‡
                st_instance.write(f"**æ€»è®¡:** {actual_selected_count} ä¸ªå˜é‡è¢«é€‰æ‹©")

                # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºè¯¦ç»†çš„é€‰æ‹©ä¿¡æ¯
                if total_available > 0:
                    selection_rate = (actual_selected_count / total_available) * 100
                    st_instance.write(f"**é€‰æ‹©ç‡:** {actual_selected_count}/{total_available} ({selection_rate:.1f}%)")

                # ğŸ”¥ æ–°å¢ï¼šå¦‚æœå‘ç°è®¡æ•°ä¸ä¸€è‡´ï¼Œæ˜¾ç¤ºè­¦å‘Š
                if total_selected != actual_selected_count:
                    st_instance.warning(f"âš ï¸ æ³¨æ„ï¼šè¡Œä¸šç»Ÿè®¡æ˜¾ç¤º{total_selected}ä¸ªå˜é‡ï¼Œä½†å®é™…é€‰æ‹©äº†{actual_selected_count}ä¸ªå˜é‡")
            else:
                st_instance.write("**æ€»è®¡:** 0 ä¸ªå˜é‡è¢«é€‰æ‹©")
        else:
            st_instance.write("æœªé€‰æ‹©ä»»ä½•è¡Œä¸š")

    # with st_instance.expander("æŸ¥çœ‹å·²é€‰æŒ‡æ ‡åˆ—è¡¨"):
    #     st_instance.json(session_state.dfm_selected_indicators if session_state.dfm_selected_indicators else [])

    # --- æ¨¡å‹å‚æ•°é…ç½®éƒ¨åˆ† (ä¹‹å‰åœ¨ param_col) ---
    st_instance.markdown("--- ") # åˆ†éš”çº¿ï¼Œå°†å˜é‡é€‰æ‹©ä¸å‚æ•°é…ç½®åˆ†å¼€
    st_instance.subheader("æ¨¡å‹å‚æ•°")

    # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
    col1_time, col2_factor_core, col3_factor_specific = st_instance.columns(3)

    # --- ç¬¬ä¸€åˆ—: æ—¶é—´çª—å£è®¾ç½® ---
    with col1_time:
       
        
        # è®¡ç®—åŸºäºæ•°æ®çš„æ™ºèƒ½é»˜è®¤å€¼
        def get_data_based_date_defaults():
            """åŸºäºå®é™…æ•°æ®è®¡ç®—æ—¥æœŸé»˜è®¤å€¼ï¼Œä¼˜å…ˆä½¿ç”¨æ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„æ—¥æœŸè¾¹ç•Œ"""
            from datetime import datetime, timedelta
            today = datetime.now().date()
            
            # ğŸ”¥ æ–°å¢ï¼šä¼˜å…ˆä½¿ç”¨æ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„æ—¥æœŸè¾¹ç•Œ
            data_prep_start = session_state.get('dfm_param_data_start_date')
            data_prep_end = session_state.get('dfm_param_data_end_date')
            
            # ğŸ”¥ ä¿®å¤ï¼šéªŒè¯æœŸåº”è¯¥æ˜¯å†å²æœŸé—´ï¼Œä¸åº”è¯¥åŒ…å«æœªæ¥æ—¥æœŸ
            static_defaults = {
                'training_start': data_prep_start if data_prep_start else datetime(today.year - 5, 1, 1).date(),
                'validation_start': datetime(2024, 7, 1).date(),  # 2024å¹´7æœˆ1æ—¥
                'validation_end': datetime(2024, 12, 31).date()  # ğŸ”¥ ä¿®å¤ï¼šéªŒè¯æœŸç»“æŸäº2024å¹´12æœˆ31æ—¥
            }
            
            try:
                data_df = session_state.get('dfm_prepared_data_df')
                if data_df is not None and isinstance(data_df.index, pd.DatetimeIndex) and len(data_df.index) > 0:
                    # ä»æ•°æ®è·å–ç¬¬ä¸€æœŸå’Œæœ€åä¸€æœŸ
                    data_first_date = data_df.index.min().date()  # ç¬¬ä¸€æœŸæ•°æ®
                    data_last_date = data_df.index.max().date()   # æœ€åä¸€æœŸæ•°æ®
                    
                    # é‡è¦ï¼šç¡®ä¿æ•°æ®çš„æœ€åæ—¥æœŸä¸æ˜¯æœªæ¥æ—¥æœŸ
                    if data_last_date > today:
                        print(f"âš ï¸ è­¦å‘Š: æ•°æ®åŒ…å«æœªæ¥æ—¥æœŸ {data_last_date}ï¼Œå°†ä½¿ç”¨ä»Šå¤©ä½œä¸ºæœ€åæ—¥æœŸ")
                        data_last_date = today
                    
                    # ğŸ”¥ ä¿®å¤ï¼šè®­ç»ƒå¼€å§‹æ—¥æœŸä¼˜å…ˆä½¿ç”¨æ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„è¾¹ç•Œ
                    training_start_date = data_prep_start if data_prep_start else data_first_date
                    
                    # è®¡ç®—éªŒè¯æœŸå¼€å§‹æ—¥æœŸï¼šä½¿ç”¨æ•°æ®æ—¶é—´èŒƒå›´çš„80%ä½œä¸ºè®­ç»ƒæœŸ
                    if data_prep_start and data_prep_end:
                        # å¦‚æœæ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®äº†è¾¹ç•Œï¼ŒåŸºäºè¾¹ç•Œè®¡ç®—
                        total_days = (data_prep_end - data_prep_start).days
                        training_days = int(total_days * 0.8)
                        validation_start_date = data_prep_start + timedelta(days=training_days)
                    else:
                        # å¦åˆ™åŸºäºå®é™…æ•°æ®è®¡ç®—
                        total_days = (data_last_date - data_first_date).days
                        training_days = int(total_days * 0.8)
                        validation_start_date = data_first_date + timedelta(days=training_days)
                    
                    # ç¡®ä¿éªŒè¯æœŸå¼€å§‹æ—¥æœŸä¸æ˜¯æœªæ¥æ—¥æœŸ
                    if validation_start_date > today:
                        validation_start_date = today - timedelta(days=30)  # 1ä¸ªæœˆå‰
                    
                    # ğŸ”¥ ä¿®å¤ï¼šéªŒè¯æœŸç»“æŸæ—¥æœŸå¿…é¡»æ˜¯å†å²æœŸé—´ï¼Œä¸èƒ½åŒ…å«æœªæ¥
                    # éªŒè¯æœŸç”¨äºæµ‹è¯•æ¨¡å‹æ€§èƒ½ï¼Œå¿…é¡»ä½¿ç”¨å†å²æ•°æ®
                    validation_end_date = datetime(2024, 12, 31).date()  # ğŸ”¥ å¼ºåˆ¶ä½¿ç”¨2024å¹´åº•ä½œä¸ºéªŒè¯æœŸç»“æŸ

                    # éªŒè¯æ—¥æœŸé€»è¾‘çš„åˆç†æ€§
                    if validation_start_date >= validation_end_date:
                        # å¦‚æœéªŒè¯æœŸå¼€å§‹æ™šäºæˆ–ç­‰äºç»“æŸï¼Œé‡æ–°è®¡ç®—
                        # ğŸ”¥ ä¿®å¤ï¼šéªŒè¯æœŸç»“æŸæ—¥æœŸå¿…é¡»æ˜¯å†å²æœŸé—´
                        validation_end_date = datetime(2024, 12, 31).date()  # ğŸ”¥ å¼ºåˆ¶ä½¿ç”¨2024å¹´åº•
                        validation_start_date = validation_end_date - timedelta(days=90)  # éªŒè¯æœŸ3ä¸ªæœˆ
                    
                    return {
                        'training_start': training_start_date,       # ğŸ”¥ è®­ç»ƒå¼€å§‹æ—¥ï¼šä¼˜å…ˆä½¿ç”¨æ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®
                        'validation_start': validation_start_date,   # éªŒè¯å¼€å§‹æ—¥ï¼šè®¡ç®—å¾—å‡º
                        'validation_end': validation_end_date        # ğŸ”¥ éªŒè¯ç»“æŸæ—¥ï¼šä¼˜å…ˆä½¿ç”¨æ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®
                    }
                else:
                    return static_defaults
            except Exception as e:
                print(f"âš ï¸ è®¡ç®—æ•°æ®é»˜è®¤æ—¥æœŸå¤±è´¥: {e}ï¼Œä½¿ç”¨é™æ€é»˜è®¤å€¼")
                return static_defaults
        
        # è·å–æ™ºèƒ½é»˜è®¤å€¼
        date_defaults = get_data_based_date_defaults()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®ï¼Œå¦‚æœæœ‰åˆ™å¼ºåˆ¶æ›´æ–°é»˜è®¤å€¼
        has_data = session_state.get('dfm_prepared_data_df') is not None
        if has_data:
            data_df = session_state['dfm_prepared_data_df']
            if isinstance(data_df.index, pd.DatetimeIndex) and len(data_df.index) > 0:
                # è®¡ç®—æ•°æ®çš„å®é™…æ—¥æœŸèŒƒå›´ç”¨äºæ¯”è¾ƒ
                actual_data_start = data_df.index.min().date()
                actual_data_end = data_df.index.max().date()
                
                # å¼ºåˆ¶æ›´æ–°session_stateä¸­çš„æ—¥æœŸé»˜è®¤å€¼ï¼ˆæ£€æŸ¥æ˜¯å¦ä¸ºé™æ€é»˜è®¤å€¼æˆ–ä¸æ•°æ®ä¸åŒ¹é…ï¼‰
                current_training_start = session_state.get('dfm_training_start_date')
                if (current_training_start == datetime(2010, 1, 1).date() or 
                    'dfm_training_start_date' not in session_state or
                    current_training_start != actual_data_start):
                    session_state.dfm_training_start_date = date_defaults['training_start']
                
                current_validation_start = session_state.get('dfm_validation_start_date')  
                if (current_validation_start == datetime(2020, 12, 31).date() or 
                    'dfm_validation_start_date' not in session_state):
                    session_state.dfm_validation_start_date = date_defaults['validation_start']
                
                current_validation_end = session_state.get('dfm_validation_end_date')
                if (current_validation_end == datetime(2022, 12, 31).date() or
                    'dfm_validation_end_date' not in session_state):
                    # ğŸ”¥ ä¿®å¤ï¼šç§»é™¤ä¸actual_data_endçš„æ¯”è¾ƒï¼Œé¿å…å¼ºåˆ¶ä½¿ç”¨æœªæ¥æ—¥æœŸ
                    session_state.dfm_validation_end_date = date_defaults['validation_end']
                
                # ç®€åŒ–æ•°æ®èŒƒå›´ä¿¡æ¯
                data_start = data_df.index.min().strftime('%Y-%m-%d')
                data_end = data_df.index.max().strftime('%Y-%m-%d')
                data_count = len(data_df.index)
                # ğŸ”¥ åˆ é™¤è“è‰²æç¤ºä¿¡æ¯ï¼ˆç”¨æˆ·è¦æ±‚ç§»é™¤ï¼‰
                # st_instance.info(f"ğŸ“Š æ•°æ®: {data_start} è‡³ {data_end} ({data_count}ç‚¹)")
                

        
        # 1. è®­ç»ƒæœŸå¼€å§‹æ—¥æœŸ
        session_state.dfm_training_start_date = st_instance.date_input(
            "è®­ç»ƒæœŸå¼€å§‹æ—¥æœŸ (Training Start Date)", 
            value=session_state.get('dfm_training_start_date', date_defaults['training_start']),
            key='dfm_training_start_date_input',
            help="é€‰æ‹©æ¨¡å‹è®­ç»ƒæ•°æ®çš„èµ·å§‹æ—¥æœŸã€‚é»˜è®¤ä¸ºæ•°æ®çš„ç¬¬ä¸€æœŸã€‚"
        )
        # 2. éªŒè¯æœŸå¼€å§‹æ—¥æœŸ
        session_state.dfm_validation_start_date = st_instance.date_input(
            "éªŒè¯æœŸå¼€å§‹æ—¥æœŸ (Validation Start Date)", 
            value=session_state.get('dfm_validation_start_date', date_defaults['validation_start']),
            key='dfm_validation_start_date_input',
            help="é€‰æ‹©éªŒè¯æœŸå¼€å§‹æ—¥æœŸã€‚é»˜è®¤ä¸ºæœ€åä¸€æœŸæ•°æ®å‰3ä¸ªæœˆã€‚"
        )
        # 3. éªŒè¯æœŸç»“æŸæ—¥æœŸ
        session_state.dfm_validation_end_date = st_instance.date_input(
            "éªŒè¯æœŸç»“æŸæ—¥æœŸ (Validation End Date)", 
            value=session_state.get('dfm_validation_end_date', date_defaults['validation_end']),
            key='dfm_validation_end_date_input',
            help="é€‰æ‹©éªŒè¯æœŸç»“æŸæ—¥æœŸã€‚é»˜è®¤ä¸ºæ•°æ®çš„æœ€åä¸€æœŸã€‚"
        )

    # --- ç¬¬äºŒåˆ—: å˜é‡é€‰æ‹©å‚æ•° ---
    with col2_factor_core:
        
        
        # ğŸ”¥ æ–°å¢ï¼šå˜é‡é€‰æ‹©æ–¹æ³•
        if CONFIG_AVAILABLE:
            variable_selection_options = UIDefaults.VARIABLE_SELECTION_OPTIONS
            default_var_method = TrainDefaults.VARIABLE_SELECTION_METHOD
        else:
            variable_selection_options = {
                'none': "æ— ç­›é€‰ (ä½¿ç”¨å…¨éƒ¨å·²é€‰å˜é‡)",
                'global_backward': "å…¨å±€åå‘å‰”é™¤ (åœ¨å·²é€‰å˜é‡ä¸­ç­›é€‰)"
            }
            default_var_method = 'none'  # ğŸ”¥ ç´§æ€¥ä¿®å¤ï¼šå¼ºåˆ¶é»˜è®¤ä¸ºnone
        
        # è·å–å½“å‰å˜é‡é€‰æ‹©æ–¹æ³•
        current_var_method = session_state.get('dfm_variable_selection_method', default_var_method)
        
        session_state.dfm_variable_selection_method = st_instance.selectbox(
            "å˜é‡é€‰æ‹©æ–¹æ³•",
            options=list(variable_selection_options.keys()),
            format_func=lambda x: variable_selection_options[x],
            index=list(variable_selection_options.keys()).index(current_var_method),
            key='dfm_variable_selection_method_input',
            help=(
                "é€‰æ‹©åœ¨å·²é€‰å˜é‡åŸºç¡€ä¸Šçš„ç­›é€‰æ–¹æ³•ï¼š\n"
                "- æ— ç­›é€‰: ç›´æ¥ä½¿ç”¨æ‰€æœ‰å·²é€‰æ‹©çš„å˜é‡\n"
                "- å…¨å±€åå‘å‰”é™¤: ä»å·²é€‰å˜é‡å¼€å§‹ï¼Œé€ä¸ªå‰”é™¤ä¸é‡è¦çš„å˜é‡"
            )
        )
        
        # ğŸ”¥ ä¿®å¤ï¼šæ ¹æ®é€‰æ‹©çš„æ–¹æ³•ç¡®å®šæ˜¯å¦å¯ç”¨å˜é‡é€‰æ‹©
        session_state.dfm_enable_variable_selection = (session_state.dfm_variable_selection_method != 'none')
        
        # å¦‚æœç¦ç”¨äº†å˜é‡é€‰æ‹©ï¼Œå¼ºåˆ¶è®¾ç½®æ–¹æ³•ä¸ºnone
        if not session_state.dfm_enable_variable_selection:
            session_state.dfm_variable_selection_method = 'none'        
        
        
        # æœ€å¤§è¿­ä»£æ¬¡æ•° (EMç®—æ³•)
        if CONFIG_AVAILABLE:
            max_iter_default = UIDefaults.MAX_ITERATIONS_DEFAULT
            max_iter_min = UIDefaults.MAX_ITERATIONS_MIN
            max_iter_step = UIDefaults.MAX_ITERATIONS_STEP
        else:
            max_iter_default = UIDefaults.MAX_ITERATIONS_DEFAULT if 'UIDefaults' in globals() else 30
            max_iter_min = 1
            max_iter_step = 10
            
        session_state.dfm_max_iterations = st_instance.number_input(
            "æœ€å¤§è¿­ä»£æ¬¡æ•° (Max Iterations for EM)", 
            min_value=max_iter_min, 
            value=session_state.get('dfm_max_iterations', max_iter_default),
            step=max_iter_step,
            key='dfm_max_iterations_input',
            help="EMä¼°è®¡ç®—æ³•å…è®¸çš„æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚"
        )

    # --- ç¬¬ä¸‰åˆ—: å› å­æ•°é‡é€‰æ‹©ç­–ç•¥å’Œç›¸å…³å‚æ•° ---
    with col3_factor_specific:
        
        
        # 1. å› å­æ•°é‡é€‰æ‹©ç­–ç•¥
        if CONFIG_AVAILABLE:
            factor_selection_strategy_options = UIDefaults.FACTOR_SELECTION_STRATEGY_OPTIONS
            default_strategy = TrainDefaults.FACTOR_SELECTION_STRATEGY
        else:
            factor_selection_strategy_options = {
                'information_criteria': "ä¿¡æ¯å‡†åˆ™ (Information Criteria)",
                'fixed_number': "å›ºå®šå› å­æ•°é‡ (Fixed Number of Factors)",
                'cumulative_variance': "ç´¯ç§¯å…±åŒæ–¹å·® (Cumulative Common Variance)"
            }
            default_strategy = 'information_criteria'
            
        session_state.dfm_factor_selection_strategy = st_instance.selectbox(
            "å› å­æ•°é‡é€‰æ‹©ç­–ç•¥",
            options=list(factor_selection_strategy_options.keys()),
            format_func=lambda x: factor_selection_strategy_options[x],
            index=list(factor_selection_strategy_options.keys()).index(session_state.get('dfm_factor_selection_strategy', default_strategy)),
            key='dfm_factor_selection_strategy_input',
            help=(
                "é€‰æ‹©ç¡®å®šæ¨¡å‹ä¸­å› å­æ•°é‡çš„æ–¹æ³•ï¼š\n"
                "- ä¿¡æ¯å‡†åˆ™: æ ¹æ®AIC/BICç­‰è‡ªåŠ¨é€‰æ‹©ã€‚\n"
                "- å›ºå®šå› å­æ•°é‡: ç›´æ¥æŒ‡å®šå› å­æ•°é‡ã€‚\n"
                "- ç´¯ç§¯å…±åŒæ–¹å·®: æ ¹æ®è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ç¡®å®šå› å­æ•°ã€‚"
            )
        )

        # 2. æ ¹æ®ç­–ç•¥æ˜¾ç¤ºå¯¹åº”å‚æ•°
        if session_state.dfm_factor_selection_strategy == 'information_criteria':
            # a. ä¿¡æ¯å‡†åˆ™é€‰æ‹© (BIC, AICç­‰)
            info_criterion_options = {
                'bic': "BIC (Bayesian Information Criterion)",
                'aic': "AIC (Akaike Information Criterion)",
            }
            session_state.dfm_info_criterion_method = st_instance.selectbox(
                "ä¿¡æ¯å‡†åˆ™é€‰æ‹©",
                options=list(info_criterion_options.keys()),
                format_func=lambda x: info_criterion_options[x],
                index=list(info_criterion_options.keys()).index(session_state.get('dfm_info_criterion_method', 'bic')),
                key='dfm_info_criterion_method_input',
                help="é€‰æ‹©ç”¨äºç¡®å®šæœ€ä½³å› å­æ•°é‡çš„ä¿¡æ¯å‡†åˆ™ã€‚"
            )
            # b. IC æœ€å¤§å› å­æ•°
            session_state.dfm_ic_max_factors = st_instance.number_input(
                "IC æœ€å¤§å› å­æ•° (Max Factors for IC)", 
                min_value=1, 
                value=session_state.get('dfm_ic_max_factors', 10),
                step=1,
                key='dfm_ic_max_factors_input',
                help="ä½¿ç”¨ä¿¡æ¯å‡†åˆ™æ—¶ï¼Œå…è®¸æµ‹è¯•çš„æœ€å¤§å› å­æ•°é‡ã€‚"
            )
        elif session_state.dfm_factor_selection_strategy == 'fixed_number':
            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼è€Œä¸æ˜¯ç¡¬ç¼–ç çš„3
            if CONFIG_AVAILABLE:
                default_fixed_factors = TrainDefaults.FIXED_NUMBER_OF_FACTORS
            else:
                try:
                    from ..config import TrainDefaults as FallbackDefaults
                    default_fixed_factors = FallbackDefaults.FIXED_NUMBER_OF_FACTORS
                except ImportError:
                    default_fixed_factors = 3  # æœ€ç»ˆåå¤‡å€¼
                
            session_state.dfm_fixed_number_of_factors = st_instance.number_input(
                "å›ºå®šå› å­æ•°é‡ (Fixed Number of Factors)", 
                min_value=1, 
                value=session_state.get('dfm_fixed_number_of_factors', default_fixed_factors),
                step=1,
                key='dfm_fixed_number_of_factors_input',
                help="ç›´æ¥æŒ‡å®šæ¨¡å‹ä¸­è¦ä½¿ç”¨çš„å› å­æ•°é‡ã€‚"
            )
        elif session_state.dfm_factor_selection_strategy == 'cumulative_variance':
            # a. ç´¯ç§¯å…±åŒæ–¹å·®é˜ˆå€¼
            session_state.dfm_cum_variance_threshold = st_instance.slider(
                "ç´¯ç§¯å…±åŒæ–¹å·®é˜ˆå€¼ (Cumulative Variance Threshold)",
                min_value=0.1, max_value=1.0, 
                value=session_state.get('dfm_cum_variance_threshold', 0.8),
                step=0.05,
                key='dfm_cum_variance_threshold_input',
                help="é€‰æ‹©å› å­ä»¥è§£é‡Šè‡³å°‘æ­¤æ¯”ä¾‹çš„å…±åŒæ–¹å·®ã€‚å€¼åœ¨0åˆ°1ä¹‹é—´ã€‚"
            )
        elif session_state.dfm_factor_selection_strategy == 'manual_override': # è™½ç„¶ç§»é™¤äº†é€‰é¡¹ï¼Œä½†ä¿ç•™é€»è¾‘ä»¥é˜²æœªæ¥éœ€è¦
            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼è€Œä¸æ˜¯ç¡¬ç¼–ç çš„3
            if CONFIG_AVAILABLE:
                default_manual_factors = TrainDefaults.FIXED_NUMBER_OF_FACTORS
            else:
                try:
                    from ..config import TrainDefaults as FallbackDefaults
                    default_manual_factors = FallbackDefaults.FIXED_NUMBER_OF_FACTORS
                except ImportError:
                    default_manual_factors = 3  # æœ€ç»ˆåå¤‡å€¼
                
            session_state.dfm_manual_override_factors = st_instance.number_input(
                "å› å­æ•°é‡ (æ‰‹åŠ¨è¦†ç›–)", 
                min_value=1, 
                value=session_state.get('dfm_manual_override_factors', default_manual_factors),
                step=1,
                key='dfm_manual_override_factors_input',
                help="æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹ä¸­çš„å› å­æ•°é‡ï¼Œè¿™å°†è¦†ç›–å…¶ä»–è‡ªåŠ¨é€‰æ‹©æ–¹æ³•ã€‚"
            )

    # --- é‡ç½®å‚æ•°æŒ‰é’® ---
    # å®šä¹‰é»˜è®¤å‚æ•°çš„å‡½æ•°ï¼Œä»¥ä¾¿é‡ç½®æ—¶è°ƒç”¨
    def get_default_model_params():
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨é…ç½®å€¼è€Œä¸æ˜¯ç¡¬ç¼–ç 
        if CONFIG_AVAILABLE:
            default_fixed_factors = TrainDefaults.FIXED_NUMBER_OF_FACTORS
            default_manual_factors = TrainDefaults.FIXED_NUMBER_OF_FACTORS
        else:
            try:
                from ..config import TrainDefaults as FallbackDefaults
                default_fixed_factors = FallbackDefaults.FIXED_NUMBER_OF_FACTORS
                default_manual_factors = FallbackDefaults.FIXED_NUMBER_OF_FACTORS
            except ImportError:
                default_fixed_factors = 3  # æœ€ç»ˆåå¤‡å€¼
                default_manual_factors = 3  # æœ€ç»ˆåå¤‡å€¼
            
        # åªé‡ç½®éæ—¥æœŸå‚æ•°ï¼Œæ—¥æœŸç”±ç”¨æˆ·å®Œå…¨æ§åˆ¶
        return {
            # ğŸ”¥ å˜é‡é€‰æ‹©å‚æ•° - ä¿®å¤ï¼šé»˜è®¤ç¦ç”¨è‡ªåŠ¨å˜é‡é€‰æ‹©ï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©ç”Ÿæ•ˆ
            'dfm_variable_selection_method': 'global_backward',
            'dfm_enable_variable_selection': True,
            # å› å­é€‰æ‹©å‚æ•°
            'dfm_factor_selection_strategy': 'information_criteria',
            'dfm_max_iterations': 30,
            'dfm_fixed_number_of_factors': default_fixed_factors,  # ğŸ”¥ ä½¿ç”¨é…ç½®å€¼
            'dfm_manual_override_factors': default_manual_factors,  # ğŸ”¥ ä½¿ç”¨é…ç½®å€¼
            'dfm_info_criterion_method': 'bic',
            'dfm_ic_max_factors': 10,
            'dfm_cum_variance_threshold': 0.8,
        }

    def reset_model_parameters():
        defaults = get_default_model_params()
        for key, value in defaults.items():
            # ç›´æ¥æ›´æ–° session_state ä¸­çš„å€¼
            # å¯¹äº date_input, selectbox, number_input, slider, Streamlit ä¼šåœ¨ä¸‹æ¬¡æ¸²æŸ“æ—¶
            # ä½¿ç”¨è¿™äº›æ–°çš„ session_state å€¼ä½œä¸ºå…¶ value/index/default
            session_state[key] = value

        st_instance.success("æ¨¡å‹å‚æ•°å·²é‡ç½®ä¸ºé»˜è®¤å€¼ï¼ˆæ—¥æœŸå‚æ•°ä¸å—å½±å“ï¼Œç”±ç”¨æˆ·å®Œå…¨æ§åˆ¶ï¼‰ã€‚")
        # st_instance.rerun() # å¯ä»¥è€ƒè™‘æ˜¯å¦éœ€è¦ rerunï¼Œé€šå¸¸çŠ¶æ€æ›´æ–°åä¼šè‡ªåŠ¨é‡ç»˜

    # é‡ç½®å‚æ•°æŒ‰é’®
    col_reset, col_spacer = st_instance.columns([2, 8])
    
    with col_reset:
        st_instance.button("é‡ç½®æ¨¡å‹å‚æ•°", on_click=reset_model_parameters, help="ç‚¹å‡»å°†æ‰€æœ‰æ¨¡å‹å‚æ•°æ¢å¤åˆ°é¢„è®¾çš„é»˜è®¤å€¼ã€‚")

    # --- EMç®—æ³•æ”¶æ•›æ ‡å‡† (é€šå¸¸ä¸éœ€è¦ç”¨æˆ·è°ƒæ•´ï¼Œè®¾ä¸ºé»˜è®¤å€¼) ---
    # session_state.dfm_em_convergence_criterion = 1e-4 # ä¿æŒé»˜è®¤æˆ–ä»configåŠ è½½

    st_instance.markdown("--- ") # åˆ†éš”çº¿åœ¨å› å­å‚æ•°è®¾ç½®æ¨¡å—ä¹‹å

    # æ–°å¢"æ¨¡å‹è®­ç»ƒ"æ¨¡å—
    st_instance.subheader("æ¨¡å‹è®­ç»ƒ")
    
    # å¼€å§‹è®­ç»ƒæŒ‰é’®
    col_train_btn, col_spacer = st_instance.columns([2, 8])
    
    with col_train_btn:
        # æ£€æŸ¥é¢„å¤„ç†æ•°æ®æ˜¯å¦å­˜åœ¨
        input_df_check = session_state.get('dfm_prepared_data_df', None)
        can_train = input_df_check is not None and not input_df_check.empty
        
        if st_instance.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹", key="dfm_train_model_button", disabled=not can_train):
            # **æ–°å¢ï¼šéªŒè¯è®­ç»ƒæœŸã€éªŒè¯æœŸæ˜¯å¦åœ¨æ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„è¾¹ç•Œå†…**
            validation_error = None
            
            # è·å–æ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„è¾¹ç•Œæ—¥æœŸ
            data_prep_start = session_state.get('dfm_param_data_start_date')
            data_prep_end = session_state.get('dfm_param_data_end_date')
            
            # è·å–ç”¨æˆ·è®¾ç½®çš„è®­ç»ƒæœŸã€éªŒè¯æœŸ
            train_start = session_state.get('dfm_training_start_date')
            val_start = session_state.get('dfm_validation_start_date')
            val_end = session_state.get('dfm_validation_end_date')
            
            # éªŒè¯æ—¥æœŸè¾¹ç•Œ
            if data_prep_start and train_start and train_start < data_prep_start:
                validation_error = f"è®­ç»ƒå¼€å§‹æ—¥æœŸ ({train_start}) ä¸èƒ½æ—©äºæ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„å¼€å§‹è¾¹ç•Œ ({data_prep_start})"
            elif data_prep_end and val_end and val_end > data_prep_end:
                validation_error = f"éªŒè¯ç»“æŸæ—¥æœŸ ({val_end}) ä¸èƒ½æ™šäºæ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„ç»“æŸè¾¹ç•Œ ({data_prep_end})"
            elif data_prep_start and val_start and val_start < data_prep_start:
                validation_error = f"éªŒè¯å¼€å§‹æ—¥æœŸ ({val_start}) ä¸èƒ½æ—©äºæ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„å¼€å§‹è¾¹ç•Œ ({data_prep_start})"
            elif data_prep_end and train_start and train_start > data_prep_end:
                validation_error = f"è®­ç»ƒå¼€å§‹æ—¥æœŸ ({train_start}) ä¸èƒ½æ™šäºæ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„ç»“æŸè¾¹ç•Œ ({data_prep_end})"
            
            if validation_error:
                st_instance.error(f"âŒ æ—¥æœŸéªŒè¯å¤±è´¥: {validation_error}")
                st_instance.info("ğŸ’¡ è¯·è°ƒæ•´è®­ç»ƒæœŸã€éªŒè¯æœŸè®¾ç½®ï¼Œç¡®ä¿åœ¨æ•°æ®å‡†å¤‡é¡µé¢è®¾ç½®çš„æ—¥æœŸè¾¹ç•Œå†…ã€‚")
                return  # ä¸æ‰§è¡Œè®­ç»ƒ
            
            # é‡ç½®å…¨å±€çŠ¶æ€
            _training_state['status'] = 'å‡†å¤‡å¯åŠ¨è®­ç»ƒ...'
            _training_state['log'] = []
            _training_state['results'] = None
            _training_state['error'] = None
            
            # è®¾ç½®è®­ç»ƒå¯åŠ¨æ ‡å¿—
            session_state.dfm_should_start_training = True
            session_state.dfm_training_log = []
            session_state.dfm_training_status = "å‡†å¤‡å¯åŠ¨è®­ç»ƒ..."

    # --- Callback function for logging ---
    def training_log_callback(message, st_instance_ref=st_instance):
        # è¿™ä¸ªå‡½æ•°ç°åœ¨åªç”¨äºUIå†…éƒ¨ï¼Œä¸åº”è¯¥åœ¨è®­ç»ƒçº¿ç¨‹ä¸­ä½¿ç”¨
        # è®­ç»ƒçº¿ç¨‹æœ‰è‡ªå·±çš„thread_log_callback
        pass

    # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯åŠ¨è®­ç»ƒ
    should_start_training = session_state.get('dfm_should_start_training', False)
    
    # æ‰§è¡Œè®­ç»ƒé€»è¾‘ï¼ˆåœ¨å¸ƒå±€ä¹‹å‰ï¼‰
    if should_start_training:
        # é‡ç½®å¯åŠ¨æ ‡å¿—
        session_state.dfm_should_start_training = False
        
        # é‡ç½®å…¨å±€çŠ¶æ€
        _training_state['status'] = 'å‡†å¤‡å¯åŠ¨è®­ç»ƒ...'
        _training_state['log'] = []
        _training_state['results'] = None
        _training_state['error'] = None
        
        session_state.dfm_training_status = 'å‡†å¤‡å¯åŠ¨è®­ç»ƒ...'
        session_state.dfm_training_log = []
        session_state.dfm_model_results_paths = None
        
        # è·å–æ‰€æœ‰è®­ç»ƒå‚æ•°
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„ç­–ç•¥ç¡®å®šå› å­æ•°é‡
        default_factors = TrainDefaults.FIXED_NUMBER_OF_FACTORS if CONFIG_AVAILABLE else 3
        if session_state.get('dfm_factor_selection_strategy') == 'fixed_number':
            n_factors = session_state.get('dfm_fixed_number_of_factors', default_factors)  # ğŸ”¥ ä½¿ç”¨é…ç½®å€¼
        elif session_state.get('dfm_factor_selection_strategy') == 'manual_override':
            n_factors = session_state.get('dfm_manual_override_factors', default_factors)  # ğŸ”¥ ä½¿ç”¨é…ç½®å€¼
        else:
            # å¯¹äºä¿¡æ¯å‡†åˆ™å’Œç´¯ç§¯æ–¹å·®ç­–ç•¥ï¼Œæä¾›ä¸€ä¸ªé»˜è®¤å€¼ï¼Œåç«¯ä¼šè‡ªåŠ¨ä¼˜åŒ–
            n_factors = session_state.get('dfm_fixed_number_of_factors', default_factors)  # ğŸ”¥ ä½¿ç”¨é…ç½®å€¼

        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨é…ç½®çš„å› å­é€‰æ‹©èŒƒå›´
        # å› å­é€‰æ‹©èŒƒå›´å‚æ•° - æ ¹æ®ç”¨æˆ·çš„ç­–ç•¥è®¾ç½®
        if session_state.get('dfm_factor_selection_strategy') == 'information_criteria':
            # ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„ICæœ€å¤§å› å­æ•°ï¼Œä¸å—é…ç½®æ–‡ä»¶çš„K_FACTORS_RANGE_MAXé™åˆ¶
            if CONFIG_AVAILABLE:
                min_factors = TrainDefaults.K_FACTORS_RANGE_MIN
                # ğŸ”¥ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„ICæœ€å¤§å› å­æ•°ï¼Œä¸ç”¨min()é™åˆ¶
                max_factors = session_state.get('dfm_ic_max_factors', TrainDefaults.IC_MAX_FACTORS)
            else:
                min_factors = 1
                max_factors = session_state.get('dfm_ic_max_factors', 10)
            k_factors_range = (min_factors, max_factors)
        else:
            # å¯¹äºå›ºå®šæ•°é‡ç­–ç•¥ï¼Œä½¿ç”¨å•ä¸€å€¼
            k_factors_range = (n_factors, n_factors)

        # ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„æ¥å£å‚æ•°æ ¼å¼
        params_for_training = {
            # åŸºç¡€æ•°æ®å‚æ•°
            'input_df': session_state.get('dfm_prepared_data_df'),
            'target_variable': session_state.get('dfm_target_variable', 'è§„æ¨¡ä»¥ä¸Šå·¥ä¸šå¢åŠ å€¼:å½“æœˆåŒæ¯”'),
            'selected_indicators': session_state.get('dfm_selected_indicators', []),

            # æ—¥æœŸå‚æ•°
            'training_start_date': convert_to_datetime(session_state.get('dfm_training_start_date')),
            'validation_start_date': convert_to_datetime(session_state.get('dfm_validation_start_date')),
            'validation_end_date': convert_to_datetime(session_state.get('dfm_validation_end_date')),

            # å› å­é€‰æ‹©ç­–ç•¥å‚æ•°
            'factor_selection_strategy': session_state.get('dfm_factor_selection_strategy', 'information_criteria'),
            'fixed_number_of_factors': session_state.get('dfm_fixed_number_of_factors', n_factors),
            'ic_max_factors': session_state.get('dfm_ic_max_factors', 20),
            'cum_variance_threshold': session_state.get('dfm_cum_variance_threshold', 0.8),
            'info_criterion_method': session_state.get('dfm_info_criterion_method', 'bic'),

            # å˜é‡é€‰æ‹©å‚æ•°
            'variable_selection_method': session_state.get('dfm_variable_selection_method', 'global_backward'),
            'enable_variable_selection': session_state.get('dfm_enable_variable_selection', True),

            # è®­ç»ƒå‚æ•°
            'max_iterations': session_state.get('dfm_max_iterations', 30),
            'em_max_iter': session_state.get('dfm_max_iterations', 30),  # æ·»åŠ EMç®—æ³•æœ€å¤§è¿­ä»£æ¬¡æ•°

            # å› å­é€‰æ‹©èŒƒå›´å‚æ•°
            'k_factors_range': k_factors_range,
            'enable_hyperparameter_tuning': session_state.get('dfm_factor_selection_strategy') == 'information_criteria',

            # ğŸ”¥ ç§»é™¤ï¼šä¸å†ä½¿ç”¨å›ºå®šçš„è¾“å‡ºç›®å½•ï¼Œæ‰€æœ‰æ–‡ä»¶é€šè¿‡UIä¸‹è½½
            # 'output_dir': config.DFM_TRAIN_OUTPUT_DIR if hasattr(config, 'DFM_TRAIN_OUTPUT_DIR') else "dashboard/DFM/outputs",

            # è¿›åº¦å›è°ƒ
            'progress_callback': training_log_callback,

            # æ˜ å°„å‚æ•°ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰
            'var_industry_map': session_state.get('dfm_industry_map_obj'),
            'var_type_map': session_state.get('dfm_var_type_map_obj'),
        }
        
        # ğŸ”¥ å®é™…æ•°æ®å¤„ç†ï¼šå˜é‡é€‰æ‹©èŒƒå›´æ€»æ˜¯ç”¨æˆ·é€‰æ‹©çš„å˜é‡
        # è·å–ç”¨æˆ·é€‰æ‹©çš„å˜é‡èŒƒå›´ï¼ˆç›®æ ‡å˜é‡+é¢„æµ‹å˜é‡ï¼‰
        available_cols = params_for_training['selected_indicators'].copy()
        if params_for_training['target_variable'] not in available_cols:
            available_cols.insert(0, params_for_training['target_variable'])
        actual_variables_to_use = list(set(available_cols))
        
        # è·å–å®é™…å°†è¦ä½¿ç”¨çš„æ•°æ®å½¢çŠ¶
        actual_data_shape = (len(params_for_training['input_df']), len(actual_variables_to_use))
        
        # å‚æ•°éªŒè¯å’Œè°ƒè¯•ä¿¡æ¯
        print(f"[TRAIN_DEBUG] è®­ç»ƒå‚æ•°æ£€æŸ¥:")
        print(f"  - ğŸ”¥ğŸ”¥ğŸ”¥ åŸå§‹æ•°æ®å½¢çŠ¶: {params_for_training['input_df'].shape}")
        print(f"  - ğŸ”¥ğŸ”¥ğŸ”¥ ç”¨æˆ·é€‰æ‹©å˜é‡æ•°: {len(actual_variables_to_use)} ä¸ª")
        print(f"  - ğŸ”¥ğŸ”¥ğŸ”¥ å®é™…è®­ç»ƒæ•°æ®å½¢çŠ¶: {actual_data_shape} â† è¿™æ˜¯è®­ç»ƒçš„æ•°æ®å¤§å°ï¼")
        print(f"  - ç›®æ ‡å˜é‡: {params_for_training['target_variable']}")
        print(f"  - é€‰æ‹©æŒ‡æ ‡æ•°é‡: {len(params_for_training['selected_indicators'])}")
        print(f"  - ğŸ”¥ğŸ”¥ğŸ”¥ é€‰æ‹©çš„æŒ‡æ ‡åˆ—è¡¨: {params_for_training['selected_indicators']}")
        print(f"  - è®­ç»ƒå¼€å§‹æ—¥æœŸ: {params_for_training['training_start_date']}")
        print(f"  - éªŒè¯å¼€å§‹æ—¥æœŸ: {params_for_training['validation_start_date']}")
        print(f"  - éªŒè¯ç»“æŸæ—¥æœŸ: {params_for_training['validation_end_date']}")
        
        # ğŸ”¥ è¯¦ç»†çš„UIè®¾ç½®ä¸åå°å‚æ•°å¯¹æ¯”
        print(f"\n[UI vs åå°å‚æ•°å¯¹æ¯”]:")
        print(f"  ğŸ“‹ å˜é‡é€‰æ‹©è®¾ç½®:")
        print(f"    - UIæ˜¾ç¤º: {session_state.get('dfm_variable_selection_method', 'none')}")
        print(f"    - åå°å‚æ•°: {params_for_training['variable_selection_method']}")
        print(f"    - æ˜¯å¦å¯ç”¨: {params_for_training['enable_variable_selection']}")
        
        print(f"  ğŸ¯ å› å­æ•°é‡ç­–ç•¥:")
        print(f"    - UIæ˜¾ç¤º: {session_state.get('dfm_factor_selection_strategy', 'information_criteria')}")
        print(f"    - åå°å¯ç”¨è¶…å‚æ•°è°ƒä¼˜: {params_for_training['enable_hyperparameter_tuning']}")
        
        print(f"  ğŸ“Š ä¿¡æ¯å‡†åˆ™è®¾ç½®:")
        print(f"    - UIæ˜¾ç¤ºæ–¹æ³•: {session_state.get('dfm_info_criterion_method', 'bic')}")
        print(f"    - åå°å‚æ•°: {params_for_training['info_criterion_method']}")
        print(f"    - UIè®¾ç½®ICæœ€å¤§å› å­æ•°: {session_state.get('dfm_ic_max_factors', 10)}")
        print(f"    - åå°å› å­é€‰æ‹©èŒƒå›´: {params_for_training['k_factors_range']}")
        
        print(f"  âš™ï¸ å…¶ä»–è®¾ç½®:")
        print(f"    - UIè®¾ç½®æœ€å¤§è¿­ä»£æ¬¡æ•°: {session_state.get('dfm_max_iterations', 30)}")
        print(f"    - åå°å‚æ•°: {params_for_training['em_max_iter']}")
        
        if params_for_training['enable_variable_selection']:
            print(f"  - ğŸ”¥ å˜é‡ç­›é€‰è¯´æ˜: å°†ä»ç”¨æˆ·é€‰æ‹©çš„ {len(actual_variables_to_use)} ä¸ªå˜é‡ä¸­è¿›è¡Œ {params_for_training['variable_selection_method']} ç­›é€‰")
        else:
            print(f"  - ğŸ”¥ å˜é‡ç­›é€‰è¯´æ˜: ç›´æ¥ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ {len(actual_variables_to_use)} ä¸ªå˜é‡ï¼Œä¸è¿›è¡Œç­›é€‰")

        # ğŸ”¥ æ£€æŸ¥session_stateä¸­çš„æŒ‡æ ‡é€‰æ‹©çŠ¶æ€
        print(f"  - ğŸ”¥ Sessionä¸­çš„selected_indicators: {session_state.get('dfm_selected_indicators', 'NOT_FOUND')}")
        print(f"  - ğŸ”¥ Sessionä¸­çš„è¡Œä¸šé€‰æ‹©: {session_state.get('dfm_selected_industries', 'NOT_FOUND')}")
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¯¦ç»†çš„å˜é‡ä¼ é€’è¯Šæ–­
        print(f"\n" + "="*80)
        print(f"ğŸ”ğŸ”ğŸ” [è®­ç»ƒå‚æ•°ä¼ é€’è¯Šæ–­] è¯¦ç»†åˆ†æå˜é‡ä¼ é€’è¿‡ç¨‹")
        print(f"="*80)

        print(f"ğŸ“‹ UIå±‚é¢çš„å˜é‡é€‰æ‹©çŠ¶æ€:")
        selected_indicators_from_session = session_state.get('dfm_selected_indicators', [])
        selected_industries_from_session = session_state.get('dfm_selected_industries', [])
        print(f"    - é€‰æ‹©çš„è¡Œä¸šæ•°é‡: {len(selected_industries_from_session)}")
        print(f"    - é€‰æ‹©çš„è¡Œä¸šåˆ—è¡¨: {selected_industries_from_session}")
        print(f"    - é€‰æ‹©çš„æŒ‡æ ‡æ•°é‡: {len(selected_indicators_from_session)}")
        print(f"    - é€‰æ‹©çš„æŒ‡æ ‡åˆ—è¡¨ (å‰10ä¸ª): {selected_indicators_from_session[:10]}{'...' if len(selected_indicators_from_session) > 10 else ''}")

        print(f"\nğŸ”„ å‚æ•°ä¼ é€’åˆ°åç«¯:")
        print(f"    - ä¼ é€’ç»™è®­ç»ƒå‡½æ•°çš„selected_indicatorsæ•°é‡: {len(params_for_training['selected_indicators'])}")
        print(f"    - ä¼ é€’çš„æŒ‡æ ‡åˆ—è¡¨ (å‰10ä¸ª): {params_for_training['selected_indicators'][:10]}{'...' if len(params_for_training['selected_indicators']) > 10 else ''}")
        print(f"    - ç›®æ ‡å˜é‡: {params_for_training['target_variable']}")

        print(f"\nğŸ¯ æœ€ç»ˆè®­ç»ƒå˜é‡ç»„åˆ:")
        print(f"    - é¢„æµ‹æŒ‡æ ‡æ•°é‡: {len(params_for_training['selected_indicators'])}")
        print(f"    - ç›®æ ‡å˜é‡: {params_for_training['target_variable']}")
        print(f"    - æ€»å˜é‡æ•°: {len(actual_variables_to_use)} (åŒ…å«ç›®æ ‡å˜é‡)")

        # ğŸ”¥ æ–°å¢ï¼šæ£€æŸ¥å˜é‡ä¼ é€’æ˜¯å¦ä¸€è‡´
        ui_count = len(selected_indicators_from_session)
        param_count = len(params_for_training['selected_indicators'])

        if ui_count != param_count:
            print(f"    âŒ è­¦å‘Šï¼šUIé€‰æ‹©æ•°é‡({ui_count}) != ä¼ é€’æ•°é‡({param_count})")

            # æ‰¾å‡ºå·®å¼‚
            ui_set = set(selected_indicators_from_session)
            param_set = set(params_for_training['selected_indicators'])

            missing_in_params = ui_set - param_set
            extra_in_params = param_set - ui_set

            if missing_in_params:
                print(f"    âŒ UIä¸­æœ‰ä½†å‚æ•°ä¸­æ²¡æœ‰çš„å˜é‡: {list(missing_in_params)[:5]}{'...' if len(missing_in_params) > 5 else ''}")
            if extra_in_params:
                print(f"    âŒ å‚æ•°ä¸­æœ‰ä½†UIä¸­æ²¡æœ‰çš„å˜é‡: {list(extra_in_params)[:5]}{'...' if len(extra_in_params) > 5 else ''}")
        else:
            print(f"    âœ… å˜é‡ä¼ é€’æ•°é‡ä¸€è‡´: {ui_count} ä¸ª")

        print(f"="*80)

        # ğŸ”¥ğŸ”¥ğŸ”¥ æ£€æŸ¥å˜é‡æ˜¯å¦åœ¨æ•°æ®ä¸­å­˜åœ¨
        if params_for_training['input_df'] is not None:
            # ğŸ” è°ƒè¯•ï¼šæ˜¾ç¤ºæ•°æ®ä¸­çš„å®é™…åˆ—å
            data_columns = list(params_for_training['input_df'].columns)
            print(f"  ğŸ” æ•°æ®ä¸­çš„å®é™…åˆ—å (å‰20ä¸ª): {data_columns[:20]}")
            print(f"  ğŸ” æ•°æ®ä¸­æ€»åˆ—æ•°: {len(data_columns)}")

            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥åˆ¶é€ ä¸šç›¸å…³çš„åˆ—å
            manufacturing_cols = [col for col in data_columns if 'åˆ¶é€ ä¸š' in str(col) or 'pmi' in str(col).lower()]
            print(f"  ğŸ” æ•°æ®ä¸­åŒ…å«'åˆ¶é€ ä¸š'æˆ–'pmi'çš„åˆ—å: {manufacturing_cols}")

            # ğŸ”§ ä¿®å¤ï¼šåˆ›å»ºå¤§å°å†™ä¸æ•æ„Ÿçš„åˆ—åæ˜ å°„
            column_mapping = {}
            data_columns_lower = {col.lower().strip(): col for col in data_columns}

            # ğŸ”¥ æ–°å¢ï¼šä½¿ç”¨session_stateä¸­çš„æ˜ å°„å…³ç³»
            indicator_to_actual_map = session_state.get('dfm_indicator_to_actual_column_map', {})

            # ä¸ºæ¯ä¸ªé€‰æ‹©çš„å˜é‡æ‰¾åˆ°åŒ¹é…çš„å®é™…åˆ—å
            matched_variables = []
            for var in actual_variables_to_use:
                var_lower = var.lower().strip()
                var_normalized = unicodedata.normalize('NFKC', var_lower)

                if var in data_columns:
                    # ç²¾ç¡®åŒ¹é…
                    matched_variables.append(var)
                    column_mapping[var] = var
                elif var_lower in data_columns_lower:
                    # å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
                    actual_col = data_columns_lower[var_lower]
                    matched_variables.append(var)
                    column_mapping[var] = actual_col
                    print(f"  ğŸ”§ å˜é‡åæ˜ å°„: '{var}' -> '{actual_col}'")
                elif var_normalized in indicator_to_actual_map:
                    # ğŸ”¥ æ–°å¢ï¼šä½¿ç”¨é¢„å»ºçš„æ˜ å°„å…³ç³»
                    actual_col = indicator_to_actual_map[var_normalized]
                    matched_variables.append(var)
                    column_mapping[var] = actual_col
                    print(f"  ğŸ”§ å˜é‡åæ˜ å°„ (é¢„å»ºæ˜ å°„): '{var}' -> '{actual_col}'")

            available_in_data = matched_variables
            missing_in_data = [var for var in actual_variables_to_use if var not in matched_variables]

            print(f"  âœ… æ•°æ®éªŒè¯ (ä¿®å¤å):")
            print(f"    - åœ¨æ•°æ®ä¸­å­˜åœ¨çš„å˜é‡: {len(available_in_data)} ä¸ª")
            print(f"    - åœ¨æ•°æ®ä¸­å­˜åœ¨çš„å˜é‡åˆ—è¡¨: {available_in_data}")
            if missing_in_data:
                print(f"    - âŒ åœ¨æ•°æ®ä¸­ç¼ºå¤±çš„å˜é‡: {len(missing_in_data)} ä¸ª")
                print(f"    - âŒ ç¼ºå¤±å˜é‡åˆ—è¡¨: {missing_in_data}")
            else:
                print(f"    - âœ… æ‰€æœ‰é€‰æ‹©çš„å˜é‡éƒ½åœ¨æ•°æ®ä¸­å­˜åœ¨ï¼")

            # ğŸ”§ æ›´æ–°å‚æ•°ä¸­çš„å˜é‡åˆ—è¡¨ï¼Œä½¿ç”¨å®é™…çš„åˆ—å
            if column_mapping:
                # æ›´æ–°selected_indicatorsä¸ºå®é™…çš„åˆ—å
                mapped_indicators = []
                for indicator in params_for_training['selected_indicators']:
                    if indicator in column_mapping:
                        mapped_indicators.append(column_mapping[indicator])
                    else:
                        mapped_indicators.append(indicator)  # ä¿æŒåŸå

                params_for_training['selected_indicators'] = mapped_indicators
                print(f"  ğŸ”§ æ›´æ–°åçš„æŒ‡æ ‡åˆ—è¡¨: {mapped_indicators}")
        else:
            print(f"    - âŒ è­¦å‘Šï¼šinput_dfä¸ºNoneï¼Œæ— æ³•éªŒè¯å˜é‡å­˜åœ¨æ€§")

        # ğŸ”§ å•çº¿ç¨‹æ¨¡å¼ï¼šç›´æ¥è¿è¡Œè®­ç»ƒï¼ˆä¸ä½¿ç”¨çº¿ç¨‹ï¼‰
        _run_training_thread(params_for_training, st_instance, training_log_callback)

    # åˆ›å»ºç´§å‡‘çš„çŠ¶æ€å’Œç»“æœæ˜¾ç¤ºåŒºåŸŸ
    col_status, col_results = st_instance.columns([3, 2])
    
    with col_status:
        st_instance.markdown("**è®­ç»ƒçŠ¶æ€**")
        
        # å®æ—¶çŠ¶æ€æ˜¾ç¤ºï¼ŒåŒ…å«è‡ªåŠ¨åŒæ­¥
        current_status = _training_state['status']  # ç›´æ¥ä½¿ç”¨å…¨å±€çŠ¶æ€
        
        # æ˜¾ç¤ºå½“å‰è®­ç»ƒçŠ¶æ€
        if current_status == 'ç­‰å¾…å¼€å§‹':
            st_instance.info("ğŸ”µ å‡†å¤‡å°±ç»ª")
        elif current_status == 'å‡†å¤‡å¯åŠ¨è®­ç»ƒ...':
            st_instance.info("ğŸŸ¡ å‡†å¤‡ä¸­...")
        elif current_status == 'æ­£åœ¨è®­ç»ƒ...':
            st_instance.warning("ğŸŸ  è®­ç»ƒä¸­...")
            # è®­ç»ƒä¸­è‡ªåŠ¨åˆ·æ–°é¡µé¢
            import time
            time.sleep(0.5)
            st_instance.rerun()
        elif current_status == 'è®­ç»ƒå®Œæˆ':
            st_instance.success("ğŸŸ¢ è®­ç»ƒå®Œæˆ")
        elif current_status.startswith('è®­ç»ƒå¤±è´¥'):
            st_instance.error(f"ğŸ”´ è®­ç»ƒå¤±è´¥")
        else:
            st_instance.info(f"ğŸ“Š {current_status}")
        
        # æ•°æ®å‡†å¤‡çŠ¶æ€æ£€æŸ¥
        if input_df_check is None:
            st_instance.error("âŒ æ— æ•°æ®")
        elif input_df_check.empty:
            st_instance.error("âŒ æ•°æ®ç©º")
        else:
            # ğŸ”¥ ä¿®å¤ï¼šæ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„å˜é‡æ•°é‡è€Œä¸æ˜¯åŸå§‹æ•°æ®çš„æ‰€æœ‰å˜é‡
            selected_indicators = session_state.get('dfm_selected_indicators', [])
            target_variable = session_state.get('dfm_target_variable', '')
            
            # è®¡ç®—å®é™…ä½¿ç”¨çš„å˜é‡æ•°é‡
            actual_variables = selected_indicators.copy()
            if target_variable and target_variable not in actual_variables:
                actual_variables.append(target_variable)
            
            actual_var_count = len(actual_variables)
            
            if actual_var_count > 0:
                st_instance.success(f"âœ… æ•°æ® ({input_df_check.shape[0]}Ã—{actual_var_count})")
            else:
                # ğŸ”¥ ä¿®å¤ï¼šå³ä½¿æœªé€‰æ‹©å˜é‡ï¼Œä¹Ÿä¸è¦æ˜¾ç¤ºåŸå§‹æ•°æ®çš„æ‰€æœ‰åˆ—æ•°
                st_instance.warning(f"âš ï¸ æœªé€‰æ‹©å˜é‡ - è¯·å…ˆé€‰æ‹©ç›®æ ‡å˜é‡å’Œé¢„æµ‹æŒ‡æ ‡")
        
        # å®æ—¶è®­ç»ƒè¿›åº¦æ˜¾ç¤º
        current_log = _training_state['log']  # ç›´æ¥ä½¿ç”¨å…¨å±€æ—¥å¿—
        
        st_instance.markdown("**è®­ç»ƒæ—¥å¿—**")
        
        if current_log:
            # æ˜¾ç¤ºæœ€æ–°5æ¡æ—¥å¿—
            recent_logs = current_log[-5:] if len(current_log) > 5 else current_log
            log_content = "\n".join(recent_logs)
            
            # ä½¿ç”¨åŠ¨æ€keyç¡®ä¿å†…å®¹æ›´æ–°
            log_display_key = f"dfm_log_display_{len(current_log)}_{hash(log_content) % 10000}"
            st_instance.text_area(
                "è®­ç»ƒæ—¥å¿—å†…å®¹", 
                value=log_content, 
                height=120, 
                disabled=True, 
                key=log_display_key,
                label_visibility="collapsed"
            )
            
            # ç®€åŒ–æ—¥å¿—ç»Ÿè®¡
            st_instance.caption(f"ğŸ“ {len(current_log)} æ¡æ—¥å¿—")
        else:
            if current_status in ['æ­£åœ¨è®­ç»ƒ...', 'å‡†å¤‡å¯åŠ¨è®­ç»ƒ...']:
                st_instance.info("â³ ç­‰å¾…æ—¥å¿—...")
            else:
                st_instance.info("ğŸ”˜ æ— æ—¥å¿—")
    
    with col_results:
        st_instance.markdown("**è®­ç»ƒç»“æœ**")
        
        # æ£€æŸ¥è®­ç»ƒæ˜¯å¦å®Œæˆ - ä½¿ç”¨å…¨å±€çŠ¶æ€è€Œä¸æ˜¯session_state
        current_results = _training_state.get('results')
        
        if current_status == 'è®­ç»ƒå®Œæˆ' and current_results:
            # è®¡ç®—å®é™…å­˜åœ¨çš„æ ¸å¿ƒæ–‡ä»¶æ•°é‡ï¼ˆæ¨¡å‹æ–‡ä»¶ã€å…ƒæ•°æ®å’ŒExcelæŠ¥å‘Šï¼‰
            core_file_keys = ['final_model_joblib', 'model_joblib', 'metadata', 'simplified_metadata', 'excel_report']
            core_files = {k: v for k, v in current_results.items() if k in core_file_keys}
            existing_core_files = sum(1 for path in core_files.values() if path and os.path.exists(path))
            
            st_instance.success("âœ… è®­ç»ƒå®Œæˆ")
            st_instance.info(f"ğŸ“ {existing_core_files} ä¸ªæ–‡ä»¶")
            
            # åŒæ­¥åˆ°session_stateä»¥ä¾¿ä¸‹è½½åŠŸèƒ½æ­£å¸¸å·¥ä½œ
            session_state.dfm_training_status = "è®­ç»ƒå®Œæˆ"
            session_state.dfm_model_results_paths = current_results
            
            # ç´§å‡‘çš„ä¸‹è½½åŒºåŸŸ
            st_instance.markdown("**ğŸ“¥ ä¸‹è½½æ–‡ä»¶**")
            
            # æ ¸å¿ƒæ–‡ä»¶ï¼šæ¨¡å‹æ–‡ä»¶ã€å…ƒæ•°æ®ã€ExcelæŠ¥å‘Šå’Œè®­ç»ƒæ•°æ®
            core_file_types = {
                'final_model_joblib': ('ğŸ“¦', 'æ¨¡å‹'),
                'model_joblib': ('ğŸ“¦', 'æ¨¡å‹'), 
                'metadata': ('ğŸ“„', 'å…ƒæ•°æ®'),
                'simplified_metadata': ('ğŸ“„', 'å…ƒæ•°æ®'),
                'excel_report': ('ğŸ“Š', 'ExcelæŠ¥å‘Š'),
                'training_data': ('ğŸ“Š', 'è®­ç»ƒæ•°æ®')
            }
            
            # æ”¶é›†å¯ç”¨çš„ä¸‹è½½æ–‡ä»¶
            available_downloads = []
            for file_key, file_path in current_results.items():
                if file_key in core_file_types and file_path and os.path.exists(file_path):
                    available_downloads.append((file_key, file_path))
            
            # ä½¿ç”¨å››åˆ—å¸ƒå±€æ˜¾ç¤ºä¸‹è½½æŒ‰é’®ï¼Œæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ–‡ä»¶
            if available_downloads:
                num_cols = min(4, len(available_downloads))  # æœ€å¤š4åˆ—
                download_cols = st_instance.columns(num_cols)
                
                for idx, (file_key, file_path) in enumerate(available_downloads):  # æ˜¾ç¤ºæ‰€æœ‰æ–‡ä»¶
                    with download_cols[idx % num_cols]:
                        try:
                            # è·å–æ–‡ä»¶å›¾æ ‡å’Œæ˜¾ç¤ºåç§°
                            icon, display_name = core_file_types[file_key]
                            file_name = os.path.basename(file_path)
                            
                            # æ ¹æ®æ–‡ä»¶ç±»å‹ç¡®å®šMIMEç±»å‹
                            if file_path.endswith('.pkl'):
                                mime_type = "application/octet-stream"
                            elif file_path.endswith('.joblib'):
                                mime_type = "application/octet-stream"
                            elif file_path.endswith('.xlsx'):
                                mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            elif file_path.endswith('.csv'):
                                mime_type = "text/csv"
                            else:
                                mime_type = "application/octet-stream"
                            
                            # è¯»å–æ–‡ä»¶æ•°æ®
                            with open(file_path, 'rb') as f:
                                file_data = f.read()
                            
                            # åˆ›å»ºä¸‹è½½æŒ‰é’®
                            st_instance.download_button(
                                label=f"{icon} {display_name}",
                                data=file_data,
                                file_name=file_name,
                                mime=mime_type,
                                key=f"download_{file_key}_{hash(file_path) % 1000}",
                                use_container_width=True
                            )
                            
                        except Exception as e:
                            st_instance.warning(f"âš ï¸ {display_name} æ–‡ä»¶è¯»å–å¤±è´¥")
            
                # æ˜¾ç¤ºä¸‹è½½ç»Ÿè®¡å’Œæ¸…ç©ºæŒ‰é’®
                if len(available_downloads) > 0:
                    st_instance.success(f"ğŸ“ {len(available_downloads)} ä¸ªæ–‡ä»¶å¯ä¸‹è½½")
                    
                    # æ·»åŠ æ¸…ç©ºç»“æœæŒ‰é’®
                    if st_instance.button("ğŸ—‘ï¸ æ¸…ç©ºè®­ç»ƒç»“æœ", 
                                         key="clear_training_results", 
                                         help="æ¸…ç©ºå½“å‰çš„è®­ç»ƒç»“æœå’ŒçŠ¶æ€",
                                         use_container_width=True):
                        # æ ‡è®°éœ€è¦é‡ç½®çŠ¶æ€
                        session_state.dfm_force_reset_training_state = True
                        st_instance.success("âœ… è®­ç»ƒç»“æœå·²æ¸…ç©ºï¼Œé¡µé¢å°†è‡ªåŠ¨åˆ·æ–°")
                        st_instance.rerun()
            else:
                st_instance.warning("âŒ æš‚æ— å¯ä¸‹è½½çš„æ–‡ä»¶")
        else:
            # æ˜¾ç¤ºç­‰å¾…çŠ¶æ€æˆ–é”™è¯¯ä¿¡æ¯
            if current_status == 'ç­‰å¾…å¼€å§‹':
                st_instance.info("ğŸ”˜ æ— æ—¥å¿—")
            elif current_status.startswith('è®­ç»ƒå¤±è´¥'):
                st_instance.error("âŒ è®­ç»ƒå¤±è´¥")
            else:
                st_instance.info("â³ ç­‰å¾…è®­ç»ƒ...")
