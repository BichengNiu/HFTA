import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.colors
from datetime import datetime
import sys
import os
import unicodedata
import re
import io

# Get the directory of the current file
diffusion_mod_dir = os.path.dirname(__file__)
dashboard_dir = os.path.abspath(os.path.join(diffusion_mod_dir, '..'))
project_root_diff = os.path.abspath(os.path.join(dashboard_dir, '..'))

if project_root_diff not in sys.path:
    sys.path.insert(0, project_root_diff)

def normalize_string(s: str) -> str:
    """å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ ‡å‡†åŒ–å½¢å¼ï¼šåŠè§’ï¼Œå»é™¤é¦–å°¾ç©ºæ ¼ï¼Œåˆå¹¶ä¸­é—´ç©ºæ ¼ã€‚"""
    if not isinstance(s, str):
        return s
    # è½¬æ¢å…¨è§’ä¸ºåŠè§’ (å¸¸è§æ ‡ç‚¹å’Œç©ºæ ¼)
    full_width = "ï¼ˆï¼‰ï¼šã€€"
    half_width = "(): "
    translation_table = str.maketrans(full_width, half_width)
    s = s.translate(translation_table)
    # ç‰¹æ®Šå¤„ç†ï¼šç¡®ä¿å†’å·åé¢æœ‰ç©ºæ ¼
    s = re.sub(r':(?!\s)', ': ', s)
    # å»é™¤é¦–å°¾ç©ºæ ¼
    s = s.strip()
    # åˆå¹¶ä¸­é—´å¤šä½™ç©ºæ ¼
    s = re.sub(r'\s+', ' ', s)
    return s

# === æ–°å¢ï¼šç¼“å­˜æœºåˆ¶ ===
@st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
def cached_calculate_diffusion_index(df_hash: str, 
                                   frequency: str,
                                   comparison_type: str,
                                   tolerance_threshold: float,
                                   df_values: list) -> pd.Series:
    """
    å¸¦ç¼“å­˜çš„æ‰©æ•£æŒ‡æ•°è®¡ç®—
    """
    # é‡æ„DataFrame
    df = pd.DataFrame(df_values[0], index=df_values[1], columns=df_values[2])
    df.index = pd.to_datetime(df.index)
    
    return calculate_diffusion_index(df, frequency, comparison_type, tolerance_threshold)

def get_dataframe_hash(df: pd.DataFrame) -> str:
    """è·å–DataFrameçš„å“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
    return str(hash(str(df.shape) + str(df.columns.tolist()) + str(df.index[-1]) if not df.empty else "empty"))

# === æ–°å¢ï¼šæ‰©æ•£æŒ‡æ•°è®¡ç®—æ ¸å¿ƒå‡½æ•° ===
def calculate_diffusion_index(df: pd.DataFrame, 
                            frequency: str,
                            comparison_type: str,
                            tolerance_threshold: float) -> pd.Series:
    """
    è®¡ç®—æŒ‡å®šé¢‘ç‡å’Œæ¯”è¾ƒç±»å‹çš„æ‰©æ•£æŒ‡æ•°
    
    Args:
        df: æ—¶é—´åºåˆ—æ•°æ®DataFrame
        frequency: æ—¶é—´é¢‘ç‡ ("daily", "weekly", "monthly", "annual")
        comparison_type: æ¯”è¾ƒç±»å‹ ("åŒæ¯”", "ç¯æ¯”")
        tolerance_threshold: å®¹å¿åº¦é˜ˆå€¼
        
    Returns:
        æ‰©æ•£æŒ‡æ•°æ—¶é—´åºåˆ—
    """
    if df.empty:
        return pd.Series(dtype=float)
    
    # ç¡®ä¿ç´¢å¼•æ˜¯datetimeç±»å‹
    df_copy = df.copy()
    df_copy.index = pd.to_datetime(df_copy.index)
    
    # æ ¹æ®é¢‘ç‡å’Œæ¯”è¾ƒç±»å‹è®¾ç½®periodså‚æ•°
    periods_map = {
        "daily": {
            "åŒæ¯”": 365,  # æ—¥åº¦åŒæ¯”ï¼šä¸å»å¹´åŒä¸€å¤©æ¯”è¾ƒ
            "ç¯æ¯”": 1     # æ—¥åº¦ç¯æ¯”ï¼šä¸å‰ä¸€å¤©æ¯”è¾ƒ
        },
        "weekly": {
            "åŒæ¯”": 52,   # å‘¨åº¦åŒæ¯”ï¼šä¸å»å¹´åŒä¸€å‘¨æ¯”è¾ƒ
            "ç¯æ¯”": 1     # å‘¨åº¦ç¯æ¯”ï¼šä¸å‰ä¸€å‘¨æ¯”è¾ƒ
        },
        "monthly": {
            "åŒæ¯”": 12,   # æœˆåº¦åŒæ¯”ï¼šä¸å»å¹´åŒæœˆæ¯”è¾ƒ
            "ç¯æ¯”": 1     # æœˆåº¦ç¯æ¯”ï¼šä¸å‰ä¸€æœˆæ¯”è¾ƒ
        },
        "annual": {
            "åŒæ¯”": 1,    # å¹´åº¦åŒæ¯”ï¼šä¸å‰ä¸€å¹´æ¯”è¾ƒ
            "ç¯æ¯”": 1     # å¹´åº¦ç¯æ¯”ï¼šä¸å‰ä¸€å¹´æ¯”è¾ƒï¼ˆå¹´åº¦æƒ…å†µä¸‹åŒæ¯”ç¯æ¯”ç›¸åŒï¼‰
        }
    }
    
    periods = periods_map.get(frequency, {}).get(comparison_type, 1)
    
    # è®¡ç®—ç™¾åˆ†æ¯”å˜åŒ–
    df_pct_change = df_copy.pct_change(periods=periods, fill_method=None) * 100
    
    if df_pct_change.empty:
        return pd.Series(dtype=float)
    
    # è®¡ç®—æ‰©æ•£æŒ‡æ•°ï¼šè¶…è¿‡é˜ˆå€¼çš„æŒ‡æ ‡æ•°é‡ / æ€»æœ‰æ•ˆæŒ‡æ ‡æ•°é‡
    above_threshold = (df_pct_change > tolerance_threshold).sum(axis=1)
    total_non_nan = df_pct_change.notna().sum(axis=1)
    diffusion_index = (above_threshold / total_non_nan).fillna(0) * 100
    
    return diffusion_index

def get_frequency_display_info(frequency: str, comparison_type: str) -> dict:
    """è·å–é¢‘ç‡æ˜¾ç¤ºç›¸å…³ä¿¡æ¯"""
    info_map = {
        "daily": {
            "åŒæ¯”": {
                "title_prefix": "æ—¥åº¦åŒæ¯”",
                "line_name": "æ—¥åº¦åŒæ¯”æ‰©æ•£æŒ‡æ•°",
                "color": "blue",
                "tolerance_range": (-10.0, 30.0, 0.0, 0.5),
                "file_suffix": "daily_yoy"
            },
            "ç¯æ¯”": {
                "title_prefix": "æ—¥åº¦ç¯æ¯”", 
                "line_name": "æ—¥åº¦ç¯æ¯”æ‰©æ•£æŒ‡æ•°",
                "color": "green",
                "tolerance_range": (-5.0, 15.0, 0.0, 0.1),
                "file_suffix": "daily_wow"
            }
        },
        "weekly": {
            "åŒæ¯”": {
                "title_prefix": "å‘¨åº¦åŒæ¯”",
                "line_name": "å‘¨åº¦åŒæ¯”æ‰©æ•£æŒ‡æ•°",
                "color": "royalblue",
                "tolerance_range": (-25.0, 50.0, 0.0, 0.5),
                "file_suffix": "weekly_yoy"
            },
            "ç¯æ¯”": {
                "title_prefix": "å‘¨åº¦ç¯æ¯”",
                "line_name": "å‘¨åº¦ç¯æ¯”æ‰©æ•£æŒ‡æ•°", 
                "color": "darkorange",
                "tolerance_range": (-10.0, 20.0, 0.0, 0.1),
                "file_suffix": "weekly_wow"
            }
        },
        "monthly": {
            "åŒæ¯”": {
                "title_prefix": "æœˆåº¦åŒæ¯”",
                "line_name": "æœˆåº¦åŒæ¯”æ‰©æ•£æŒ‡æ•°",
                "color": "purple",
                "tolerance_range": (-20.0, 40.0, 0.0, 0.5),
                "file_suffix": "monthly_yoy"
            },
            "ç¯æ¯”": {
                "title_prefix": "æœˆåº¦ç¯æ¯”",
                "line_name": "æœˆåº¦ç¯æ¯”æ‰©æ•£æŒ‡æ•°",
                "color": "red",
                "tolerance_range": (-8.0, 15.0, 0.0, 0.2),
                "file_suffix": "monthly_wow"
            }
        },
        "annual": {
            "åŒæ¯”": {
                "title_prefix": "å¹´åº¦åŒæ¯”",
                "line_name": "å¹´åº¦åŒæ¯”æ‰©æ•£æŒ‡æ•°",
                "color": "darkgreen",
                "tolerance_range": (-15.0, 25.0, 0.0, 0.5),
                "file_suffix": "annual_yoy"
            },
            "ç¯æ¯”": {
                "title_prefix": "å¹´åº¦ç¯æ¯”",
                "line_name": "å¹´åº¦ç¯æ¯”æ‰©æ•£æŒ‡æ•°",
                "color": "brown", 
                "tolerance_range": (-15.0, 25.0, 0.0, 0.5),
                "file_suffix": "annual_wow"
            }
        }
    }
    
    return info_map.get(frequency, {}).get(comparison_type, {
        "title_prefix": "æ‰©æ•£æŒ‡æ•°",
        "line_name": "æ‰©æ•£æŒ‡æ•°",
        "color": "gray",
        "tolerance_range": (-10.0, 20.0, 0.0, 0.1),
        "file_suffix": "diffusion"
    })

def calculate_weekly_growth_summary(df_weekly: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—å‘¨åº¦æ•°æ®çš„å†å²å€¼ã€å¢é•¿ç‡åŠè¿‘5å¹´ç»Ÿè®¡ï¼Œå¹¶ç”Ÿæˆæ±‡æ€»è¡¨ã€‚
    å¯¹æ¯ä¸ªæŒ‡æ ‡ï¼Œä½¿ç”¨å…¶è‡ªèº«æœ€æ–°çš„æœ‰æ•ˆæ•°æ®æ—¥æœŸè¿›è¡Œè®¡ç®—ã€‚

    å‚æ•°:
    df_weekly: pd.DataFrame
        é¢„å¤„ç†åçš„å‘¨åº¦æ•°æ® DataFrame (åº”åŒ…å« DatetimeIndex)ã€‚

    è¿”å›:
    pd.DataFrame: åŒ…å«æŒ‡æ ‡åç§°ã€æœ€æ–°æ—¥æœŸåŠå„ç§æœ€æ–°å¢é•¿ç‡çš„æ±‡æ€»è¡¨ã€‚
                 å¦‚æœè¾“å…¥ DataFrame ä¸ºç©ºæˆ–æ— æ•ˆï¼Œåˆ™è¿”å›ç©º DataFrameã€‚
    """
    if df_weekly is None or df_weekly.empty or not isinstance(df_weekly.index, pd.DatetimeIndex):
        print("è¾“å…¥çš„å‘¨åº¦ DataFrame ä¸ºç©ºæˆ–ç´¢å¼•æ— æ•ˆï¼Œæ— æ³•è®¡ç®—ã€‚")
        return pd.DataFrame()

    # ç¡®ä¿æŒ‰æ—¶é—´æ’åº
    df_weekly = df_weekly.sort_index()

    print("å‡†å¤‡å†å²å€¼...")
    summary_data = []
    print("ç”Ÿæˆæ±‡æ€»è¡¨ä¸­ (æŒ‰æŒ‡æ ‡æœ€æ–°æ—¥æœŸè®¡ç®—)...")

    for indicator in df_weekly.columns:
        indicator_series = df_weekly[indicator].dropna()

        if indicator_series.empty:
            print(f"æŒ‡æ ‡ '{indicator}' æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡ã€‚")
            continue

        current_date = indicator_series.index.max()
        current_value = indicator_series.loc[current_date]

        last_week_date = current_date - pd.Timedelta(weeks=1)
        last_month_date = current_date - pd.Timedelta(weeks=4)
        last_year_date = current_date - pd.Timedelta(weeks=52)

        # ä¿®æ­£å†å²å€¼è·å–é€»è¾‘
        try:
            val_last_week = df_weekly.loc[last_week_date, indicator] if last_week_date in df_weekly.index else np.nan
        except (KeyError, IndexError):
            val_last_week = np.nan
            
        try:
            val_last_month = df_weekly.loc[last_month_date, indicator] if last_month_date in df_weekly.index else np.nan
        except (KeyError, IndexError):
            val_last_month = np.nan
            
        try:
            val_last_year = df_weekly.loc[last_year_date, indicator] if last_year_date in df_weekly.index else np.nan
        except (KeyError, IndexError):
            val_last_year = np.nan

        latest_wow = (current_value - val_last_week) / abs(val_last_week) if pd.notna(current_value) and pd.notna(val_last_week) and val_last_week != 0 else np.nan
        latest_moy = (current_value - val_last_month) / abs(val_last_month) if pd.notna(current_value) and pd.notna(val_last_month) and val_last_month != 0 else np.nan
        latest_yoy = (current_value - val_last_year) / abs(val_last_year) if pd.notna(current_value) and pd.notna(val_last_year) and val_last_year != 0 else np.nan

        current_year = current_date.year 
        stats_start_year = current_year - 5
        stats_end_year = current_year - 1
        stats_start_date = pd.Timestamp(f'{stats_start_year}-01-01')
        stats_end_date = pd.Timestamp(f'{stats_end_year}-12-31')

        historical_5y_data = indicator_series.loc[
            (indicator_series.index >= stats_start_date) &
            (indicator_series.index <= stats_end_date)
        ]

        if not historical_5y_data.empty:
            stat_max = historical_5y_data.max()
            stat_min = historical_5y_data.min()
            stat_mean = historical_5y_data.mean()
        else:
            stat_max, stat_min, stat_mean = np.nan, np.nan, np.nan

        summary_data.append({
            'å‘¨åº¦æŒ‡æ ‡åç§°': indicator,
            'æœ€æ–°æ—¥æœŸ': current_date.strftime('%Y-%m-%d'), 
            'æœ€æ–°å€¼': current_value, 
            'ä¸Šå‘¨å€¼': val_last_week,
            'ç¯æ¯”ä¸Šå‘¨': latest_wow,
            'ä¸Šæœˆå€¼': val_last_month, 
            'ç¯æ¯”ä¸Šæœˆ': latest_moy,  
            'ä¸Šå¹´å€¼': val_last_year, 
            'åŒæ¯”ä¸Šå¹´': latest_yoy, 
            'è¿‘5å¹´æœ€å¤§å€¼': stat_max,
            'è¿‘5å¹´æœ€å°å€¼': stat_min,
            'è¿‘5å¹´å¹³å‡å€¼': stat_mean
        })

    summary_df = pd.DataFrame(summary_data)
    print(f"æ±‡æ€»è¡¨ç”Ÿæˆå®Œæˆï¼Œå…± {len(summary_df)} ä¸ªæŒ‡æ ‡ã€‚")

    column_order = [
        'å‘¨åº¦æŒ‡æ ‡åç§°', 'æœ€æ–°æ—¥æœŸ', 'æœ€æ–°å€¼',
        'ä¸Šå‘¨å€¼', 'ç¯æ¯”ä¸Šå‘¨',
        'ä¸Šæœˆå€¼', 'ç¯æ¯”ä¸Šæœˆ',
        'ä¸Šå¹´å€¼', 'åŒæ¯”ä¸Šå¹´',
        'è¿‘5å¹´æœ€å¤§å€¼', 'è¿‘5å¹´æœ€å°å€¼', 'è¿‘5å¹´å¹³å‡å€¼'
    ]
    existing_columns = [col for col in column_order if col in summary_df.columns]
    summary_df = summary_df[existing_columns]

    return summary_df

def display_diffusion_tab(st, session_state):
    """æ˜¾ç¤ºå¢å¼ºç‰ˆæ‰©æ•£æŒ‡æ•°åˆ†æï¼Œæ”¯æŒå¤šç§æ—¶é—´é¢‘ç‡"""
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦å·²åŠ è½½
    if not session_state.get('data_loaded', False):
        st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶ã€‚")
        return

    # è·å–å¯ç”¨çš„æ•°æ® - ç¡®ä¿ä½¿ç”¨åŸå§‹æ•°æ®è€Œéæ±‡æ€»æ•°æ®
    available_frequencies = []
    frequency_data_map = {}
    
    # æ—¥åº¦æ•°æ®ï¼šä½¿ç”¨åŸå§‹æ—¥åº¦æ•°æ®
    daily_df = None
    if hasattr(session_state, 'daily_df') and not session_state.daily_df.empty:
        daily_df = session_state.daily_df
    elif hasattr(session_state, 'preview_daily_df') and not session_state.preview_daily_df.empty:
        daily_df = session_state.preview_daily_df
    
    if daily_df is not None and not daily_df.empty:
        available_frequencies.append(("æ—¥åº¦", "daily"))
        frequency_data_map["daily"] = daily_df
        
    # å‘¨åº¦æ•°æ®ï¼šä½¿ç”¨åŸå§‹å‘¨åº¦æ•°æ®
    weekly_df = None
    if hasattr(session_state, 'weekly_df') and not session_state.weekly_df.empty:
        weekly_df = session_state.weekly_df
    elif hasattr(session_state, 'preview_weekly_df') and not session_state.preview_weekly_df.empty:
        weekly_df = session_state.preview_weekly_df
    
    if weekly_df is not None and not weekly_df.empty:
        available_frequencies.append(("å‘¨åº¦", "weekly"))
        frequency_data_map["weekly"] = weekly_df
        
    # æœˆåº¦æ•°æ®ï¼šä½¿ç”¨åŸå§‹æœˆåº¦æ•°æ®
    monthly_df = None
    if hasattr(session_state, 'monthly_df') and not session_state.monthly_df.empty:
        monthly_df = session_state.monthly_df
    elif hasattr(session_state, 'preview_monthly_df') and not session_state.preview_monthly_df.empty:
        monthly_df = session_state.preview_monthly_df
    
    if monthly_df is not None and not monthly_df.empty:
        available_frequencies.append(("æœˆåº¦", "monthly"))
        frequency_data_map["monthly"] = monthly_df

    # å¹´åº¦æ•°æ®ï¼šä½¿ç”¨åŸå§‹å¹´åº¦æ•°æ®
    annual_df = None
    if hasattr(session_state, 'annual_df') and not session_state.annual_df.empty:
        annual_df = session_state.annual_df
    elif hasattr(session_state, 'preview_annual_df') and not session_state.preview_annual_df.empty:
        annual_df = session_state.preview_annual_df
    
    if annual_df is not None and not annual_df.empty:
        available_frequencies.append(("å¹´åº¦", "annual"))
        frequency_data_map["annual"] = annual_df

    if not available_frequencies:
        st.warning("æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„æ—¶é—´åºåˆ—æ•°æ®ã€‚è¯·ç¡®ä¿å·²ä¸Šä¼ åŒ…å«æ—¥åº¦ã€å‘¨åº¦æˆ–æœˆåº¦æ•°æ®çš„æ–‡ä»¶ã€‚")
        return

    # ç”¨æˆ·ç•Œé¢è®¾è®¡
    st.markdown("#### ç»¼åˆåˆ†æ")
    
    # å·¦å³å¸ƒå±€ï¼šå·¦ä¾§å‚æ•°è®¾ç½®ï¼Œå³ä¾§æ•°å€¼æ˜¾ç¤º
    left_col, right_col = st.columns([1, 1])
    
    with left_col:
        st.markdown("**å‚æ•°è®¾ç½®**")
        
        # ç¬¬ä¸€æ­¥ï¼šé€‰æ‹©æ—¶é—´é¢‘ç‡
        freq_options = [f[0] for f in available_frequencies]
        selected_freq_display = st.selectbox(
            "é€‰æ‹©æ•°æ®é¢‘ç‡",
            freq_options,
            key="diffusion_frequency_select",
            help="ä¸åŒé¢‘ç‡å°†ä½¿ç”¨å¯¹åº”çš„æ•°æ®è¿›è¡Œæ‰©æ•£æŒ‡æ•°è®¡ç®—"
        )
        
        # è·å–å¯¹åº”çš„é¢‘ç‡ä»£ç 
        selected_frequency = None
        for freq_display, freq_code in available_frequencies:
            if freq_display == selected_freq_display:
                selected_frequency = freq_code
                break
        
        if not selected_frequency:
            st.error("æœªèƒ½æ‰¾åˆ°å¯¹åº”çš„é¢‘ç‡æ•°æ®")
            return
        
        # ä¸ºä¸åŒé¢‘ç‡æä¾›è¯´æ˜
        comparison_help_text = {
            "daily": "åŒæ¯”ï¼šä¸ä¸Šå¹´åŒä¸€å¤©æ¯”è¾ƒï¼›ç¯æ¯”ï¼šä¸å‰ä¸€å¤©æ¯”è¾ƒ",
            "weekly": "åŒæ¯”ï¼šä¸ä¸Šå¹´åŒä¸€å‘¨æ¯”è¾ƒï¼›ç¯æ¯”ï¼šä¸å‰ä¸€å‘¨æ¯”è¾ƒ", 
            "monthly": "åŒæ¯”ï¼šä¸ä¸Šå¹´åŒæœˆæ¯”è¾ƒï¼›ç¯æ¯”ï¼šä¸å‰ä¸€æœˆæ¯”è¾ƒ",
            "annual": "åŒæ¯”ï¼šä¸å‰ä¸€å¹´æ¯”è¾ƒï¼›ç¯æ¯”ï¼šä¸å‰ä¸€å¹´æ¯”è¾ƒ"
        }
        
        # ç¬¬äºŒæ­¥ï¼šé€‰æ‹©æ¯”è¾ƒç±»å‹
        comparison_type = st.radio(
            "è®¡ç®—æ–¹å¼",
            ("åŒæ¯”", "ç¯æ¯”"),
            key="diffusion_comparison_select",
            horizontal=True,
            help=comparison_help_text.get(selected_frequency, "é€‰æ‹©åŒæ¯”æˆ–ç¯æ¯”è®¡ç®—æ–¹å¼")
        )
        
        # è·å–å½“å‰é€‰æ‹©çš„æ•°æ®å’Œæ˜¾ç¤ºä¿¡æ¯
        current_data = frequency_data_map[selected_frequency]
        display_info = get_frequency_display_info(selected_frequency, comparison_type)
        
        # ç¬¬ä¸‰æ­¥ï¼šè®¾ç½®å®¹å¿åº¦é˜ˆå€¼
        min_val, max_val, default_val, step_val = display_info["tolerance_range"]
        tolerance_threshold = st.slider(
            f"å®¹å¿åº¦é˜ˆå€¼ (%)",
            min_value=min_val,
            max_value=max_val,
            value=default_val,
            step=step_val,
            format="%.1f%%",
            help=f"æŒ‡æ ‡{selected_freq_display}{comparison_type}å¢é•¿ç‡è¶…è¿‡æ­¤é˜ˆå€¼æ‰è¢«è§†ä¸ºå¢é•¿",
            key=f"tolerance_{selected_frequency}_{comparison_type}"
        )
        
                        # æ·»åŠ æ—¶é—´èŒƒå›´ç­›é€‰
        st.markdown("**é€‰æ‹©æ—¶é—´èŒƒå›´**")
        
        if not current_data.empty:
            # è·å–æ•°æ®çš„æ—¶é—´èŒƒå›´
            min_date = current_data.index.min().date()
            max_date = current_data.index.max().date()
            
            # é»˜è®¤æ˜¾ç¤ºæœ€è¿‘2å¹´çš„æ•°æ®
            from datetime import timedelta
            try:
                default_start_date = max_date - timedelta(days=365*2)
                if default_start_date < min_date:
                    default_start_date = min_date
            except:
                default_start_date = min_date
            
            # åˆ†ç¦»çš„æ—¶é—´é€‰æ‹©å™¨
            col_start, col_sep, col_end = st.columns([1, 0.1, 1])
            
            with col_start:
                start_date = st.date_input(
                    "å¼€å§‹æ—¶é—´",
                    value=default_start_date,
                    min_value=min_date,
                    max_value=max_date,
                    key="start_date_diffusion"
                )
                
            with col_sep:
                st.markdown("<div style='text-align: center; padding-top: 25px;'>-</div>", unsafe_allow_html=True)
                
            with col_end:
                end_date = st.date_input(
                    "ç»“æŸæ—¶é—´", 
                    value=max_date,
                    min_value=min_date,
                    max_value=max_date,
                    key="end_date_diffusion"
                )
            
            # ç¡®ä¿ç»“æŸæ—¶é—´ä¸æ—©äºå¼€å§‹æ—¶é—´
            if end_date < start_date:
                st.error("ç»“æŸæ—¶é—´ä¸èƒ½æ—©äºå¼€å§‹æ—¶é—´")
                return
            
            # æ ¹æ®æ¯”è¾ƒç±»å‹ç¡®å®šæ‰€éœ€çš„åŸºæœŸé•¿åº¦
            if comparison_type == "åŒæ¯”":
                if selected_frequency == "daily":
                    base_periods = 365  # æ—¥åº¦åŒæ¯”éœ€è¦365å¤©åŸºæœŸ
                elif selected_frequency == "weekly": 
                    base_periods = 52   # å‘¨åº¦åŒæ¯”éœ€è¦52å‘¨åŸºæœŸ
                elif selected_frequency == "monthly":
                    base_periods = 12   # æœˆåº¦åŒæ¯”éœ€è¦12ä¸ªæœˆåŸºæœŸ
                else:  # annual
                    base_periods = 1    # å¹´åº¦åŒæ¯”éœ€è¦1å¹´åŸºæœŸ
            else:  # ç¯æ¯”
                base_periods = 1        # ç¯æ¯”åªéœ€è¦1æœŸåŸºæœŸ
            
            # è®¡ç®—éœ€è¦åŒ…å«çš„åŸºæœŸå¼€å§‹æ—¶é—´
            if selected_frequency == "daily":
                base_start_date = start_date - timedelta(days=base_periods)
            elif selected_frequency == "weekly":
                base_start_date = start_date - timedelta(weeks=base_periods) 
            elif selected_frequency == "monthly":
                base_start_date = start_date - timedelta(days=base_periods*30)  # è¿‘ä¼¼
            else:  # annual
                base_start_date = start_date - timedelta(days=base_periods*365)
            
            # ç¡®ä¿åŸºæœŸå¼€å§‹æ—¶é—´ä¸æ—©äºæ•°æ®æœ€æ—©æ—¶é—´
            if base_start_date < min_date:
                base_start_date = min_date
            
            # æ˜¾ç¤ºåŸºæœŸæç¤ºä¿¡æ¯
            if base_start_date < start_date:
                st.info(f"ä¸ºè®¡ç®—{comparison_type}å¢é•¿ç‡ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨ {base_start_date} è‡³ {start_date} çš„æ•°æ®ä½œä¸ºåŸºæœŸï¼ˆä¸åœ¨å›¾è¡¨ä¸­æ˜¾ç¤ºï¼‰ï¼Œå®é™…å±•ç¤ºæ—¶é—´ä¸º {start_date} è‡³ {end_date}")
            
            # è·å–åŒ…å«åŸºæœŸçš„å®Œæ•´æ•°æ®ç”¨äºè®¡ç®—
            full_data_for_calc = current_data.loc[base_start_date:end_date]
            
            # è·å–ä»…ç”¨äºæ˜¾ç¤ºçš„æ•°æ®ï¼ˆæ’é™¤åŸºæœŸï¼‰
            display_data = current_data.loc[start_date:end_date]
            
            # æ›´æ–°current_dataä¸ºåŒ…å«åŸºæœŸçš„æ•°æ®ï¼ˆç”¨äºè®¡ç®—ï¼‰
            current_data = full_data_for_calc
    
    # è®¡ç®—å’Œæ˜¾ç¤ºæ‰©æ•£æŒ‡æ•°ç»“æœ

    try:
        # ä½¿ç”¨ç¼“å­˜æœºåˆ¶ä¼˜åŒ–æ€§èƒ½
        df_hash = get_dataframe_hash(current_data)
        df_values = [current_data.values.tolist(), current_data.index.tolist(), current_data.columns.tolist()]
        
        with st.spinner(f"æ­£åœ¨è®¡ç®—{selected_freq_display}{comparison_type}æ‰©æ•£æŒ‡æ•°..."):
            diffusion_index_full = cached_calculate_diffusion_index(
                df_hash,
                selected_frequency, 
                comparison_type, 
                tolerance_threshold,
                df_values
            )
        
        # å¦‚æœæœ‰æ—¶é—´èŒƒå›´é€‰æ‹©ï¼Œåˆ™åªæ˜¾ç¤ºæ’é™¤åŸºæœŸåçš„æ‰©æ•£æŒ‡æ•°
        if 'display_data' in locals() and not display_data.empty:
            # ç­›é€‰å‡ºæ˜¾ç¤ºæ—¶é—´èŒƒå›´å†…çš„æ‰©æ•£æŒ‡æ•°
            diffusion_index = diffusion_index_full.loc[start_date:end_date]
        else:
            diffusion_index = diffusion_index_full
        
        if not diffusion_index.empty:
            # å³ä¾§æ˜¾ç¤ºæ•°å€¼ä¿¡æ¯
            with right_col:
                st.markdown("**æ‘˜è¦**")
                
                # æœ€æ–°å€¼ç»Ÿè®¡ä¿¡æ¯
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("æœ€æ–°å€¼", f"{diffusion_index.iloc[-1]:.1f}%")
                    st.metric("æœ€å¤§å€¼", f"{diffusion_index.max():.1f}%")
                    st.metric("æœ€å°å€¼", f"{diffusion_index.min():.1f}%")
                    
                with col2:
                    st.metric("å¹³å‡å€¼", f"{diffusion_index.mean():.1f}%")
                    # è®¡ç®—è¶‹åŠ¿
                    if len(diffusion_index) >= 2:
                        latest_change = diffusion_index.iloc[-1] - diffusion_index.iloc[-2]
                        trend_direction = "ä¸Šå‡" if latest_change > 0 else "ä¸‹é™" if latest_change < 0 else "æŒå¹³"
                        st.metric(f"å˜åŒ– ({trend_direction})", f"{latest_change:+.1f}%")
                    else:
                        st.metric("æ•°æ®ç‚¹", f"{len(diffusion_index)}")
            
            st.markdown("---")
            
            # ç»˜åˆ¶æ‰©æ•£æŒ‡æ•°å›¾è¡¨
            fig_diffusion = go.Figure()
            fig_diffusion.add_trace(go.Scatter(
                x=diffusion_index.index,
                y=diffusion_index,
                mode='lines+markers',
                name=display_info["line_name"],
                line=dict(color=display_info["color"], width=2),
                marker=dict(size=4),
                hovertemplate='%{x|%Y-%m-%d}<br>æ‰©æ•£æŒ‡æ•°: %{y:.1f}%<extra></extra>'
            ))

            # æ·»åŠ 50%åŸºå‡†çº¿
            fig_diffusion.add_hline(
                y=50,
                line_width=1.5,
                line_dash="dash",
                line_color="grey",
                annotation_text="50%",
                annotation_position="bottom right"
            )

            # æ ¹æ®é¢‘ç‡è®¾ç½®æ—¶é—´è½´æ ¼å¼
            xaxis_format_map = {
                "daily": {"dtick": "M1", "tickformat": "%Y-%m"},      # æœˆåº¦åˆ»åº¦
                "weekly": {"dtick": "M1", "tickformat": "%Y-%m"},     # æœˆåº¦åˆ»åº¦  
                "monthly": {"dtick": "M3", "tickformat": "%Y-%m"},    # å­£åº¦åˆ»åº¦
                "annual": {"dtick": "M12", "tickformat": "%Y"}        # å¹´åº¦åˆ»åº¦
            }
            
            xaxis_config = xaxis_format_map.get(selected_frequency, {"dtick": "M1", "tickformat": "%Y-%m"})
            
            fig_diffusion.update_layout(
                title=f'{display_info["title_prefix"]}æ‰©æ•£æŒ‡æ•° (é˜ˆå€¼: {tolerance_threshold:.1f}%)',
                xaxis=dict(
                    dtick=xaxis_config["dtick"],
                    tickformat=xaxis_config["tickformat"],
                    tickangle=45
                ),
                yaxis_title="æ‰©æ•£æŒ‡æ•° (%)",
                yaxis_range=[0, 100],
                hovermode='x unified',
                height=450,
                showlegend=False
            )

            st.plotly_chart(fig_diffusion, use_container_width=True)
            
            # æä¾›æ•°æ®ä¸‹è½½
            if not diffusion_index.empty:
                try:
                    output_di = io.BytesIO()
                    df_di_download = diffusion_index.reset_index()
                    df_di_download.columns = ['æ—¥æœŸ', 'æ‰©æ•£æŒ‡æ•°(%)']
                    excel_sheet_name_di = f'{display_info["title_prefix"]}æ‰©æ•£æŒ‡æ•°'
                    
                    with pd.ExcelWriter(output_di, engine='openpyxl', datetime_format='yyyy-mm-dd') as writer:
                        df_di_download.to_excel(writer, sheet_name=excel_sheet_name_di, index=False)
                    output_di.seek(0)
                    
                    st.download_button(
                        label=f"ä¸‹è½½{display_info['title_prefix']}æ‰©æ•£æŒ‡æ•°æ•°æ®",
                        data=output_di,
                        file_name=f'diffusion_index_{display_info["file_suffix"]}_thr{tolerance_threshold:.1f}.xlsx',
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                        key=f'download_diffusion_{selected_frequency}_{comparison_type}'
                    )
                except Exception as e_download:
                    st.error(f"ç”Ÿæˆä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e_download}")
                
        else:
            st.warning(f"æ— æ³•è®¡ç®—{selected_freq_display}{comparison_type}æ‰©æ•£æŒ‡æ•°ï¼Œå¯èƒ½æ˜¯æ•°æ®ä¸è¶³æˆ–æ—¶é—´èŒƒå›´ä¸å¤Ÿã€‚")
            
    except Exception as e:
        st.error(f"è®¡ç®—æ‰©æ•£æŒ‡æ•°æ—¶å‡ºé”™: {e}")
        import traceback
        st.error(traceback.format_exc())

    # === çƒ­åŠ›å›¾åŠŸèƒ½ï¼ˆæ”¯æŒæ‰€æœ‰é¢‘ç‡ï¼‰ ===
    indicator_industry_map = session_state.get('indicator_industry_map') or session_state.get('preview_indicator_industry_map')
    if indicator_industry_map:
                
        industry_map = indicator_industry_map
        # ä½¿ç”¨åŒ…å«åŸºæœŸçš„å®Œæ•´æ•°æ®è¿›è¡Œè®¡ç®—ï¼Œä½†æ˜¾ç¤ºæ—¶æ’é™¤åŸºæœŸ
        data_full = current_data
        
        # å¦‚æœæœ‰æ—¶é—´èŒƒå›´é€‰æ‹©ï¼Œå‡†å¤‡ç”¨äºæ˜¾ç¤ºçš„æ•°æ®
        if 'display_data' in locals() and not display_data.empty:
            data_display = display_data
        else:
            data_display = current_data
        
        if not industry_map:
            st.warning("ç¼ºå°‘è¡Œä¸šæ˜ å°„ä¿¡æ¯ï¼Œæ— æ³•æŒ‰è¡Œä¸šåˆ†ç»„ç”Ÿæˆçƒ­åŠ›å›¾ã€‚")
            return

        try:
            # æ ¹æ®é¢‘ç‡è®¾ç½®çƒ­åŠ›å›¾å‚æ•°
            freq_display_map = {
                "daily": "æ—¥",
                "weekly": "å‘¨", 
                "monthly": "æœˆ",
                "annual": "å¹´"
            }
            freq_display = freq_display_map.get(selected_frequency, "")
            heatmap_type_display = f'{freq_display}{comparison_type}'
            
            # æ ¹æ®é¢‘ç‡å’Œæ¯”è¾ƒç±»å‹è®¾ç½®è®¡ç®—å‘¨æœŸ
            if comparison_type == "åŒæ¯”":
                calc_periods_map = {
                    "daily": 365,
                    "weekly": 52,
                    "monthly": 12,
                    "annual": 1
                }
                calc_periods = calc_periods_map.get(selected_frequency, 1)
            else:  # ç¯æ¯”
                calc_periods = 1
            
            hover_label_prefix = f"{freq_display}{comparison_type}"
            
            # ä½¿ç”¨åŒ…å«åŸºæœŸçš„å®Œæ•´æ•°æ®è®¡ç®—å¢é•¿ç‡
            data_calc = data_full.copy()
            data_calc.index = pd.to_datetime(data_calc.index)
            
            with st.spinner(f"æ­£åœ¨è®¡ç®—{heatmap_type_display}å¢é•¿ç‡..."):
                df_pct_change_full = data_calc.pct_change(periods=calc_periods, fill_method=None) * 100

            # å¦‚æœæœ‰æ—¶é—´èŒƒå›´ç­›é€‰ï¼Œåªå–æ˜¾ç¤ºæ—¶é—´èŒƒå›´å†…çš„æ•°æ®
            if 'data_display' in locals() and not data_display.empty:
                # ç­›é€‰å‡ºæ˜¾ç¤ºæ—¶é—´èŒƒå›´å†…çš„å¢é•¿ç‡æ•°æ®
                display_start = data_display.index.min()
                display_end = data_display.index.max()
                heatmap_data = df_pct_change_full.loc[display_start:display_end]
            else:
                heatmap_data = df_pct_change_full.copy()
            
            if not heatmap_data.empty and isinstance(heatmap_data.index, pd.DatetimeIndex):
                # æ ¹æ®é¢‘ç‡è®¾ç½®æ˜¾ç¤ºçš„æœŸæ•°
                periods_to_show_map = {
                    "daily": 20,    # æ˜¾ç¤ºæœ€è¿‘20å¤©
                    "weekly": 15,   # æ˜¾ç¤ºæœ€è¿‘15å‘¨
                    "monthly": 12,  # æ˜¾ç¤ºæœ€è¿‘12æœˆ
                    "annual": 5     # æ˜¾ç¤ºæœ€è¿‘5å¹´
                }
                n_periods_to_show = periods_to_show_map.get(selected_frequency, 15)
                heatmap_data_recent = heatmap_data.tail(n_periods_to_show)

                if not heatmap_data_recent.empty:
                    # è½¬ç½®æ•°æ®ï¼ˆæŒ‡æ ‡ä½œä¸ºè¡Œï¼Œæ—¶é—´ä½œä¸ºåˆ—ï¼‰
                    heatmap_data_transposed = heatmap_data_recent.transpose()
                    heatmap_data_transposed = heatmap_data_transposed.sort_index(axis=1, ascending=False)
                    latest_date_col = heatmap_data_transposed.columns[0]

                    # ğŸ” æ ¹æ®æ•°æ®æºä¸¥æ ¼è¿‡æ»¤ï¼šåªä¿ç•™å¯¹åº”é¢‘ç‡çš„åŸå§‹æŒ‡æ ‡
                    all_indicators = heatmap_data_transposed.index.tolist()
                    
                    # è·å–åŸå§‹çš„source_mapæ¥åˆ¤æ–­æŒ‡æ ‡çœŸå®æ¥æº
                    source_map = session_state.get('source_map') or session_state.get('preview_source_map', {})
                    
                    # æ ¹æ®é€‰æ‹©çš„é¢‘ç‡ç¡®å®šè¿‡æ»¤æ¡ä»¶
                    freq_filter_map = {
                        "daily": "æ—¥åº¦",
                        "weekly": "å‘¨åº¦", 
                        "monthly": "æœˆåº¦",
                        "annual": "å¹´åº¦"
                    }
                    target_freq_name = freq_filter_map.get(selected_frequency, "")
                    
                    genuine_indicators = []
                    other_freq_indicators = []
                    
                    for indicator in all_indicators:
                        source = source_map.get(indicator, "")
                        # æ£€æŸ¥æ•°æ®æºï¼šåªä¿ç•™ç›®æ ‡é¢‘ç‡çš„åŸå§‹æŒ‡æ ‡
                        if target_freq_name in source:
                            genuine_indicators.append(indicator)
                        else:
                            # å¯èƒ½æ˜¯å…¶ä»–é¢‘ç‡çš„æŒ‡æ ‡
                            other_freq_indicators.append(indicator)
                    
                    # åªä¿ç•™å¯¹åº”é¢‘ç‡çš„åŸå§‹æŒ‡æ ‡
                    if genuine_indicators:
                        heatmap_data_transposed = heatmap_data_transposed.loc[genuine_indicators]
                    else:
                        st.warning(f"æœªæ‰¾åˆ°çº¯{selected_freq_display}æŒ‡æ ‡ï¼Œæ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾ã€‚")
                        return
                    
                    # æ·»åŠ è¡Œä¸šä¿¡æ¯
                    heatmap_data_transposed['è¡Œä¸š'] = heatmap_data_transposed.index.map(
                        lambda x: industry_map.get(normalize_string(x), 'æœªåˆ†ç±»')
                    )
                    
                    # æŒ‰è¡Œä¸šåˆ†ç»„æ•°æ®
                    industries = heatmap_data_transposed['è¡Œä¸š'].unique()
                    # è¿‡æ»¤æ‰ç©ºçš„æˆ–æ— æŒ‡æ ‡çš„è¡Œä¸š
                    valid_industries = []
                    industry_data_dict = {}
                    
                    for industry in industries:
                        industry_data = heatmap_data_transposed[heatmap_data_transposed['è¡Œä¸š'] == industry]
                        if not industry_data.empty and len(industry_data) > 0:
                            valid_industries.append(industry)
                            # æŒ‰æœ€æ–°æœŸæ•°å€¼æ’åº
                            industry_data_sorted = industry_data.sort_values(
                                by=latest_date_col, 
                                ascending=False
                            )
                            industry_data_dict[industry] = industry_data_sorted.drop(columns=['è¡Œä¸š'])
                    
                    if not valid_industries:
                        st.warning("æ²¡æœ‰æœ‰æ•ˆçš„è¡Œä¸šæ•°æ®ç”¨äºç”Ÿæˆçƒ­åŠ›å›¾ã€‚")
                        return
                    
                    # æ¯æ’2ä¸ªçƒ­åŠ›å›¾çš„å¸ƒå±€
                    
                    # è®¡ç®—éœ€è¦çš„è¡Œæ•°
                    n_industries = len(valid_industries)
                    n_rows = (n_industries + 1) // 2  # å‘ä¸Šå–æ•´
                    
                    for row in range(n_rows):
                        cols = st.columns(2)
                        
                        for col_idx in range(2):
                            industry_idx = row * 2 + col_idx
                            if industry_idx < n_industries:
                                industry = valid_industries[industry_idx]
                                industry_data = industry_data_dict[industry]
                                
                                with cols[col_idx]:
                                    # å‡†å¤‡è¯¥è¡Œä¸šçš„ç»˜å›¾æ•°æ®
                                    indicator_names = industry_data.index.tolist()
                                    y_labels_industry = [name.split(' - ')[-1] if ' - ' in name else name for name in indicator_names]
                                    x_labels_industry = [col.strftime('%Y-%m-%d') for col in industry_data.columns]
                                    
                                    z_values_industry = industry_data.values
                                    z_color_values_industry = np.sign(z_values_industry)
                                    z_text_values_industry = [[f'{val:.1f}' if pd.notna(val) else '' for val in row] for row in z_values_industry]
                                    
                                    # åˆ›å»ºè¯¥è¡Œä¸šçš„çƒ­åŠ›å›¾
                                    fig_industry = go.Figure(data=go.Heatmap(
                                        z=z_color_values_industry,
                                        x=x_labels_industry,
                                        y=y_labels_industry,
                                        colorscale=[[0.0, 'rgb(144,238,144)'], [0.5, 'rgb(255,255,255)'], [1.0, 'rgb(255,182,193)']],
                                        zmin=-1,
                                        zmax=1,
                                        showscale=False,
                                        text=z_text_values_industry,
                                        texttemplate="%{text}",
                                        textfont={"size": 9},
                                        customdata=z_values_industry,
                                        hovertemplate="<b>%{y}</b><br><i>%{x}</i><br>" + 
                                                      f"{hover_label_prefix}: %{{customdata:.1f}}%<extra></extra>",
                                        hoverongaps=False,
                                        xgap=1,
                                        ygap=1
                                    ))

                                    # åŠ¨æ€è°ƒæ•´é«˜åº¦
                                    chart_height = max(300, len(indicator_names) * 25 + 100)
                                    
                                    fig_industry.update_layout(
                                        title=f"{industry}",
                                        title_font_size=14,
                                        xaxis={'type': 'category', 'tickfont': {'size': 9}},
                                        xaxis_side='top',
                                        yaxis_title="",
                                        yaxis={'type': 'category', 'tickfont': {'size': 9}},
                                        height=chart_height,
                                        margin=dict(l=20, r=20, t=40, b=20)
                                    )
                                    
                                    st.plotly_chart(fig_industry, use_container_width=True)
                            else:
                                # å¦‚æœæ˜¯å¥‡æ•°ä¸ªè¡Œä¸šï¼Œæœ€åä¸€ä¸ªä½ç½®ç•™ç©º
                                with cols[col_idx]:
                                    st.empty()

                    # çƒ­åŠ›å›¾æ•°æ®ä¸‹è½½
                    try:
                        output = io.BytesIO()
                        
                        # é‡æ–°æ„å»ºå®Œæ•´çš„æ•°æ®ç”¨äºä¸‹è½½
                        all_data_for_download = []
                        for industry in valid_industries:
                            industry_data = industry_data_dict[industry].copy()
                            industry_data['è¡Œä¸š'] = industry
                            all_data_for_download.append(industry_data)
                        
                        if all_data_for_download:
                            df_to_download = pd.concat(all_data_for_download)
                            # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåºï¼ŒæŠŠè¡Œä¸šåˆ—æ”¾åœ¨æœ€å‰é¢
                            cols = ['è¡Œä¸š'] + [col for col in df_to_download.columns if col != 'è¡Œä¸š']
                            df_to_download = df_to_download[cols]
                            
                            # æ ¼å¼åŒ–æ—¥æœŸåˆ—
                            date_cols = [col for col in df_to_download.columns if isinstance(df_to_download[col].dtype, type(pd.Timestamp))]
                            for col in date_cols:
                                df_to_download[col] = df_to_download[col].dt.strftime('%Y-%m-%d')

                            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                df_to_download.to_excel(writer, sheet_name=f"{heatmap_type_display}æ•°æ®", index=True)
                            output.seek(0)
                            
                            st.download_button(
                                label="ä¸‹è½½çƒ­åŠ›å›¾æ•°æ®",
                                data=output,
                                file_name=f'diffusion_heatmap_{display_info["file_suffix"]}.xlsx',
                                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                                key='download_diffusion_heatmap'
                            )
                    except Exception as e_download:
                        st.error(f"ç”Ÿæˆçƒ­åŠ›å›¾ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e_download}")

        except Exception as e:
            st.error(f"ç”Ÿæˆçƒ­åŠ›å›¾æ—¶å‡ºé”™: {e}")
            import traceback
            st.error(traceback.format_exc())

